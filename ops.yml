graph:
  $args: {$x_1: Tensor}
  $1: int[] = prim::Constant[value=[0, 0]]()
  $2: int[] = prim::Constant[value=[3, 3]]()
  $3: int[] = prim::Constant[value=[2, 2]]()
  $4: float = prim::Constant[value=1.0000000000000001e-05]() # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/functional.py:2391:0
  $5: float = prim::Constant[value=0.10000000000000001]() # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/functional.py:2391:0
  $6: int = prim::Constant[value=1]() # :0:0
  $7: Float(64, 3, 7, 7, strides=[147, 49, 7, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # :0:0
  $8: NoneType = prim::Constant() # :0:0
  $9: bool = prim::Constant[value=0]() # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/modules/conv.py:444:0
  $10: bool = prim::Constant[value=1]() # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/modules/conv.py:444:0
  $11: Float(64, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # :0:0
  $12: Float(64, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # :0:0
  $13: int[] = prim::Constant[value=[1, 1]]()
  $14: Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # :0:0
  $15: Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # :0:0
  $16: Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # :0:0
  $17: Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # :0:0
  $18: Float(128, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # :0:0
  $19: Float(128, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # :0:0
  $20: Float(128, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # :0:0
  $21: Float(128, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # :0:0
  $22: Float(128, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # :0:0
  $23: Float(128, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # :0:0
  $24: Float(128, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # :0:0
  $25: Float(256, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # :0:0
  $26: Float(256, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # :0:0
  $27: Float(256, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # :0:0
  $28: Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # :0:0
  $29: Float(256, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # :0:0
  $30: Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # :0:0
  $31: Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # :0:0
  $32: Float(512, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # :0:0
  $33: Float(512, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # :0:0
  $34: Float(512, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # :0:0
  $35: Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # :0:0
  $36: Float(512, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # :0:0
  $37: Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # :0:0
  $38: Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # :0:0
  $39: int = prim::Constant[value=-1]()
  $40: Float(1000, 512, strides=[512, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # :0:0
  $41: Float(1000, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # :0:0
  $input_1: Float(1, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution($x_1, $7, $8, $3, $2, $13, $9, $1, $6, $9, $9, $10, $10) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/modules/conv.py:444:0
  $input0_1: Float(1, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cpu) = aten::batch_norm($input_1, $11, $12, $12, $11, $9, $5, $4, $10) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/functional.py:2391:0
  $input1_1: Float(1, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cpu) = aten::relu($input0_1) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/functional.py:1400:0
  $input2_1: Float(1, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cpu) = aten::max_pool2d($input1_1, $2, $3, $13, $13, $9) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/functional.py:790:0
  $input3_1: Float(1, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution($input2_1, $14, $8, $13, $13, $13, $9, $1, $6, $9, $9, $10, $10) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/modules/conv.py:444:0
  $input4_1: Float(1, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cpu) = aten::batch_norm($input3_1, $11, $12, $12, $11, $9, $5, $4, $10) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/functional.py:2391:0
  $input5_1: Float(1, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cpu) = aten::relu($input4_1) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/functional.py:1400:0
  $input6_1: Float(1, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution($input5_1, $15, $8, $13, $13, $13, $9, $1, $6, $9, $9, $10, $10) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/modules/conv.py:444:0
  $out_1: Float(1, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cpu) = aten::batch_norm($input6_1, $11, $12, $12, $11, $9, $5, $4, $10) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/functional.py:2391:0
  $input7_1: Float(1, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cpu) = aten::add($out_1, $input2_1, $6) # /Users/mlevental/dev_projects/pytorch_memory_planning/resnet.py:96:0
  $input8_1: Float(1, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cpu) = aten::relu($input7_1) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/functional.py:1400:0
  $input9_1: Float(1, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution($input8_1, $16, $8, $13, $13, $13, $9, $1, $6, $9, $9, $10, $10) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/modules/conv.py:444:0
  $input10_1: Float(1, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cpu) = aten::batch_norm($input9_1, $11, $12, $12, $11, $9, $5, $4, $10) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/functional.py:2391:0
  $input11_1: Float(1, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cpu) = aten::relu($input10_1) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/functional.py:1400:0
  $input12_1: Float(1, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution($input11_1, $17, $8, $13, $13, $13, $9, $1, $6, $9, $9, $10, $10) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/modules/conv.py:444:0
  $out0_1: Float(1, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cpu) = aten::batch_norm($input12_1, $11, $12, $12, $11, $9, $5, $4, $10) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/functional.py:2391:0
  $input13_1: Float(1, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cpu) = aten::add($out0_1, $input8_1, $6) # /Users/mlevental/dev_projects/pytorch_memory_planning/resnet.py:96:0
  $input14_1: Float(1, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cpu) = aten::relu($input13_1) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/functional.py:1400:0
  $input15_1: Float(1, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution($input14_1, $18, $8, $3, $13, $13, $9, $1, $6, $9, $9, $10, $10) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/modules/conv.py:444:0
  $input16_1: Float(1, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cpu) = aten::batch_norm($input15_1, $19, $20, $20, $19, $9, $5, $4, $10) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/functional.py:2391:0
  $input17_1: Float(1, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cpu) = aten::relu($input16_1) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/functional.py:1400:0
  $input18_1: Float(1, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution($input17_1, $21, $8, $13, $13, $13, $9, $1, $6, $9, $9, $10, $10) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/modules/conv.py:444:0
  $out1_1: Float(1, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cpu) = aten::batch_norm($input18_1, $19, $20, $20, $19, $9, $5, $4, $10) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/functional.py:2391:0
  $input19_1: Float(1, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution($input14_1, $22, $8, $3, $1, $13, $9, $1, $6, $9, $9, $10, $10) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/modules/conv.py:444:0
  $identity_1: Float(1, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cpu) = aten::batch_norm($input19_1, $19, $20, $20, $19, $9, $5, $4, $10) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/functional.py:2391:0
  $input20_1: Float(1, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cpu) = aten::add($out1_1, $identity_1, $6) # /Users/mlevental/dev_projects/pytorch_memory_planning/resnet.py:96:0
  $input21_1: Float(1, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cpu) = aten::relu($input20_1) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/functional.py:1400:0
  $input22_1: Float(1, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution($input21_1, $23, $8, $13, $13, $13, $9, $1, $6, $9, $9, $10, $10) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/modules/conv.py:444:0
  $input23_1: Float(1, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cpu) = aten::batch_norm($input22_1, $19, $20, $20, $19, $9, $5, $4, $10) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/functional.py:2391:0
  $input24_1: Float(1, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cpu) = aten::relu($input23_1) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/functional.py:1400:0
  $input25_1: Float(1, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution($input24_1, $24, $8, $13, $13, $13, $9, $1, $6, $9, $9, $10, $10) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/modules/conv.py:444:0
  $out2_1: Float(1, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cpu) = aten::batch_norm($input25_1, $19, $20, $20, $19, $9, $5, $4, $10) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/functional.py:2391:0
  $input26_1: Float(1, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cpu) = aten::add($out2_1, $input21_1, $6) # /Users/mlevental/dev_projects/pytorch_memory_planning/resnet.py:96:0
  $input27_1: Float(1, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cpu) = aten::relu($input26_1) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/functional.py:1400:0
  $input28_1: Float(1, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution($input27_1, $25, $8, $3, $13, $13, $9, $1, $6, $9, $9, $10, $10) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/modules/conv.py:444:0
  $input29_1: Float(1, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cpu) = aten::batch_norm($input28_1, $26, $27, $27, $26, $9, $5, $4, $10) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/functional.py:2391:0
  $input30_1: Float(1, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cpu) = aten::relu($input29_1) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/functional.py:1400:0
  $input31_1: Float(1, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution($input30_1, $28, $8, $13, $13, $13, $9, $1, $6, $9, $9, $10, $10) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/modules/conv.py:444:0
  $out3_1: Float(1, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cpu) = aten::batch_norm($input31_1, $26, $27, $27, $26, $9, $5, $4, $10) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/functional.py:2391:0
  $input32_1: Float(1, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution($input27_1, $29, $8, $3, $1, $13, $9, $1, $6, $9, $9, $10, $10) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/modules/conv.py:444:0
  $identity0_1: Float(1, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cpu) = aten::batch_norm($input32_1, $26, $27, $27, $26, $9, $5, $4, $10) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/functional.py:2391:0
  $input33_1: Float(1, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cpu) = aten::add($out3_1, $identity0_1, $6) # /Users/mlevental/dev_projects/pytorch_memory_planning/resnet.py:96:0
  $input34_1: Float(1, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cpu) = aten::relu($input33_1) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/functional.py:1400:0
  $input35_1: Float(1, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution($input34_1, $30, $8, $13, $13, $13, $9, $1, $6, $9, $9, $10, $10) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/modules/conv.py:444:0
  $input36_1: Float(1, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cpu) = aten::batch_norm($input35_1, $26, $27, $27, $26, $9, $5, $4, $10) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/functional.py:2391:0
  $input37_1: Float(1, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cpu) = aten::relu($input36_1) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/functional.py:1400:0
  $input38_1: Float(1, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution($input37_1, $31, $8, $13, $13, $13, $9, $1, $6, $9, $9, $10, $10) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/modules/conv.py:444:0
  $out4_1: Float(1, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cpu) = aten::batch_norm($input38_1, $26, $27, $27, $26, $9, $5, $4, $10) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/functional.py:2391:0
  $input39_1: Float(1, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cpu) = aten::add($out4_1, $input34_1, $6) # /Users/mlevental/dev_projects/pytorch_memory_planning/resnet.py:96:0
  $input40_1: Float(1, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cpu) = aten::relu($input39_1) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/functional.py:1400:0
  $input41_1: Float(1, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution($input40_1, $32, $8, $3, $13, $13, $9, $1, $6, $9, $9, $10, $10) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/modules/conv.py:444:0
  $input42_1: Float(1, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=0, device=cpu) = aten::batch_norm($input41_1, $33, $34, $34, $33, $9, $5, $4, $10) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/functional.py:2391:0
  $input43_1: Float(1, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=0, device=cpu) = aten::relu($input42_1) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/functional.py:1400:0
  $input44_1: Float(1, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution($input43_1, $35, $8, $13, $13, $13, $9, $1, $6, $9, $9, $10, $10) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/modules/conv.py:444:0
  $out5_1: Float(1, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=0, device=cpu) = aten::batch_norm($input44_1, $33, $34, $34, $33, $9, $5, $4, $10) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/functional.py:2391:0
  $input45_1: Float(1, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution($input40_1, $36, $8, $3, $1, $13, $9, $1, $6, $9, $9, $10, $10) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/modules/conv.py:444:0
  $identity1_1: Float(1, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=0, device=cpu) = aten::batch_norm($input45_1, $33, $34, $34, $33, $9, $5, $4, $10) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/functional.py:2391:0
  $input46_1: Float(1, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=0, device=cpu) = aten::add($out5_1, $identity1_1, $6) # /Users/mlevental/dev_projects/pytorch_memory_planning/resnet.py:96:0
  $input47_1: Float(1, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=0, device=cpu) = aten::relu($input46_1) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/functional.py:1400:0
  $input48_1: Float(1, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution($input47_1, $37, $8, $13, $13, $13, $9, $1, $6, $9, $9, $10, $10) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/modules/conv.py:444:0
  $input49_1: Float(1, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=0, device=cpu) = aten::batch_norm($input48_1, $33, $34, $34, $33, $9, $5, $4, $10) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/functional.py:2391:0
  $input50_1: Float(1, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=0, device=cpu) = aten::relu($input49_1) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/functional.py:1400:0
  $input51_1: Float(1, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution($input50_1, $38, $8, $13, $13, $13, $9, $1, $6, $9, $9, $10, $10) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/modules/conv.py:444:0
  $out6_1: Float(1, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=0, device=cpu) = aten::batch_norm($input51_1, $33, $34, $34, $33, $9, $5, $4, $10) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/functional.py:2391:0
  $input52_1: Float(1, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=0, device=cpu) = aten::add($out6_1, $input47_1, $6) # /Users/mlevental/dev_projects/pytorch_memory_planning/resnet.py:96:0
  $input53_1: Float(1, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=0, device=cpu) = aten::relu($input52_1) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/functional.py:1400:0
  $x0_1: Float(1, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d($input53_1, $13) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/functional.py:1234:0
  $input54_1: Float(1, 512, strides=[512, 1], requires_grad=0, device=cpu) = aten::flatten($x0_1, $6, $39) # /Users/mlevental/dev_projects/pytorch_memory_planning/resnet.py:272:0
  $110: Float(1, 1000, strides=[1000, 1], requires_grad=0, device=cpu) = aten::linear($input54_1, $40, $41) # /Users/mlevental/opt/miniconda3/envs/pytorch_dev_shape_inference/lib/python3.9/site-packages/torch/nn/functional.py:1951:0
  return: ($110)
constants:
  $1: [0, 0]
  $2: [3, 3]
  $3: [2, 2]
  $4: 1.0000000000000001e-05
  $5: 0.10000000000000001
  $6: 1
  $7: tensor_ptr_4513409856_2
  $8: None
  $9: False
  $10: True
  $11: tensor_ptr_4511708672_3
  $12: tensor_ptr_4511708928_4
  $13: [1, 1]
  $14: tensor_ptr_4513453568_5
  $15: tensor_ptr_4513621824_6
  $16: tensor_ptr_4513788352_7
  $17: tensor_ptr_4513955840_8
  $18: tensor_ptr_4514125888_9
  $19: tensor_ptr_4480589824_10
  $20: tensor_ptr_4498414080_11
  $21: tensor_ptr_4514483072_12
  $22: tensor_ptr_4515142528_13
  $23: tensor_ptr_4515177344_14
  $24: tensor_ptr_4515839552_15
  $25: tensor_ptr_4516498944_16
  $26: tensor_ptr_4509185024_17
  $27: tensor_ptr_4509186048_18
  $28: tensor_ptr_4517840064_19
  $29: tensor_ptr_4520466816_20
  $30: tensor_ptr_4520600064_21
  $31: tensor_ptr_4525122816_22
  $32: tensor_ptr_4527748224_23
  $33: tensor_ptr_4513214464_24
  $34: tensor_ptr_4513216512_25
  $35: tensor_ptr_4536140864_26
  $36: tensor_ptr_4523226944_27
  $37: tensor_ptr_4546629696_28
  $38: tensor_ptr_4557119488_29
  $39: -1
  $40: tensor_ptr_4567609856_30
  $41: tensor_ptr_4511916032_31
trace:
  - fn_name: aten::randn
    args: [[1, 3, 1, 1], None, None, cpu, None]
    args types: [GenericList, None, None, Device, None]
    op_id: 1
    schema: aten::randn(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None) -> (Tensor)
    calls: 
    - fn_name: aten::empty
      args: [[1, 3, 1, 1], None, None, cpu, None, None]
      args types: [GenericList, None, None, Device, None, None]
      op_id: 2
      schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
      calls: 
      - fn_name: allocate
        addr: '4571030976_167'
        size: 12
        op_id: 3
      returns: [tensor_ptr_4571030976_167]
      returns types: [Tensor]
    - fn_name: aten::normal_
      args: [tensor_ptr_4571030976_167, 0., 1., None]
      args types: [Tensor, Double, Double, None]
      op_id: 4
      schema: aten::normal_(Tensor(a!) self, float mean=0., float std=1., *, Generator? generator=None) -> (Tensor(a!))
      calls: 
      returns: [tensor_ptr_4571030976_167]
      returns types: [Tensor]
    returns: [tensor_ptr_4571030976_167]
    returns types: [Tensor]
  - fn_name: resnet18
    args: [tensor_ptr_4571030976_167]
    args types: [Tensor]
    op_id: 5
    schema: no schema
    calls: 
    - fn_name: aten::_convolution
      args: [tensor_ptr_4571030976_167, tensor_ptr_4513409856_2, None, [2, 2], [3, 3], [1, 1], False, [0, 0], 1, False, False, True, True]
      args types: [Tensor, Tensor, None, GenericList, GenericList, GenericList, Bool, GenericList, Int, Bool, Bool, Bool, Bool]
      args names: [$x_1, $7, $8, $3, $2, $13, $9, $1, $6, $9, $9, $10, $10]
      op_id: 6
      schema: aten::_convolution(Tensor input, Tensor weight, Tensor? bias, int[] stride, int[] padding, int[] dilation, bool transposed, int[] output_padding, int groups, bool benchmark, bool deterministic, bool cudnn_enabled, bool allow_tf32) -> (Tensor)
      calls: 
      - fn_name: aten::thnn_conv2d
        args: [tensor_ptr_4571030976_167, tensor_ptr_4513409856_2, [7, 7], null, [2, 2], [3, 3]]
        args types: [Tensor, Tensor, GenericList, Tensor, GenericList, GenericList]
        op_id: 7
        schema: aten::thnn_conv2d(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias=None, int[2] stride=[1, 1], int[2] padding=[0, 0]) -> (Tensor)
        calls: 
        - fn_name: aten::_slow_conv2d_forward
          args: [tensor_ptr_4571030976_167, tensor_ptr_4513409856_2, [7, 7], null, [2, 2], [3, 3]]
          args types: [Tensor, Tensor, GenericList, Tensor, GenericList, GenericList]
          op_id: 8
          schema: aten::_slow_conv2d_forward(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias, int[2] stride, int[2] padding) -> (Tensor output, Tensor finput)
          calls: 
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 9
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_254]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 10
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_255]
            returns types: [Tensor]
          - fn_name: aten::view
            args: [tensor_ptr_4513409856_2, [64, 147]]
            args types: [Tensor, GenericList]
            op_id: 11
            schema: aten::view(Tensor(a) self, int[] size) -> (Tensor(a))
            calls: 
            returns: [tensor_ptr_4513409856_2]
            returns types: [Tensor]
          - fn_name: aten::resize_
            args: [empty_tensor_255, [1, 147, 1], None]
            args types: [Tensor, GenericList, None]
            op_id: 12
            schema: aten::resize_(Tensor(a!) self, int[] size, *, int? memory_format=None) -> (Tensor(a!))
            calls: 
            - fn_name: allocate
              addr: '4511493376_168'
              size: 588
              op_id: 13
            returns: [tensor_ptr_4511493376_168]
            returns types: [Tensor]
          - fn_name: aten::resize_
            args: [empty_tensor_254, [1, 64, 1, 1], None]
            args types: [Tensor, GenericList, None]
            op_id: 14
            schema: aten::resize_(Tensor(a!) self, int[] size, *, int? memory_format=None) -> (Tensor(a!))
            calls: 
            - fn_name: allocate
              addr: '4587130112_169'
              size: 256
              op_id: 15
            returns: [tensor_ptr_4587130112_169]
            returns types: [Tensor]
          returns: [tensor_ptr_4587130112_169, tensor_ptr_4511493376_168]
          returns types: [Tensor, Tensor]
        - fn_name: free
          addr: '4511493376_168'
          size: 588
          op_id: 16
        returns: [tensor_ptr_4587130112_169]
        returns types: [Tensor]
      returns: [tensor_ptr_4587130112_169]
      returns types: [Tensor]
      returns names: [$input_1]
    - fn_name: aten::batch_norm
      args: [tensor_ptr_4587130112_169, tensor_ptr_4511708672_3, tensor_ptr_4511708928_4, tensor_ptr_4511708928_4, tensor_ptr_4511708672_3, False, 0.10000000000000001, 1.0000000000000001e-05, True]
      args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double, Bool]
      args names: [$input_1, $11, $12, $12, $11, $9, $5, $4, $10]
      op_id: 17
      schema: aten::batch_norm(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps, bool cudnn_enabled) -> (Tensor)
      calls: 
      - fn_name: aten::_batch_norm_impl_index
        args: [tensor_ptr_4587130112_169, tensor_ptr_4511708672_3, tensor_ptr_4511708928_4, tensor_ptr_4511708928_4, tensor_ptr_4511708672_3, False, 0.10000000000000001, 1.0000000000000001e-05, True]
        args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double, Bool]
        op_id: 18
        schema: aten::_batch_norm_impl_index(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps, bool cudnn_enabled) -> (Tensor, Tensor, Tensor, Tensor, int)
        calls: 
        - fn_name: aten::empty
          args: [[0], 0, 0, cpu, None, None]
          args types: [GenericList, Int, Int, Device, None, None]
          op_id: 19
          schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
          calls: 
          returns: [empty_tensor_256]
          returns types: [Tensor]
        - fn_name: aten::native_batch_norm
          args: [tensor_ptr_4587130112_169, tensor_ptr_4511708672_3, tensor_ptr_4511708928_4, tensor_ptr_4511708928_4, tensor_ptr_4511708672_3, False, 0.10000000000000001, 1.0000000000000001e-05]
          args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double]
          op_id: 20
          schema: aten::native_batch_norm(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps) -> (Tensor, Tensor, Tensor)
          calls: 
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 21
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_257]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 22
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_258]
            returns types: [Tensor]
          - fn_name: aten::empty_like
            args: [tensor_ptr_4587130112_169, None, None, None, None, 0]
            args types: [Tensor, None, None, None, None, Int]
            op_id: 23
            schema: aten::empty_like(Tensor self, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: aten::empty
              args: [[1, 64, 1, 1], 6, 0, cpu, None, 0]
              args types: [GenericList, Int, Int, Device, None, Int]
              op_id: 24
              schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
              calls: 
              - fn_name: allocate
                addr: '4587129856_170'
                size: 256
                op_id: 25
              returns: [tensor_ptr_4587129856_170]
              returns types: [Tensor]
            returns: [tensor_ptr_4587129856_170]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[64], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 26
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: allocate
              addr: '4587139072_171'
              size: 256
              op_id: 27
            returns: [tensor_ptr_4587139072_171]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[64], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 28
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: allocate
              addr: '4587139328_172'
              size: 256
              op_id: 29
            returns: [tensor_ptr_4587139328_172]
            returns types: [Tensor]
          - fn_name: free
            addr: '4587139328_172'
            size: 256
            op_id: 30
          - fn_name: free
            addr: '4587139072_171'
            size: 256
            op_id: 31
          returns: [tensor_ptr_4587129856_170, empty_tensor_257, empty_tensor_258]
          returns types: [Tensor, Tensor, Tensor]
        returns: [tensor_ptr_4587129856_170, empty_tensor_257, empty_tensor_258, empty_tensor_256, 0]
        returns types: [Tensor, Tensor, Tensor, Tensor, Int]
      returns: [tensor_ptr_4587129856_170]
      returns types: [Tensor]
      returns names: [$input0_1]
    - fn_name: free
      addr: '4587130112_169'
      size: 256
      op_id: 32
    - fn_name: aten::relu
      args: [tensor_ptr_4587129856_170]
      args types: [Tensor]
      args names: [$input0_1]
      op_id: 33
      schema: aten::relu(Tensor self) -> (Tensor)
      calls: 
      - fn_name: aten::clamp_min
        args: [tensor_ptr_4587129856_170, 0]
        args types: [Tensor, Int]
        op_id: 34
        schema: aten::clamp_min(Tensor self, Scalar min) -> (Tensor)
        calls: 
        - fn_name: aten::empty
          args: [[0], 6, 0, cpu, None, None]
          args types: [GenericList, Int, Int, Device, None, None]
          op_id: 35
          schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
          calls: 
          returns: [empty_tensor_262]
          returns types: [Tensor]
        - fn_name: aten::clamp_min
          args: [tensor_ptr_4587129856_170, 0, empty_tensor_262]
          args types: [Tensor, Int, Tensor]
          op_id: 36
          schema: aten::clamp_min.out(Tensor self, Scalar min, *, Tensor(a!) out) -> (Tensor(a!))
          calls: 
          - fn_name: allocate
            addr: '4587130112_173'
            size: 256
            op_id: 37
          returns: [tensor_ptr_4587130112_173]
          returns types: [Tensor]
        returns: [tensor_ptr_4587130112_173]
        returns types: [Tensor]
      returns: [tensor_ptr_4587130112_173]
      returns types: [Tensor]
      returns names: [$input1_1]
    - fn_name: free
      addr: '4587129856_170'
      size: 256
      op_id: 38
    - fn_name: aten::max_pool2d
      args: [tensor_ptr_4587130112_173, [3, 3], [2, 2], [1, 1], [1, 1], False]
      args types: [Tensor, GenericList, GenericList, GenericList, GenericList, Bool]
      args names: [$input1_1, $2, $3, $13, $13, $9]
      op_id: 39
      schema: aten::max_pool2d(Tensor self, int[2] kernel_size, int[2] stride=[], int[2] padding=[0, 0], int[2] dilation=[1, 1], bool ceil_mode=False) -> (Tensor)
      calls: 
      - fn_name: aten::max_pool2d_with_indices
        args: [tensor_ptr_4587130112_173, [3, 3], [2, 2], [1, 1], [1, 1], False]
        args types: [Tensor, GenericList, GenericList, GenericList, GenericList, Bool]
        op_id: 40
        schema: aten::max_pool2d_with_indices(Tensor self, int[2] kernel_size, int[2] stride=[], int[2] padding=[0, 0], int[2] dilation=[1, 1], bool ceil_mode=False) -> (Tensor, Tensor)
        calls: 
        - fn_name: allocate
          addr: '4587129856_174'
          size: 256
          op_id: 41
        - fn_name: allocate
          addr: '4502885888_175'
          size: 512
          op_id: 42
        returns: [tensor_ptr_4587129856_174, tensor_ptr_4502885888_175]
        returns types: [Tensor, Tensor]
      - fn_name: free
        addr: '4502885888_175'
        size: 512
        op_id: 43
      returns: [tensor_ptr_4587129856_174]
      returns types: [Tensor]
      returns names: [$input2_1]
    - fn_name: free
      addr: '4587130112_173'
      size: 256
      op_id: 44
    - fn_name: aten::_convolution
      args: [tensor_ptr_4587129856_174, tensor_ptr_4513453568_5, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1, False, False, True, True]
      args types: [Tensor, Tensor, None, GenericList, GenericList, GenericList, Bool, GenericList, Int, Bool, Bool, Bool, Bool]
      args names: [$input2_1, $14, $8, $13, $13, $13, $9, $1, $6, $9, $9, $10, $10]
      op_id: 45
      schema: aten::_convolution(Tensor input, Tensor weight, Tensor? bias, int[] stride, int[] padding, int[] dilation, bool transposed, int[] output_padding, int groups, bool benchmark, bool deterministic, bool cudnn_enabled, bool allow_tf32) -> (Tensor)
      calls: 
      - fn_name: aten::thnn_conv2d
        args: [tensor_ptr_4587129856_174, tensor_ptr_4513453568_5, [3, 3], null, [1, 1], [1, 1]]
        args types: [Tensor, Tensor, GenericList, Tensor, GenericList, GenericList]
        op_id: 46
        schema: aten::thnn_conv2d(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias=None, int[2] stride=[1, 1], int[2] padding=[0, 0]) -> (Tensor)
        calls: 
        - fn_name: aten::_slow_conv2d_forward
          args: [tensor_ptr_4587129856_174, tensor_ptr_4513453568_5, [3, 3], null, [1, 1], [1, 1]]
          args types: [Tensor, Tensor, GenericList, Tensor, GenericList, GenericList]
          op_id: 47
          schema: aten::_slow_conv2d_forward(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias, int[2] stride, int[2] padding) -> (Tensor output, Tensor finput)
          calls: 
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 48
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_265]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 49
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_266]
            returns types: [Tensor]
          - fn_name: aten::view
            args: [tensor_ptr_4513453568_5, [64, 576]]
            args types: [Tensor, GenericList]
            op_id: 50
            schema: aten::view(Tensor(a) self, int[] size) -> (Tensor(a))
            calls: 
            returns: [tensor_ptr_4513453568_5]
            returns types: [Tensor]
          - fn_name: aten::resize_
            args: [empty_tensor_266, [1, 576, 1], None]
            args types: [Tensor, GenericList, None]
            op_id: 51
            schema: aten::resize_(Tensor(a!) self, int[] size, *, int? memory_format=None) -> (Tensor(a!))
            calls: 
            - fn_name: allocate
              addr: '4588744704_176'
              size: 2304
              op_id: 52
            returns: [tensor_ptr_4588744704_176]
            returns types: [Tensor]
          - fn_name: aten::resize_
            args: [empty_tensor_265, [1, 64, 1, 1], None]
            args types: [Tensor, GenericList, None]
            op_id: 53
            schema: aten::resize_(Tensor(a!) self, int[] size, *, int? memory_format=None) -> (Tensor(a!))
            calls: 
            - fn_name: allocate
              addr: '4587130112_177'
              size: 256
              op_id: 54
            returns: [tensor_ptr_4587130112_177]
            returns types: [Tensor]
          returns: [tensor_ptr_4587130112_177, tensor_ptr_4588744704_176]
          returns types: [Tensor, Tensor]
        - fn_name: free
          addr: '4588744704_176'
          size: 2304
          op_id: 55
        returns: [tensor_ptr_4587130112_177]
        returns types: [Tensor]
      returns: [tensor_ptr_4587130112_177]
      returns types: [Tensor]
      returns names: [$input3_1]
    - fn_name: aten::batch_norm
      args: [tensor_ptr_4587130112_177, tensor_ptr_4511708672_3, tensor_ptr_4511708928_4, tensor_ptr_4511708928_4, tensor_ptr_4511708672_3, False, 0.10000000000000001, 1.0000000000000001e-05, True]
      args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double, Bool]
      args names: [$input3_1, $11, $12, $12, $11, $9, $5, $4, $10]
      op_id: 56
      schema: aten::batch_norm(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps, bool cudnn_enabled) -> (Tensor)
      calls: 
      - fn_name: aten::_batch_norm_impl_index
        args: [tensor_ptr_4587130112_177, tensor_ptr_4511708672_3, tensor_ptr_4511708928_4, tensor_ptr_4511708928_4, tensor_ptr_4511708672_3, False, 0.10000000000000001, 1.0000000000000001e-05, True]
        args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double, Bool]
        op_id: 57
        schema: aten::_batch_norm_impl_index(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps, bool cudnn_enabled) -> (Tensor, Tensor, Tensor, Tensor, int)
        calls: 
        - fn_name: aten::empty
          args: [[0], 0, 0, cpu, None, None]
          args types: [GenericList, Int, Int, Device, None, None]
          op_id: 58
          schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
          calls: 
          returns: [empty_tensor_267]
          returns types: [Tensor]
        - fn_name: aten::native_batch_norm
          args: [tensor_ptr_4587130112_177, tensor_ptr_4511708672_3, tensor_ptr_4511708928_4, tensor_ptr_4511708928_4, tensor_ptr_4511708672_3, False, 0.10000000000000001, 1.0000000000000001e-05]
          args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double]
          op_id: 59
          schema: aten::native_batch_norm(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps) -> (Tensor, Tensor, Tensor)
          calls: 
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 60
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_268]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 61
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_269]
            returns types: [Tensor]
          - fn_name: aten::empty_like
            args: [tensor_ptr_4587130112_177, None, None, None, None, 0]
            args types: [Tensor, None, None, None, None, Int]
            op_id: 62
            schema: aten::empty_like(Tensor self, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: aten::empty
              args: [[1, 64, 1, 1], 6, 0, cpu, None, 0]
              args types: [GenericList, Int, Int, Device, None, Int]
              op_id: 63
              schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
              calls: 
              - fn_name: allocate
                addr: '4587139072_178'
                size: 256
                op_id: 64
              returns: [tensor_ptr_4587139072_178]
              returns types: [Tensor]
            returns: [tensor_ptr_4587139072_178]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[64], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 65
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: allocate
              addr: '4587139328_179'
              size: 256
              op_id: 66
            returns: [tensor_ptr_4587139328_179]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[64], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 67
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: allocate
              addr: '4587139584_180'
              size: 256
              op_id: 68
            returns: [tensor_ptr_4587139584_180]
            returns types: [Tensor]
          - fn_name: free
            addr: '4587139584_180'
            size: 256
            op_id: 69
          - fn_name: free
            addr: '4587139328_179'
            size: 256
            op_id: 70
          returns: [tensor_ptr_4587139072_178, empty_tensor_268, empty_tensor_269]
          returns types: [Tensor, Tensor, Tensor]
        returns: [tensor_ptr_4587139072_178, empty_tensor_268, empty_tensor_269, empty_tensor_267, 0]
        returns types: [Tensor, Tensor, Tensor, Tensor, Int]
      returns: [tensor_ptr_4587139072_178]
      returns types: [Tensor]
      returns names: [$input4_1]
    - fn_name: free
      addr: '4587130112_177'
      size: 256
      op_id: 71
    - fn_name: aten::relu
      args: [tensor_ptr_4587139072_178]
      args types: [Tensor]
      args names: [$input4_1]
      op_id: 72
      schema: aten::relu(Tensor self) -> (Tensor)
      calls: 
      - fn_name: aten::clamp_min
        args: [tensor_ptr_4587139072_178, 0]
        args types: [Tensor, Int]
        op_id: 73
        schema: aten::clamp_min(Tensor self, Scalar min) -> (Tensor)
        calls: 
        - fn_name: aten::empty
          args: [[0], 6, 0, cpu, None, None]
          args types: [GenericList, Int, Int, Device, None, None]
          op_id: 74
          schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
          calls: 
          returns: [empty_tensor_273]
          returns types: [Tensor]
        - fn_name: aten::clamp_min
          args: [tensor_ptr_4587139072_178, 0, empty_tensor_273]
          args types: [Tensor, Int, Tensor]
          op_id: 75
          schema: aten::clamp_min.out(Tensor self, Scalar min, *, Tensor(a!) out) -> (Tensor(a!))
          calls: 
          - fn_name: allocate
            addr: '4587130112_181'
            size: 256
            op_id: 76
          returns: [tensor_ptr_4587130112_181]
          returns types: [Tensor]
        returns: [tensor_ptr_4587130112_181]
        returns types: [Tensor]
      returns: [tensor_ptr_4587130112_181]
      returns types: [Tensor]
      returns names: [$input5_1]
    - fn_name: free
      addr: '4587139072_178'
      size: 256
      op_id: 77
    - fn_name: aten::_convolution
      args: [tensor_ptr_4587130112_181, tensor_ptr_4513621824_6, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1, False, False, True, True]
      args types: [Tensor, Tensor, None, GenericList, GenericList, GenericList, Bool, GenericList, Int, Bool, Bool, Bool, Bool]
      args names: [$input5_1, $15, $8, $13, $13, $13, $9, $1, $6, $9, $9, $10, $10]
      op_id: 78
      schema: aten::_convolution(Tensor input, Tensor weight, Tensor? bias, int[] stride, int[] padding, int[] dilation, bool transposed, int[] output_padding, int groups, bool benchmark, bool deterministic, bool cudnn_enabled, bool allow_tf32) -> (Tensor)
      calls: 
      - fn_name: aten::thnn_conv2d
        args: [tensor_ptr_4587130112_181, tensor_ptr_4513621824_6, [3, 3], null, [1, 1], [1, 1]]
        args types: [Tensor, Tensor, GenericList, Tensor, GenericList, GenericList]
        op_id: 79
        schema: aten::thnn_conv2d(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias=None, int[2] stride=[1, 1], int[2] padding=[0, 0]) -> (Tensor)
        calls: 
        - fn_name: aten::_slow_conv2d_forward
          args: [tensor_ptr_4587130112_181, tensor_ptr_4513621824_6, [3, 3], null, [1, 1], [1, 1]]
          args types: [Tensor, Tensor, GenericList, Tensor, GenericList, GenericList]
          op_id: 80
          schema: aten::_slow_conv2d_forward(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias, int[2] stride, int[2] padding) -> (Tensor output, Tensor finput)
          calls: 
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 81
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_274]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 82
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_275]
            returns types: [Tensor]
          - fn_name: aten::view
            args: [tensor_ptr_4513621824_6, [64, 576]]
            args types: [Tensor, GenericList]
            op_id: 83
            schema: aten::view(Tensor(a) self, int[] size) -> (Tensor(a))
            calls: 
            returns: [tensor_ptr_4513621824_6]
            returns types: [Tensor]
          - fn_name: aten::resize_
            args: [empty_tensor_275, [1, 576, 1], None]
            args types: [Tensor, GenericList, None]
            op_id: 84
            schema: aten::resize_(Tensor(a!) self, int[] size, *, int? memory_format=None) -> (Tensor(a!))
            calls: 
            - fn_name: allocate
              addr: '4589154816_182'
              size: 2304
              op_id: 85
            returns: [tensor_ptr_4589154816_182]
            returns types: [Tensor]
          - fn_name: aten::resize_
            args: [empty_tensor_274, [1, 64, 1, 1], None]
            args types: [Tensor, GenericList, None]
            op_id: 86
            schema: aten::resize_(Tensor(a!) self, int[] size, *, int? memory_format=None) -> (Tensor(a!))
            calls: 
            - fn_name: allocate
              addr: '4587139072_183'
              size: 256
              op_id: 87
            returns: [tensor_ptr_4587139072_183]
            returns types: [Tensor]
          returns: [tensor_ptr_4587139072_183, tensor_ptr_4589154816_182]
          returns types: [Tensor, Tensor]
        - fn_name: free
          addr: '4589154816_182'
          size: 2304
          op_id: 88
        returns: [tensor_ptr_4587139072_183]
        returns types: [Tensor]
      returns: [tensor_ptr_4587139072_183]
      returns types: [Tensor]
      returns names: [$input6_1]
    - fn_name: free
      addr: '4587130112_181'
      size: 256
      op_id: 89
    - fn_name: aten::batch_norm
      args: [tensor_ptr_4587139072_183, tensor_ptr_4511708672_3, tensor_ptr_4511708928_4, tensor_ptr_4511708928_4, tensor_ptr_4511708672_3, False, 0.10000000000000001, 1.0000000000000001e-05, True]
      args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double, Bool]
      args names: [$input6_1, $11, $12, $12, $11, $9, $5, $4, $10]
      op_id: 90
      schema: aten::batch_norm(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps, bool cudnn_enabled) -> (Tensor)
      calls: 
      - fn_name: aten::_batch_norm_impl_index
        args: [tensor_ptr_4587139072_183, tensor_ptr_4511708672_3, tensor_ptr_4511708928_4, tensor_ptr_4511708928_4, tensor_ptr_4511708672_3, False, 0.10000000000000001, 1.0000000000000001e-05, True]
        args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double, Bool]
        op_id: 91
        schema: aten::_batch_norm_impl_index(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps, bool cudnn_enabled) -> (Tensor, Tensor, Tensor, Tensor, int)
        calls: 
        - fn_name: aten::empty
          args: [[0], 0, 0, cpu, None, None]
          args types: [GenericList, Int, Int, Device, None, None]
          op_id: 92
          schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
          calls: 
          returns: [empty_tensor_276]
          returns types: [Tensor]
        - fn_name: aten::native_batch_norm
          args: [tensor_ptr_4587139072_183, tensor_ptr_4511708672_3, tensor_ptr_4511708928_4, tensor_ptr_4511708928_4, tensor_ptr_4511708672_3, False, 0.10000000000000001, 1.0000000000000001e-05]
          args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double]
          op_id: 93
          schema: aten::native_batch_norm(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps) -> (Tensor, Tensor, Tensor)
          calls: 
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 94
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_277]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 95
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_278]
            returns types: [Tensor]
          - fn_name: aten::empty_like
            args: [tensor_ptr_4587139072_183, None, None, None, None, 0]
            args types: [Tensor, None, None, None, None, Int]
            op_id: 96
            schema: aten::empty_like(Tensor self, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: aten::empty
              args: [[1, 64, 1, 1], 6, 0, cpu, None, 0]
              args types: [GenericList, Int, Int, Device, None, Int]
              op_id: 97
              schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
              calls: 
              - fn_name: allocate
                addr: '4587130112_184'
                size: 256
                op_id: 98
              returns: [tensor_ptr_4587130112_184]
              returns types: [Tensor]
            returns: [tensor_ptr_4587130112_184]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[64], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 99
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: allocate
              addr: '4587139328_185'
              size: 256
              op_id: 100
            returns: [tensor_ptr_4587139328_185]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[64], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 101
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: allocate
              addr: '4587139584_186'
              size: 256
              op_id: 102
            returns: [tensor_ptr_4587139584_186]
            returns types: [Tensor]
          - fn_name: free
            addr: '4587139584_186'
            size: 256
            op_id: 103
          - fn_name: free
            addr: '4587139328_185'
            size: 256
            op_id: 104
          returns: [tensor_ptr_4587130112_184, empty_tensor_277, empty_tensor_278]
          returns types: [Tensor, Tensor, Tensor]
        returns: [tensor_ptr_4587130112_184, empty_tensor_277, empty_tensor_278, empty_tensor_276, 0]
        returns types: [Tensor, Tensor, Tensor, Tensor, Int]
      returns: [tensor_ptr_4587130112_184]
      returns types: [Tensor]
      returns names: [$out_1]
    - fn_name: free
      addr: '4587139072_183'
      size: 256
      op_id: 105
    - fn_name: aten::add
      args: [tensor_ptr_4587130112_184, tensor_ptr_4587129856_174, 1]
      args types: [Tensor, Tensor, Int]
      args names: [$out_1, $input2_1, $6]
      op_id: 106
      schema: aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> (Tensor)
      calls: 
      - fn_name: allocate
        addr: '4587139072_187'
        size: 256
        op_id: 107
      returns: [tensor_ptr_4587139072_187]
      returns types: [Tensor]
      returns names: [$input7_1]
    - fn_name: free
      addr: '4587129856_174'
      size: 256
      op_id: 108
    - fn_name: free
      addr: '4587130112_184'
      size: 256
      op_id: 109
    - fn_name: aten::relu
      args: [tensor_ptr_4587139072_187]
      args types: [Tensor]
      args names: [$input7_1]
      op_id: 110
      schema: aten::relu(Tensor self) -> (Tensor)
      calls: 
      - fn_name: aten::clamp_min
        args: [tensor_ptr_4587139072_187, 0]
        args types: [Tensor, Int]
        op_id: 111
        schema: aten::clamp_min(Tensor self, Scalar min) -> (Tensor)
        calls: 
        - fn_name: aten::empty
          args: [[0], 6, 0, cpu, None, None]
          args types: [GenericList, Int, Int, Device, None, None]
          op_id: 112
          schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
          calls: 
          returns: [empty_tensor_283]
          returns types: [Tensor]
        - fn_name: aten::clamp_min
          args: [tensor_ptr_4587139072_187, 0, empty_tensor_283]
          args types: [Tensor, Int, Tensor]
          op_id: 113
          schema: aten::clamp_min.out(Tensor self, Scalar min, *, Tensor(a!) out) -> (Tensor(a!))
          calls: 
          - fn_name: allocate
            addr: '4587130112_188'
            size: 256
            op_id: 114
          returns: [tensor_ptr_4587130112_188]
          returns types: [Tensor]
        returns: [tensor_ptr_4587130112_188]
        returns types: [Tensor]
      returns: [tensor_ptr_4587130112_188]
      returns types: [Tensor]
      returns names: [$input8_1]
    - fn_name: free
      addr: '4587139072_187'
      size: 256
      op_id: 115
    - fn_name: aten::_convolution
      args: [tensor_ptr_4587130112_188, tensor_ptr_4513788352_7, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1, False, False, True, True]
      args types: [Tensor, Tensor, None, GenericList, GenericList, GenericList, Bool, GenericList, Int, Bool, Bool, Bool, Bool]
      args names: [$input8_1, $16, $8, $13, $13, $13, $9, $1, $6, $9, $9, $10, $10]
      op_id: 116
      schema: aten::_convolution(Tensor input, Tensor weight, Tensor? bias, int[] stride, int[] padding, int[] dilation, bool transposed, int[] output_padding, int groups, bool benchmark, bool deterministic, bool cudnn_enabled, bool allow_tf32) -> (Tensor)
      calls: 
      - fn_name: aten::thnn_conv2d
        args: [tensor_ptr_4587130112_188, tensor_ptr_4513788352_7, [3, 3], null, [1, 1], [1, 1]]
        args types: [Tensor, Tensor, GenericList, Tensor, GenericList, GenericList]
        op_id: 117
        schema: aten::thnn_conv2d(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias=None, int[2] stride=[1, 1], int[2] padding=[0, 0]) -> (Tensor)
        calls: 
        - fn_name: aten::_slow_conv2d_forward
          args: [tensor_ptr_4587130112_188, tensor_ptr_4513788352_7, [3, 3], null, [1, 1], [1, 1]]
          args types: [Tensor, Tensor, GenericList, Tensor, GenericList, GenericList]
          op_id: 118
          schema: aten::_slow_conv2d_forward(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias, int[2] stride, int[2] padding) -> (Tensor output, Tensor finput)
          calls: 
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 119
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_284]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 120
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_285]
            returns types: [Tensor]
          - fn_name: aten::view
            args: [tensor_ptr_4513788352_7, [64, 576]]
            args types: [Tensor, GenericList]
            op_id: 121
            schema: aten::view(Tensor(a) self, int[] size) -> (Tensor(a))
            calls: 
            returns: [tensor_ptr_4513788352_7]
            returns types: [Tensor]
          - fn_name: aten::resize_
            args: [empty_tensor_285, [1, 576, 1], None]
            args types: [Tensor, GenericList, None]
            op_id: 122
            schema: aten::resize_(Tensor(a!) self, int[] size, *, int? memory_format=None) -> (Tensor(a!))
            calls: 
            - fn_name: allocate
              addr: '4589157376_189'
              size: 2304
              op_id: 123
            returns: [tensor_ptr_4589157376_189]
            returns types: [Tensor]
          - fn_name: aten::resize_
            args: [empty_tensor_284, [1, 64, 1, 1], None]
            args types: [Tensor, GenericList, None]
            op_id: 124
            schema: aten::resize_(Tensor(a!) self, int[] size, *, int? memory_format=None) -> (Tensor(a!))
            calls: 
            - fn_name: allocate
              addr: '4587139072_190'
              size: 256
              op_id: 125
            returns: [tensor_ptr_4587139072_190]
            returns types: [Tensor]
          returns: [tensor_ptr_4587139072_190, tensor_ptr_4589157376_189]
          returns types: [Tensor, Tensor]
        - fn_name: free
          addr: '4589157376_189'
          size: 2304
          op_id: 126
        returns: [tensor_ptr_4587139072_190]
        returns types: [Tensor]
      returns: [tensor_ptr_4587139072_190]
      returns types: [Tensor]
      returns names: [$input9_1]
    - fn_name: aten::batch_norm
      args: [tensor_ptr_4587139072_190, tensor_ptr_4511708672_3, tensor_ptr_4511708928_4, tensor_ptr_4511708928_4, tensor_ptr_4511708672_3, False, 0.10000000000000001, 1.0000000000000001e-05, True]
      args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double, Bool]
      args names: [$input9_1, $11, $12, $12, $11, $9, $5, $4, $10]
      op_id: 127
      schema: aten::batch_norm(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps, bool cudnn_enabled) -> (Tensor)
      calls: 
      - fn_name: aten::_batch_norm_impl_index
        args: [tensor_ptr_4587139072_190, tensor_ptr_4511708672_3, tensor_ptr_4511708928_4, tensor_ptr_4511708928_4, tensor_ptr_4511708672_3, False, 0.10000000000000001, 1.0000000000000001e-05, True]
        args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double, Bool]
        op_id: 128
        schema: aten::_batch_norm_impl_index(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps, bool cudnn_enabled) -> (Tensor, Tensor, Tensor, Tensor, int)
        calls: 
        - fn_name: aten::empty
          args: [[0], 0, 0, cpu, None, None]
          args types: [GenericList, Int, Int, Device, None, None]
          op_id: 129
          schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
          calls: 
          returns: [empty_tensor_286]
          returns types: [Tensor]
        - fn_name: aten::native_batch_norm
          args: [tensor_ptr_4587139072_190, tensor_ptr_4511708672_3, tensor_ptr_4511708928_4, tensor_ptr_4511708928_4, tensor_ptr_4511708672_3, False, 0.10000000000000001, 1.0000000000000001e-05]
          args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double]
          op_id: 130
          schema: aten::native_batch_norm(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps) -> (Tensor, Tensor, Tensor)
          calls: 
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 131
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_287]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 132
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_288]
            returns types: [Tensor]
          - fn_name: aten::empty_like
            args: [tensor_ptr_4587139072_190, None, None, None, None, 0]
            args types: [Tensor, None, None, None, None, Int]
            op_id: 133
            schema: aten::empty_like(Tensor self, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: aten::empty
              args: [[1, 64, 1, 1], 6, 0, cpu, None, 0]
              args types: [GenericList, Int, Int, Device, None, Int]
              op_id: 134
              schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
              calls: 
              - fn_name: allocate
                addr: '4587129856_191'
                size: 256
                op_id: 135
              returns: [tensor_ptr_4587129856_191]
              returns types: [Tensor]
            returns: [tensor_ptr_4587129856_191]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[64], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 136
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: allocate
              addr: '4587139328_192'
              size: 256
              op_id: 137
            returns: [tensor_ptr_4587139328_192]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[64], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 138
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: allocate
              addr: '4587139584_193'
              size: 256
              op_id: 139
            returns: [tensor_ptr_4587139584_193]
            returns types: [Tensor]
          - fn_name: free
            addr: '4587139584_193'
            size: 256
            op_id: 140
          - fn_name: free
            addr: '4587139328_192'
            size: 256
            op_id: 141
          returns: [tensor_ptr_4587129856_191, empty_tensor_287, empty_tensor_288]
          returns types: [Tensor, Tensor, Tensor]
        returns: [tensor_ptr_4587129856_191, empty_tensor_287, empty_tensor_288, empty_tensor_286, 0]
        returns types: [Tensor, Tensor, Tensor, Tensor, Int]
      returns: [tensor_ptr_4587129856_191]
      returns types: [Tensor]
      returns names: [$input10_1]
    - fn_name: free
      addr: '4587139072_190'
      size: 256
      op_id: 142
    - fn_name: aten::relu
      args: [tensor_ptr_4587129856_191]
      args types: [Tensor]
      args names: [$input10_1]
      op_id: 143
      schema: aten::relu(Tensor self) -> (Tensor)
      calls: 
      - fn_name: aten::clamp_min
        args: [tensor_ptr_4587129856_191, 0]
        args types: [Tensor, Int]
        op_id: 144
        schema: aten::clamp_min(Tensor self, Scalar min) -> (Tensor)
        calls: 
        - fn_name: aten::empty
          args: [[0], 6, 0, cpu, None, None]
          args types: [GenericList, Int, Int, Device, None, None]
          op_id: 145
          schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
          calls: 
          returns: [empty_tensor_292]
          returns types: [Tensor]
        - fn_name: aten::clamp_min
          args: [tensor_ptr_4587129856_191, 0, empty_tensor_292]
          args types: [Tensor, Int, Tensor]
          op_id: 146
          schema: aten::clamp_min.out(Tensor self, Scalar min, *, Tensor(a!) out) -> (Tensor(a!))
          calls: 
          - fn_name: allocate
            addr: '4587139072_194'
            size: 256
            op_id: 147
          returns: [tensor_ptr_4587139072_194]
          returns types: [Tensor]
        returns: [tensor_ptr_4587139072_194]
        returns types: [Tensor]
      returns: [tensor_ptr_4587139072_194]
      returns types: [Tensor]
      returns names: [$input11_1]
    - fn_name: free
      addr: '4587129856_191'
      size: 256
      op_id: 148
    - fn_name: aten::_convolution
      args: [tensor_ptr_4587139072_194, tensor_ptr_4513955840_8, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1, False, False, True, True]
      args types: [Tensor, Tensor, None, GenericList, GenericList, GenericList, Bool, GenericList, Int, Bool, Bool, Bool, Bool]
      args names: [$input11_1, $17, $8, $13, $13, $13, $9, $1, $6, $9, $9, $10, $10]
      op_id: 149
      schema: aten::_convolution(Tensor input, Tensor weight, Tensor? bias, int[] stride, int[] padding, int[] dilation, bool transposed, int[] output_padding, int groups, bool benchmark, bool deterministic, bool cudnn_enabled, bool allow_tf32) -> (Tensor)
      calls: 
      - fn_name: aten::thnn_conv2d
        args: [tensor_ptr_4587139072_194, tensor_ptr_4513955840_8, [3, 3], null, [1, 1], [1, 1]]
        args types: [Tensor, Tensor, GenericList, Tensor, GenericList, GenericList]
        op_id: 150
        schema: aten::thnn_conv2d(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias=None, int[2] stride=[1, 1], int[2] padding=[0, 0]) -> (Tensor)
        calls: 
        - fn_name: aten::_slow_conv2d_forward
          args: [tensor_ptr_4587139072_194, tensor_ptr_4513955840_8, [3, 3], null, [1, 1], [1, 1]]
          args types: [Tensor, Tensor, GenericList, Tensor, GenericList, GenericList]
          op_id: 151
          schema: aten::_slow_conv2d_forward(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias, int[2] stride, int[2] padding) -> (Tensor output, Tensor finput)
          calls: 
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 152
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_293]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 153
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_294]
            returns types: [Tensor]
          - fn_name: aten::view
            args: [tensor_ptr_4513955840_8, [64, 576]]
            args types: [Tensor, GenericList]
            op_id: 154
            schema: aten::view(Tensor(a) self, int[] size) -> (Tensor(a))
            calls: 
            returns: [tensor_ptr_4513955840_8]
            returns types: [Tensor]
          - fn_name: aten::resize_
            args: [empty_tensor_294, [1, 576, 1], None]
            args types: [Tensor, GenericList, None]
            op_id: 155
            schema: aten::resize_(Tensor(a!) self, int[] size, *, int? memory_format=None) -> (Tensor(a!))
            calls: 
            - fn_name: allocate
              addr: '4589154816_195'
              size: 2304
              op_id: 156
            returns: [tensor_ptr_4589154816_195]
            returns types: [Tensor]
          - fn_name: aten::resize_
            args: [empty_tensor_293, [1, 64, 1, 1], None]
            args types: [Tensor, GenericList, None]
            op_id: 157
            schema: aten::resize_(Tensor(a!) self, int[] size, *, int? memory_format=None) -> (Tensor(a!))
            calls: 
            - fn_name: allocate
              addr: '4587129856_196'
              size: 256
              op_id: 158
            returns: [tensor_ptr_4587129856_196]
            returns types: [Tensor]
          returns: [tensor_ptr_4587129856_196, tensor_ptr_4589154816_195]
          returns types: [Tensor, Tensor]
        - fn_name: free
          addr: '4589154816_195'
          size: 2304
          op_id: 159
        returns: [tensor_ptr_4587129856_196]
        returns types: [Tensor]
      returns: [tensor_ptr_4587129856_196]
      returns types: [Tensor]
      returns names: [$input12_1]
    - fn_name: free
      addr: '4587139072_194'
      size: 256
      op_id: 160
    - fn_name: aten::batch_norm
      args: [tensor_ptr_4587129856_196, tensor_ptr_4511708672_3, tensor_ptr_4511708928_4, tensor_ptr_4511708928_4, tensor_ptr_4511708672_3, False, 0.10000000000000001, 1.0000000000000001e-05, True]
      args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double, Bool]
      args names: [$input12_1, $11, $12, $12, $11, $9, $5, $4, $10]
      op_id: 161
      schema: aten::batch_norm(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps, bool cudnn_enabled) -> (Tensor)
      calls: 
      - fn_name: aten::_batch_norm_impl_index
        args: [tensor_ptr_4587129856_196, tensor_ptr_4511708672_3, tensor_ptr_4511708928_4, tensor_ptr_4511708928_4, tensor_ptr_4511708672_3, False, 0.10000000000000001, 1.0000000000000001e-05, True]
        args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double, Bool]
        op_id: 162
        schema: aten::_batch_norm_impl_index(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps, bool cudnn_enabled) -> (Tensor, Tensor, Tensor, Tensor, int)
        calls: 
        - fn_name: aten::empty
          args: [[0], 0, 0, cpu, None, None]
          args types: [GenericList, Int, Int, Device, None, None]
          op_id: 163
          schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
          calls: 
          returns: [empty_tensor_295]
          returns types: [Tensor]
        - fn_name: aten::native_batch_norm
          args: [tensor_ptr_4587129856_196, tensor_ptr_4511708672_3, tensor_ptr_4511708928_4, tensor_ptr_4511708928_4, tensor_ptr_4511708672_3, False, 0.10000000000000001, 1.0000000000000001e-05]
          args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double]
          op_id: 164
          schema: aten::native_batch_norm(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps) -> (Tensor, Tensor, Tensor)
          calls: 
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 165
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_296]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 166
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_297]
            returns types: [Tensor]
          - fn_name: aten::empty_like
            args: [tensor_ptr_4587129856_196, None, None, None, None, 0]
            args types: [Tensor, None, None, None, None, Int]
            op_id: 167
            schema: aten::empty_like(Tensor self, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: aten::empty
              args: [[1, 64, 1, 1], 6, 0, cpu, None, 0]
              args types: [GenericList, Int, Int, Device, None, Int]
              op_id: 168
              schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
              calls: 
              - fn_name: allocate
                addr: '4587139072_197'
                size: 256
                op_id: 169
              returns: [tensor_ptr_4587139072_197]
              returns types: [Tensor]
            returns: [tensor_ptr_4587139072_197]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[64], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 170
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: allocate
              addr: '4587139328_198'
              size: 256
              op_id: 171
            returns: [tensor_ptr_4587139328_198]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[64], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 172
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: allocate
              addr: '4587139584_199'
              size: 256
              op_id: 173
            returns: [tensor_ptr_4587139584_199]
            returns types: [Tensor]
          - fn_name: free
            addr: '4587139584_199'
            size: 256
            op_id: 174
          - fn_name: free
            addr: '4587139328_198'
            size: 256
            op_id: 175
          returns: [tensor_ptr_4587139072_197, empty_tensor_296, empty_tensor_297]
          returns types: [Tensor, Tensor, Tensor]
        returns: [tensor_ptr_4587139072_197, empty_tensor_296, empty_tensor_297, empty_tensor_295, 0]
        returns types: [Tensor, Tensor, Tensor, Tensor, Int]
      returns: [tensor_ptr_4587139072_197]
      returns types: [Tensor]
      returns names: [$out0_1]
    - fn_name: free
      addr: '4587129856_196'
      size: 256
      op_id: 176
    - fn_name: aten::add
      args: [tensor_ptr_4587139072_197, tensor_ptr_4587130112_188, 1]
      args types: [Tensor, Tensor, Int]
      args names: [$out0_1, $input8_1, $6]
      op_id: 177
      schema: aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> (Tensor)
      calls: 
      - fn_name: allocate
        addr: '4587129856_200'
        size: 256
        op_id: 178
      returns: [tensor_ptr_4587129856_200]
      returns types: [Tensor]
      returns names: [$input13_1]
    - fn_name: free
      addr: '4587130112_188'
      size: 256
      op_id: 179
    - fn_name: free
      addr: '4587139072_197'
      size: 256
      op_id: 180
    - fn_name: aten::relu
      args: [tensor_ptr_4587129856_200]
      args types: [Tensor]
      args names: [$input13_1]
      op_id: 181
      schema: aten::relu(Tensor self) -> (Tensor)
      calls: 
      - fn_name: aten::clamp_min
        args: [tensor_ptr_4587129856_200, 0]
        args types: [Tensor, Int]
        op_id: 182
        schema: aten::clamp_min(Tensor self, Scalar min) -> (Tensor)
        calls: 
        - fn_name: aten::empty
          args: [[0], 6, 0, cpu, None, None]
          args types: [GenericList, Int, Int, Device, None, None]
          op_id: 183
          schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
          calls: 
          returns: [empty_tensor_302]
          returns types: [Tensor]
        - fn_name: aten::clamp_min
          args: [tensor_ptr_4587129856_200, 0, empty_tensor_302]
          args types: [Tensor, Int, Tensor]
          op_id: 184
          schema: aten::clamp_min.out(Tensor self, Scalar min, *, Tensor(a!) out) -> (Tensor(a!))
          calls: 
          - fn_name: allocate
            addr: '4587139072_201'
            size: 256
            op_id: 185
          returns: [tensor_ptr_4587139072_201]
          returns types: [Tensor]
        returns: [tensor_ptr_4587139072_201]
        returns types: [Tensor]
      returns: [tensor_ptr_4587139072_201]
      returns types: [Tensor]
      returns names: [$input14_1]
    - fn_name: free
      addr: '4587129856_200'
      size: 256
      op_id: 186
    - fn_name: aten::_convolution
      args: [tensor_ptr_4587139072_201, tensor_ptr_4514125888_9, None, [2, 2], [1, 1], [1, 1], False, [0, 0], 1, False, False, True, True]
      args types: [Tensor, Tensor, None, GenericList, GenericList, GenericList, Bool, GenericList, Int, Bool, Bool, Bool, Bool]
      args names: [$input14_1, $18, $8, $3, $13, $13, $9, $1, $6, $9, $9, $10, $10]
      op_id: 187
      schema: aten::_convolution(Tensor input, Tensor weight, Tensor? bias, int[] stride, int[] padding, int[] dilation, bool transposed, int[] output_padding, int groups, bool benchmark, bool deterministic, bool cudnn_enabled, bool allow_tf32) -> (Tensor)
      calls: 
      - fn_name: aten::thnn_conv2d
        args: [tensor_ptr_4587139072_201, tensor_ptr_4514125888_9, [3, 3], null, [2, 2], [1, 1]]
        args types: [Tensor, Tensor, GenericList, Tensor, GenericList, GenericList]
        op_id: 188
        schema: aten::thnn_conv2d(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias=None, int[2] stride=[1, 1], int[2] padding=[0, 0]) -> (Tensor)
        calls: 
        - fn_name: aten::_slow_conv2d_forward
          args: [tensor_ptr_4587139072_201, tensor_ptr_4514125888_9, [3, 3], null, [2, 2], [1, 1]]
          args types: [Tensor, Tensor, GenericList, Tensor, GenericList, GenericList]
          op_id: 189
          schema: aten::_slow_conv2d_forward(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias, int[2] stride, int[2] padding) -> (Tensor output, Tensor finput)
          calls: 
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 190
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_303]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 191
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_304]
            returns types: [Tensor]
          - fn_name: aten::view
            args: [tensor_ptr_4514125888_9, [128, 576]]
            args types: [Tensor, GenericList]
            op_id: 192
            schema: aten::view(Tensor(a) self, int[] size) -> (Tensor(a))
            calls: 
            returns: [tensor_ptr_4514125888_9]
            returns types: [Tensor]
          - fn_name: aten::resize_
            args: [empty_tensor_304, [1, 576, 1], None]
            args types: [Tensor, GenericList, None]
            op_id: 193
            schema: aten::resize_(Tensor(a!) self, int[] size, *, int? memory_format=None) -> (Tensor(a!))
            calls: 
            - fn_name: allocate
              addr: '4589157376_202'
              size: 2304
              op_id: 194
            returns: [tensor_ptr_4589157376_202]
            returns types: [Tensor]
          - fn_name: aten::resize_
            args: [empty_tensor_303, [1, 128, 1, 1], None]
            args types: [Tensor, GenericList, None]
            op_id: 195
            schema: aten::resize_(Tensor(a!) self, int[] size, *, int? memory_format=None) -> (Tensor(a!))
            calls: 
            - fn_name: allocate
              addr: '4503111168_203'
              size: 512
              op_id: 196
            returns: [tensor_ptr_4503111168_203]
            returns types: [Tensor]
          returns: [tensor_ptr_4503111168_203, tensor_ptr_4589157376_202]
          returns types: [Tensor, Tensor]
        - fn_name: free
          addr: '4589157376_202'
          size: 2304
          op_id: 197
        returns: [tensor_ptr_4503111168_203]
        returns types: [Tensor]
      returns: [tensor_ptr_4503111168_203]
      returns types: [Tensor]
      returns names: [$input15_1]
    - fn_name: aten::batch_norm
      args: [tensor_ptr_4503111168_203, tensor_ptr_4480589824_10, tensor_ptr_4498414080_11, tensor_ptr_4498414080_11, tensor_ptr_4480589824_10, False, 0.10000000000000001, 1.0000000000000001e-05, True]
      args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double, Bool]
      args names: [$input15_1, $19, $20, $20, $19, $9, $5, $4, $10]
      op_id: 198
      schema: aten::batch_norm(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps, bool cudnn_enabled) -> (Tensor)
      calls: 
      - fn_name: aten::_batch_norm_impl_index
        args: [tensor_ptr_4503111168_203, tensor_ptr_4480589824_10, tensor_ptr_4498414080_11, tensor_ptr_4498414080_11, tensor_ptr_4480589824_10, False, 0.10000000000000001, 1.0000000000000001e-05, True]
        args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double, Bool]
        op_id: 199
        schema: aten::_batch_norm_impl_index(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps, bool cudnn_enabled) -> (Tensor, Tensor, Tensor, Tensor, int)
        calls: 
        - fn_name: aten::empty
          args: [[0], 0, 0, cpu, None, None]
          args types: [GenericList, Int, Int, Device, None, None]
          op_id: 200
          schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
          calls: 
          returns: [empty_tensor_305]
          returns types: [Tensor]
        - fn_name: aten::native_batch_norm
          args: [tensor_ptr_4503111168_203, tensor_ptr_4480589824_10, tensor_ptr_4498414080_11, tensor_ptr_4498414080_11, tensor_ptr_4480589824_10, False, 0.10000000000000001, 1.0000000000000001e-05]
          args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double]
          op_id: 201
          schema: aten::native_batch_norm(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps) -> (Tensor, Tensor, Tensor)
          calls: 
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 202
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_306]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 203
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_307]
            returns types: [Tensor]
          - fn_name: aten::empty_like
            args: [tensor_ptr_4503111168_203, None, None, None, None, 0]
            args types: [Tensor, None, None, None, None, Int]
            op_id: 204
            schema: aten::empty_like(Tensor self, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: aten::empty
              args: [[1, 128, 1, 1], 6, 0, cpu, None, 0]
              args types: [GenericList, Int, Int, Device, None, Int]
              op_id: 205
              schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
              calls: 
              - fn_name: allocate
                addr: '4502904832_204'
                size: 512
                op_id: 206
              returns: [tensor_ptr_4502904832_204]
              returns types: [Tensor]
            returns: [tensor_ptr_4502904832_204]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[128], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 207
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: allocate
              addr: '4502705152_205'
              size: 512
              op_id: 208
            returns: [tensor_ptr_4502705152_205]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[128], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 209
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: allocate
              addr: '4502602240_206'
              size: 512
              op_id: 210
            returns: [tensor_ptr_4502602240_206]
            returns types: [Tensor]
          - fn_name: free
            addr: '4502602240_206'
            size: 512
            op_id: 211
          - fn_name: free
            addr: '4502705152_205'
            size: 512
            op_id: 212
          returns: [tensor_ptr_4502904832_204, empty_tensor_306, empty_tensor_307]
          returns types: [Tensor, Tensor, Tensor]
        returns: [tensor_ptr_4502904832_204, empty_tensor_306, empty_tensor_307, empty_tensor_305, 0]
        returns types: [Tensor, Tensor, Tensor, Tensor, Int]
      returns: [tensor_ptr_4502904832_204]
      returns types: [Tensor]
      returns names: [$input16_1]
    - fn_name: free
      addr: '4503111168_203'
      size: 512
      op_id: 213
    - fn_name: aten::relu
      args: [tensor_ptr_4502904832_204]
      args types: [Tensor]
      args names: [$input16_1]
      op_id: 214
      schema: aten::relu(Tensor self) -> (Tensor)
      calls: 
      - fn_name: aten::clamp_min
        args: [tensor_ptr_4502904832_204, 0]
        args types: [Tensor, Int]
        op_id: 215
        schema: aten::clamp_min(Tensor self, Scalar min) -> (Tensor)
        calls: 
        - fn_name: aten::empty
          args: [[0], 6, 0, cpu, None, None]
          args types: [GenericList, Int, Int, Device, None, None]
          op_id: 216
          schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
          calls: 
          returns: [empty_tensor_311]
          returns types: [Tensor]
        - fn_name: aten::clamp_min
          args: [tensor_ptr_4502904832_204, 0, empty_tensor_311]
          args types: [Tensor, Int, Tensor]
          op_id: 217
          schema: aten::clamp_min.out(Tensor self, Scalar min, *, Tensor(a!) out) -> (Tensor(a!))
          calls: 
          - fn_name: allocate
            addr: '4503111168_207'
            size: 512
            op_id: 218
          returns: [tensor_ptr_4503111168_207]
          returns types: [Tensor]
        returns: [tensor_ptr_4503111168_207]
        returns types: [Tensor]
      returns: [tensor_ptr_4503111168_207]
      returns types: [Tensor]
      returns names: [$input17_1]
    - fn_name: free
      addr: '4502904832_204'
      size: 512
      op_id: 219
    - fn_name: aten::_convolution
      args: [tensor_ptr_4503111168_207, tensor_ptr_4514483072_12, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1, False, False, True, True]
      args types: [Tensor, Tensor, None, GenericList, GenericList, GenericList, Bool, GenericList, Int, Bool, Bool, Bool, Bool]
      args names: [$input17_1, $21, $8, $13, $13, $13, $9, $1, $6, $9, $9, $10, $10]
      op_id: 220
      schema: aten::_convolution(Tensor input, Tensor weight, Tensor? bias, int[] stride, int[] padding, int[] dilation, bool transposed, int[] output_padding, int groups, bool benchmark, bool deterministic, bool cudnn_enabled, bool allow_tf32) -> (Tensor)
      calls: 
      - fn_name: aten::thnn_conv2d
        args: [tensor_ptr_4503111168_207, tensor_ptr_4514483072_12, [3, 3], null, [1, 1], [1, 1]]
        args types: [Tensor, Tensor, GenericList, Tensor, GenericList, GenericList]
        op_id: 221
        schema: aten::thnn_conv2d(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias=None, int[2] stride=[1, 1], int[2] padding=[0, 0]) -> (Tensor)
        calls: 
        - fn_name: aten::_slow_conv2d_forward
          args: [tensor_ptr_4503111168_207, tensor_ptr_4514483072_12, [3, 3], null, [1, 1], [1, 1]]
          args types: [Tensor, Tensor, GenericList, Tensor, GenericList, GenericList]
          op_id: 222
          schema: aten::_slow_conv2d_forward(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias, int[2] stride, int[2] padding) -> (Tensor output, Tensor finput)
          calls: 
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 223
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_312]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 224
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_313]
            returns types: [Tensor]
          - fn_name: aten::view
            args: [tensor_ptr_4514483072_12, [128, 1152]]
            args types: [Tensor, GenericList]
            op_id: 225
            schema: aten::view(Tensor(a) self, int[] size) -> (Tensor(a))
            calls: 
            returns: [tensor_ptr_4514483072_12]
            returns types: [Tensor]
          - fn_name: aten::resize_
            args: [empty_tensor_313, [1, 1152, 1], None]
            args types: [Tensor, GenericList, None]
            op_id: 226
            schema: aten::resize_(Tensor(a!) self, int[] size, *, int? memory_format=None) -> (Tensor(a!))
            calls: 
            - fn_name: allocate
              addr: '4590220288_208'
              size: 4608
              op_id: 227
            returns: [tensor_ptr_4590220288_208]
            returns types: [Tensor]
          - fn_name: aten::resize_
            args: [empty_tensor_312, [1, 128, 1, 1], None]
            args types: [Tensor, GenericList, None]
            op_id: 228
            schema: aten::resize_(Tensor(a!) self, int[] size, *, int? memory_format=None) -> (Tensor(a!))
            calls: 
            - fn_name: allocate
              addr: '4502904832_209'
              size: 512
              op_id: 229
            returns: [tensor_ptr_4502904832_209]
            returns types: [Tensor]
          returns: [tensor_ptr_4502904832_209, tensor_ptr_4590220288_208]
          returns types: [Tensor, Tensor]
        - fn_name: free
          addr: '4590220288_208'
          size: 4608
          op_id: 230
        returns: [tensor_ptr_4502904832_209]
        returns types: [Tensor]
      returns: [tensor_ptr_4502904832_209]
      returns types: [Tensor]
      returns names: [$input18_1]
    - fn_name: free
      addr: '4503111168_207'
      size: 512
      op_id: 231
    - fn_name: aten::batch_norm
      args: [tensor_ptr_4502904832_209, tensor_ptr_4480589824_10, tensor_ptr_4498414080_11, tensor_ptr_4498414080_11, tensor_ptr_4480589824_10, False, 0.10000000000000001, 1.0000000000000001e-05, True]
      args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double, Bool]
      args names: [$input18_1, $19, $20, $20, $19, $9, $5, $4, $10]
      op_id: 232
      schema: aten::batch_norm(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps, bool cudnn_enabled) -> (Tensor)
      calls: 
      - fn_name: aten::_batch_norm_impl_index
        args: [tensor_ptr_4502904832_209, tensor_ptr_4480589824_10, tensor_ptr_4498414080_11, tensor_ptr_4498414080_11, tensor_ptr_4480589824_10, False, 0.10000000000000001, 1.0000000000000001e-05, True]
        args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double, Bool]
        op_id: 233
        schema: aten::_batch_norm_impl_index(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps, bool cudnn_enabled) -> (Tensor, Tensor, Tensor, Tensor, int)
        calls: 
        - fn_name: aten::empty
          args: [[0], 0, 0, cpu, None, None]
          args types: [GenericList, Int, Int, Device, None, None]
          op_id: 234
          schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
          calls: 
          returns: [empty_tensor_314]
          returns types: [Tensor]
        - fn_name: aten::native_batch_norm
          args: [tensor_ptr_4502904832_209, tensor_ptr_4480589824_10, tensor_ptr_4498414080_11, tensor_ptr_4498414080_11, tensor_ptr_4480589824_10, False, 0.10000000000000001, 1.0000000000000001e-05]
          args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double]
          op_id: 235
          schema: aten::native_batch_norm(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps) -> (Tensor, Tensor, Tensor)
          calls: 
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 236
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_315]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 237
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_316]
            returns types: [Tensor]
          - fn_name: aten::empty_like
            args: [tensor_ptr_4502904832_209, None, None, None, None, 0]
            args types: [Tensor, None, None, None, None, Int]
            op_id: 238
            schema: aten::empty_like(Tensor self, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: aten::empty
              args: [[1, 128, 1, 1], 6, 0, cpu, None, 0]
              args types: [GenericList, Int, Int, Device, None, Int]
              op_id: 239
              schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
              calls: 
              - fn_name: allocate
                addr: '4503014400_210'
                size: 512
                op_id: 240
              returns: [tensor_ptr_4503014400_210]
              returns types: [Tensor]
            returns: [tensor_ptr_4503014400_210]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[128], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 241
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: allocate
              addr: '4502610944_211'
              size: 512
              op_id: 242
            returns: [tensor_ptr_4502610944_211]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[128], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 243
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: allocate
              addr: '4502704640_212'
              size: 512
              op_id: 244
            returns: [tensor_ptr_4502704640_212]
            returns types: [Tensor]
          - fn_name: free
            addr: '4502704640_212'
            size: 512
            op_id: 245
          - fn_name: free
            addr: '4502610944_211'
            size: 512
            op_id: 246
          returns: [tensor_ptr_4503014400_210, empty_tensor_315, empty_tensor_316]
          returns types: [Tensor, Tensor, Tensor]
        returns: [tensor_ptr_4503014400_210, empty_tensor_315, empty_tensor_316, empty_tensor_314, 0]
        returns types: [Tensor, Tensor, Tensor, Tensor, Int]
      returns: [tensor_ptr_4503014400_210]
      returns types: [Tensor]
      returns names: [$out1_1]
    - fn_name: free
      addr: '4502904832_209'
      size: 512
      op_id: 247
    - fn_name: aten::_convolution
      args: [tensor_ptr_4587139072_201, tensor_ptr_4515142528_13, None, [2, 2], [0, 0], [1, 1], False, [0, 0], 1, False, False, True, True]
      args types: [Tensor, Tensor, None, GenericList, GenericList, GenericList, Bool, GenericList, Int, Bool, Bool, Bool, Bool]
      args names: [$input14_1, $22, $8, $3, $1, $13, $9, $1, $6, $9, $9, $10, $10]
      op_id: 248
      schema: aten::_convolution(Tensor input, Tensor weight, Tensor? bias, int[] stride, int[] padding, int[] dilation, bool transposed, int[] output_padding, int groups, bool benchmark, bool deterministic, bool cudnn_enabled, bool allow_tf32) -> (Tensor)
      calls: 
      - fn_name: aten::thnn_conv2d
        args: [tensor_ptr_4587139072_201, tensor_ptr_4515142528_13, [1, 1], null, [2, 2], [0, 0]]
        args types: [Tensor, Tensor, GenericList, Tensor, GenericList, GenericList]
        op_id: 249
        schema: aten::thnn_conv2d(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias=None, int[2] stride=[1, 1], int[2] padding=[0, 0]) -> (Tensor)
        calls: 
        - fn_name: aten::_slow_conv2d_forward
          args: [tensor_ptr_4587139072_201, tensor_ptr_4515142528_13, [1, 1], null, [2, 2], [0, 0]]
          args types: [Tensor, Tensor, GenericList, Tensor, GenericList, GenericList]
          op_id: 250
          schema: aten::_slow_conv2d_forward(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias, int[2] stride, int[2] padding) -> (Tensor output, Tensor finput)
          calls: 
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 251
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_320]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 252
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_321]
            returns types: [Tensor]
          - fn_name: aten::view
            args: [tensor_ptr_4515142528_13, [128, 64]]
            args types: [Tensor, GenericList]
            op_id: 253
            schema: aten::view(Tensor(a) self, int[] size) -> (Tensor(a))
            calls: 
            returns: [tensor_ptr_4515142528_13]
            returns types: [Tensor]
          - fn_name: aten::resize_
            args: [empty_tensor_321, [1, 64, 1], None]
            args types: [Tensor, GenericList, None]
            op_id: 254
            schema: aten::resize_(Tensor(a!) self, int[] size, *, int? memory_format=None) -> (Tensor(a!))
            calls: 
            - fn_name: allocate
              addr: '4587129856_213'
              size: 256
              op_id: 255
            returns: [tensor_ptr_4587129856_213]
            returns types: [Tensor]
          - fn_name: aten::resize_
            args: [empty_tensor_320, [1, 128, 1, 1], None]
            args types: [Tensor, GenericList, None]
            op_id: 256
            schema: aten::resize_(Tensor(a!) self, int[] size, *, int? memory_format=None) -> (Tensor(a!))
            calls: 
            - fn_name: allocate
              addr: '4502904832_214'
              size: 512
              op_id: 257
            returns: [tensor_ptr_4502904832_214]
            returns types: [Tensor]
          returns: [tensor_ptr_4502904832_214, tensor_ptr_4587129856_213]
          returns types: [Tensor, Tensor]
        - fn_name: free
          addr: '4587129856_213'
          size: 256
          op_id: 258
        returns: [tensor_ptr_4502904832_214]
        returns types: [Tensor]
      returns: [tensor_ptr_4502904832_214]
      returns types: [Tensor]
      returns names: [$input19_1]
    - fn_name: free
      addr: '4587139072_201'
      size: 256
      op_id: 259
    - fn_name: aten::batch_norm
      args: [tensor_ptr_4502904832_214, tensor_ptr_4480589824_10, tensor_ptr_4498414080_11, tensor_ptr_4498414080_11, tensor_ptr_4480589824_10, False, 0.10000000000000001, 1.0000000000000001e-05, True]
      args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double, Bool]
      args names: [$input19_1, $19, $20, $20, $19, $9, $5, $4, $10]
      op_id: 260
      schema: aten::batch_norm(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps, bool cudnn_enabled) -> (Tensor)
      calls: 
      - fn_name: aten::_batch_norm_impl_index
        args: [tensor_ptr_4502904832_214, tensor_ptr_4480589824_10, tensor_ptr_4498414080_11, tensor_ptr_4498414080_11, tensor_ptr_4480589824_10, False, 0.10000000000000001, 1.0000000000000001e-05, True]
        args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double, Bool]
        op_id: 261
        schema: aten::_batch_norm_impl_index(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps, bool cudnn_enabled) -> (Tensor, Tensor, Tensor, Tensor, int)
        calls: 
        - fn_name: aten::empty
          args: [[0], 0, 0, cpu, None, None]
          args types: [GenericList, Int, Int, Device, None, None]
          op_id: 262
          schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
          calls: 
          returns: [empty_tensor_322]
          returns types: [Tensor]
        - fn_name: aten::native_batch_norm
          args: [tensor_ptr_4502904832_214, tensor_ptr_4480589824_10, tensor_ptr_4498414080_11, tensor_ptr_4498414080_11, tensor_ptr_4480589824_10, False, 0.10000000000000001, 1.0000000000000001e-05]
          args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double]
          op_id: 263
          schema: aten::native_batch_norm(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps) -> (Tensor, Tensor, Tensor)
          calls: 
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 264
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_323]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 265
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_324]
            returns types: [Tensor]
          - fn_name: aten::empty_like
            args: [tensor_ptr_4502904832_214, None, None, None, None, 0]
            args types: [Tensor, None, None, None, None, Int]
            op_id: 266
            schema: aten::empty_like(Tensor self, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: aten::empty
              args: [[1, 128, 1, 1], 6, 0, cpu, None, 0]
              args types: [GenericList, Int, Int, Device, None, Int]
              op_id: 267
              schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
              calls: 
              - fn_name: allocate
                addr: '4502610944_215'
                size: 512
                op_id: 268
              returns: [tensor_ptr_4502610944_215]
              returns types: [Tensor]
            returns: [tensor_ptr_4502610944_215]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[128], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 269
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: allocate
              addr: '4507297792_216'
              size: 512
              op_id: 270
            returns: [tensor_ptr_4507297792_216]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[128], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 271
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: allocate
              addr: '4507299840_217'
              size: 512
              op_id: 272
            returns: [tensor_ptr_4507299840_217]
            returns types: [Tensor]
          - fn_name: free
            addr: '4507299840_217'
            size: 512
            op_id: 273
          - fn_name: free
            addr: '4507297792_216'
            size: 512
            op_id: 274
          returns: [tensor_ptr_4502610944_215, empty_tensor_323, empty_tensor_324]
          returns types: [Tensor, Tensor, Tensor]
        returns: [tensor_ptr_4502610944_215, empty_tensor_323, empty_tensor_324, empty_tensor_322, 0]
        returns types: [Tensor, Tensor, Tensor, Tensor, Int]
      returns: [tensor_ptr_4502610944_215]
      returns types: [Tensor]
      returns names: [$identity_1]
    - fn_name: free
      addr: '4502904832_214'
      size: 512
      op_id: 275
    - fn_name: aten::add
      args: [tensor_ptr_4503014400_210, tensor_ptr_4502610944_215, 1]
      args types: [Tensor, Tensor, Int]
      args names: [$out1_1, $identity_1, $6]
      op_id: 276
      schema: aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> (Tensor)
      calls: 
      - fn_name: allocate
        addr: '4502904832_218'
        size: 512
        op_id: 277
      returns: [tensor_ptr_4502904832_218]
      returns types: [Tensor]
      returns names: [$input20_1]
    - fn_name: free
      addr: '4502610944_215'
      size: 512
      op_id: 278
    - fn_name: free
      addr: '4503014400_210'
      size: 512
      op_id: 279
    - fn_name: aten::relu
      args: [tensor_ptr_4502904832_218]
      args types: [Tensor]
      args names: [$input20_1]
      op_id: 280
      schema: aten::relu(Tensor self) -> (Tensor)
      calls: 
      - fn_name: aten::clamp_min
        args: [tensor_ptr_4502904832_218, 0]
        args types: [Tensor, Int]
        op_id: 281
        schema: aten::clamp_min(Tensor self, Scalar min) -> (Tensor)
        calls: 
        - fn_name: aten::empty
          args: [[0], 6, 0, cpu, None, None]
          args types: [GenericList, Int, Int, Device, None, None]
          op_id: 282
          schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
          calls: 
          returns: [empty_tensor_329]
          returns types: [Tensor]
        - fn_name: aten::clamp_min
          args: [tensor_ptr_4502904832_218, 0, empty_tensor_329]
          args types: [Tensor, Int, Tensor]
          op_id: 283
          schema: aten::clamp_min.out(Tensor self, Scalar min, *, Tensor(a!) out) -> (Tensor(a!))
          calls: 
          - fn_name: allocate
            addr: '4503014400_219'
            size: 512
            op_id: 284
          returns: [tensor_ptr_4503014400_219]
          returns types: [Tensor]
        returns: [tensor_ptr_4503014400_219]
        returns types: [Tensor]
      returns: [tensor_ptr_4503014400_219]
      returns types: [Tensor]
      returns names: [$input21_1]
    - fn_name: free
      addr: '4502904832_218'
      size: 512
      op_id: 285
    - fn_name: aten::_convolution
      args: [tensor_ptr_4503014400_219, tensor_ptr_4515177344_14, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1, False, False, True, True]
      args types: [Tensor, Tensor, None, GenericList, GenericList, GenericList, Bool, GenericList, Int, Bool, Bool, Bool, Bool]
      args names: [$input21_1, $23, $8, $13, $13, $13, $9, $1, $6, $9, $9, $10, $10]
      op_id: 286
      schema: aten::_convolution(Tensor input, Tensor weight, Tensor? bias, int[] stride, int[] padding, int[] dilation, bool transposed, int[] output_padding, int groups, bool benchmark, bool deterministic, bool cudnn_enabled, bool allow_tf32) -> (Tensor)
      calls: 
      - fn_name: aten::thnn_conv2d
        args: [tensor_ptr_4503014400_219, tensor_ptr_4515177344_14, [3, 3], null, [1, 1], [1, 1]]
        args types: [Tensor, Tensor, GenericList, Tensor, GenericList, GenericList]
        op_id: 287
        schema: aten::thnn_conv2d(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias=None, int[2] stride=[1, 1], int[2] padding=[0, 0]) -> (Tensor)
        calls: 
        - fn_name: aten::_slow_conv2d_forward
          args: [tensor_ptr_4503014400_219, tensor_ptr_4515177344_14, [3, 3], null, [1, 1], [1, 1]]
          args types: [Tensor, Tensor, GenericList, Tensor, GenericList, GenericList]
          op_id: 288
          schema: aten::_slow_conv2d_forward(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias, int[2] stride, int[2] padding) -> (Tensor output, Tensor finput)
          calls: 
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 289
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_330]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 290
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_331]
            returns types: [Tensor]
          - fn_name: aten::view
            args: [tensor_ptr_4515177344_14, [128, 1152]]
            args types: [Tensor, GenericList]
            op_id: 291
            schema: aten::view(Tensor(a) self, int[] size) -> (Tensor(a))
            calls: 
            returns: [tensor_ptr_4515177344_14]
            returns types: [Tensor]
          - fn_name: aten::resize_
            args: [empty_tensor_331, [1, 1152, 1], None]
            args types: [Tensor, GenericList, None]
            op_id: 292
            schema: aten::resize_(Tensor(a!) self, int[] size, *, int? memory_format=None) -> (Tensor(a!))
            calls: 
            - fn_name: allocate
              addr: '4590220288_220'
              size: 4608
              op_id: 293
            returns: [tensor_ptr_4590220288_220]
            returns types: [Tensor]
          - fn_name: aten::resize_
            args: [empty_tensor_330, [1, 128, 1, 1], None]
            args types: [Tensor, GenericList, None]
            op_id: 294
            schema: aten::resize_(Tensor(a!) self, int[] size, *, int? memory_format=None) -> (Tensor(a!))
            calls: 
            - fn_name: allocate
              addr: '4502904832_221'
              size: 512
              op_id: 295
            returns: [tensor_ptr_4502904832_221]
            returns types: [Tensor]
          returns: [tensor_ptr_4502904832_221, tensor_ptr_4590220288_220]
          returns types: [Tensor, Tensor]
        - fn_name: free
          addr: '4590220288_220'
          size: 4608
          op_id: 296
        returns: [tensor_ptr_4502904832_221]
        returns types: [Tensor]
      returns: [tensor_ptr_4502904832_221]
      returns types: [Tensor]
      returns names: [$input22_1]
    - fn_name: aten::batch_norm
      args: [tensor_ptr_4502904832_221, tensor_ptr_4480589824_10, tensor_ptr_4498414080_11, tensor_ptr_4498414080_11, tensor_ptr_4480589824_10, False, 0.10000000000000001, 1.0000000000000001e-05, True]
      args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double, Bool]
      args names: [$input22_1, $19, $20, $20, $19, $9, $5, $4, $10]
      op_id: 297
      schema: aten::batch_norm(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps, bool cudnn_enabled) -> (Tensor)
      calls: 
      - fn_name: aten::_batch_norm_impl_index
        args: [tensor_ptr_4502904832_221, tensor_ptr_4480589824_10, tensor_ptr_4498414080_11, tensor_ptr_4498414080_11, tensor_ptr_4480589824_10, False, 0.10000000000000001, 1.0000000000000001e-05, True]
        args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double, Bool]
        op_id: 298
        schema: aten::_batch_norm_impl_index(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps, bool cudnn_enabled) -> (Tensor, Tensor, Tensor, Tensor, int)
        calls: 
        - fn_name: aten::empty
          args: [[0], 0, 0, cpu, None, None]
          args types: [GenericList, Int, Int, Device, None, None]
          op_id: 299
          schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
          calls: 
          returns: [empty_tensor_332]
          returns types: [Tensor]
        - fn_name: aten::native_batch_norm
          args: [tensor_ptr_4502904832_221, tensor_ptr_4480589824_10, tensor_ptr_4498414080_11, tensor_ptr_4498414080_11, tensor_ptr_4480589824_10, False, 0.10000000000000001, 1.0000000000000001e-05]
          args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double]
          op_id: 300
          schema: aten::native_batch_norm(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps) -> (Tensor, Tensor, Tensor)
          calls: 
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 301
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_333]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 302
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_334]
            returns types: [Tensor]
          - fn_name: aten::empty_like
            args: [tensor_ptr_4502904832_221, None, None, None, None, 0]
            args types: [Tensor, None, None, None, None, Int]
            op_id: 303
            schema: aten::empty_like(Tensor self, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: aten::empty
              args: [[1, 128, 1, 1], 6, 0, cpu, None, 0]
              args types: [GenericList, Int, Int, Device, None, Int]
              op_id: 304
              schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
              calls: 
              - fn_name: allocate
                addr: '4503111168_222'
                size: 512
                op_id: 305
              returns: [tensor_ptr_4503111168_222]
              returns types: [Tensor]
            returns: [tensor_ptr_4503111168_222]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[128], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 306
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: allocate
              addr: '4507365376_223'
              size: 512
              op_id: 307
            returns: [tensor_ptr_4507365376_223]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[128], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 308
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: allocate
              addr: '4507365888_224'
              size: 512
              op_id: 309
            returns: [tensor_ptr_4507365888_224]
            returns types: [Tensor]
          - fn_name: free
            addr: '4507365888_224'
            size: 512
            op_id: 310
          - fn_name: free
            addr: '4507365376_223'
            size: 512
            op_id: 311
          returns: [tensor_ptr_4503111168_222, empty_tensor_333, empty_tensor_334]
          returns types: [Tensor, Tensor, Tensor]
        returns: [tensor_ptr_4503111168_222, empty_tensor_333, empty_tensor_334, empty_tensor_332, 0]
        returns types: [Tensor, Tensor, Tensor, Tensor, Int]
      returns: [tensor_ptr_4503111168_222]
      returns types: [Tensor]
      returns names: [$input23_1]
    - fn_name: free
      addr: '4502904832_221'
      size: 512
      op_id: 312
    - fn_name: aten::relu
      args: [tensor_ptr_4503111168_222]
      args types: [Tensor]
      args names: [$input23_1]
      op_id: 313
      schema: aten::relu(Tensor self) -> (Tensor)
      calls: 
      - fn_name: aten::clamp_min
        args: [tensor_ptr_4503111168_222, 0]
        args types: [Tensor, Int]
        op_id: 314
        schema: aten::clamp_min(Tensor self, Scalar min) -> (Tensor)
        calls: 
        - fn_name: aten::empty
          args: [[0], 6, 0, cpu, None, None]
          args types: [GenericList, Int, Int, Device, None, None]
          op_id: 315
          schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
          calls: 
          returns: [empty_tensor_338]
          returns types: [Tensor]
        - fn_name: aten::clamp_min
          args: [tensor_ptr_4503111168_222, 0, empty_tensor_338]
          args types: [Tensor, Int, Tensor]
          op_id: 316
          schema: aten::clamp_min.out(Tensor self, Scalar min, *, Tensor(a!) out) -> (Tensor(a!))
          calls: 
          - fn_name: allocate
            addr: '4507254784_225'
            size: 512
            op_id: 317
          returns: [tensor_ptr_4507254784_225]
          returns types: [Tensor]
        returns: [tensor_ptr_4507254784_225]
        returns types: [Tensor]
      returns: [tensor_ptr_4507254784_225]
      returns types: [Tensor]
      returns names: [$input24_1]
    - fn_name: free
      addr: '4503111168_222'
      size: 512
      op_id: 318
    - fn_name: aten::_convolution
      args: [tensor_ptr_4507254784_225, tensor_ptr_4515839552_15, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1, False, False, True, True]
      args types: [Tensor, Tensor, None, GenericList, GenericList, GenericList, Bool, GenericList, Int, Bool, Bool, Bool, Bool]
      args names: [$input24_1, $24, $8, $13, $13, $13, $9, $1, $6, $9, $9, $10, $10]
      op_id: 319
      schema: aten::_convolution(Tensor input, Tensor weight, Tensor? bias, int[] stride, int[] padding, int[] dilation, bool transposed, int[] output_padding, int groups, bool benchmark, bool deterministic, bool cudnn_enabled, bool allow_tf32) -> (Tensor)
      calls: 
      - fn_name: aten::thnn_conv2d
        args: [tensor_ptr_4507254784_225, tensor_ptr_4515839552_15, [3, 3], null, [1, 1], [1, 1]]
        args types: [Tensor, Tensor, GenericList, Tensor, GenericList, GenericList]
        op_id: 320
        schema: aten::thnn_conv2d(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias=None, int[2] stride=[1, 1], int[2] padding=[0, 0]) -> (Tensor)
        calls: 
        - fn_name: aten::_slow_conv2d_forward
          args: [tensor_ptr_4507254784_225, tensor_ptr_4515839552_15, [3, 3], null, [1, 1], [1, 1]]
          args types: [Tensor, Tensor, GenericList, Tensor, GenericList, GenericList]
          op_id: 321
          schema: aten::_slow_conv2d_forward(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias, int[2] stride, int[2] padding) -> (Tensor output, Tensor finput)
          calls: 
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 322
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_339]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 323
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_340]
            returns types: [Tensor]
          - fn_name: aten::view
            args: [tensor_ptr_4515839552_15, [128, 1152]]
            args types: [Tensor, GenericList]
            op_id: 324
            schema: aten::view(Tensor(a) self, int[] size) -> (Tensor(a))
            calls: 
            returns: [tensor_ptr_4515839552_15]
            returns types: [Tensor]
          - fn_name: aten::resize_
            args: [empty_tensor_340, [1, 1152, 1], None]
            args types: [Tensor, GenericList, None]
            op_id: 325
            schema: aten::resize_(Tensor(a!) self, int[] size, *, int? memory_format=None) -> (Tensor(a!))
            calls: 
            - fn_name: allocate
              addr: '4590220288_226'
              size: 4608
              op_id: 326
            returns: [tensor_ptr_4590220288_226]
            returns types: [Tensor]
          - fn_name: aten::resize_
            args: [empty_tensor_339, [1, 128, 1, 1], None]
            args types: [Tensor, GenericList, None]
            op_id: 327
            schema: aten::resize_(Tensor(a!) self, int[] size, *, int? memory_format=None) -> (Tensor(a!))
            calls: 
            - fn_name: allocate
              addr: '4503111168_227'
              size: 512
              op_id: 328
            returns: [tensor_ptr_4503111168_227]
            returns types: [Tensor]
          returns: [tensor_ptr_4503111168_227, tensor_ptr_4590220288_226]
          returns types: [Tensor, Tensor]
        - fn_name: free
          addr: '4590220288_226'
          size: 4608
          op_id: 329
        returns: [tensor_ptr_4503111168_227]
        returns types: [Tensor]
      returns: [tensor_ptr_4503111168_227]
      returns types: [Tensor]
      returns names: [$input25_1]
    - fn_name: free
      addr: '4507254784_225'
      size: 512
      op_id: 330
    - fn_name: aten::batch_norm
      args: [tensor_ptr_4503111168_227, tensor_ptr_4480589824_10, tensor_ptr_4498414080_11, tensor_ptr_4498414080_11, tensor_ptr_4480589824_10, False, 0.10000000000000001, 1.0000000000000001e-05, True]
      args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double, Bool]
      args names: [$input25_1, $19, $20, $20, $19, $9, $5, $4, $10]
      op_id: 331
      schema: aten::batch_norm(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps, bool cudnn_enabled) -> (Tensor)
      calls: 
      - fn_name: aten::_batch_norm_impl_index
        args: [tensor_ptr_4503111168_227, tensor_ptr_4480589824_10, tensor_ptr_4498414080_11, tensor_ptr_4498414080_11, tensor_ptr_4480589824_10, False, 0.10000000000000001, 1.0000000000000001e-05, True]
        args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double, Bool]
        op_id: 332
        schema: aten::_batch_norm_impl_index(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps, bool cudnn_enabled) -> (Tensor, Tensor, Tensor, Tensor, int)
        calls: 
        - fn_name: aten::empty
          args: [[0], 0, 0, cpu, None, None]
          args types: [GenericList, Int, Int, Device, None, None]
          op_id: 333
          schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
          calls: 
          returns: [empty_tensor_341]
          returns types: [Tensor]
        - fn_name: aten::native_batch_norm
          args: [tensor_ptr_4503111168_227, tensor_ptr_4480589824_10, tensor_ptr_4498414080_11, tensor_ptr_4498414080_11, tensor_ptr_4480589824_10, False, 0.10000000000000001, 1.0000000000000001e-05]
          args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double]
          op_id: 334
          schema: aten::native_batch_norm(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps) -> (Tensor, Tensor, Tensor)
          calls: 
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 335
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_342]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 336
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_343]
            returns types: [Tensor]
          - fn_name: aten::empty_like
            args: [tensor_ptr_4503111168_227, None, None, None, None, 0]
            args types: [Tensor, None, None, None, None, Int]
            op_id: 337
            schema: aten::empty_like(Tensor self, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: aten::empty
              args: [[1, 128, 1, 1], 6, 0, cpu, None, 0]
              args types: [GenericList, Int, Int, Device, None, Int]
              op_id: 338
              schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
              calls: 
              - fn_name: allocate
                addr: '4507175936_228'
                size: 512
                op_id: 339
              returns: [tensor_ptr_4507175936_228]
              returns types: [Tensor]
            returns: [tensor_ptr_4507175936_228]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[128], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 340
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: allocate
              addr: '4503844352_229'
              size: 512
              op_id: 341
            returns: [tensor_ptr_4503844352_229]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[128], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 342
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: allocate
              addr: '4503843840_230'
              size: 512
              op_id: 343
            returns: [tensor_ptr_4503843840_230]
            returns types: [Tensor]
          - fn_name: free
            addr: '4503843840_230'
            size: 512
            op_id: 344
          - fn_name: free
            addr: '4503844352_229'
            size: 512
            op_id: 345
          returns: [tensor_ptr_4507175936_228, empty_tensor_342, empty_tensor_343]
          returns types: [Tensor, Tensor, Tensor]
        returns: [tensor_ptr_4507175936_228, empty_tensor_342, empty_tensor_343, empty_tensor_341, 0]
        returns types: [Tensor, Tensor, Tensor, Tensor, Int]
      returns: [tensor_ptr_4507175936_228]
      returns types: [Tensor]
      returns names: [$out2_1]
    - fn_name: free
      addr: '4503111168_227'
      size: 512
      op_id: 346
    - fn_name: aten::add
      args: [tensor_ptr_4507175936_228, tensor_ptr_4503014400_219, 1]
      args types: [Tensor, Tensor, Int]
      args names: [$out2_1, $input21_1, $6]
      op_id: 347
      schema: aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> (Tensor)
      calls: 
      - fn_name: allocate
        addr: '4503111168_231'
        size: 512
        op_id: 348
      returns: [tensor_ptr_4503111168_231]
      returns types: [Tensor]
      returns names: [$input26_1]
    - fn_name: free
      addr: '4503014400_219'
      size: 512
      op_id: 349
    - fn_name: free
      addr: '4507175936_228'
      size: 512
      op_id: 350
    - fn_name: aten::relu
      args: [tensor_ptr_4503111168_231]
      args types: [Tensor]
      args names: [$input26_1]
      op_id: 351
      schema: aten::relu(Tensor self) -> (Tensor)
      calls: 
      - fn_name: aten::clamp_min
        args: [tensor_ptr_4503111168_231, 0]
        args types: [Tensor, Int]
        op_id: 352
        schema: aten::clamp_min(Tensor self, Scalar min) -> (Tensor)
        calls: 
        - fn_name: aten::empty
          args: [[0], 6, 0, cpu, None, None]
          args types: [GenericList, Int, Int, Device, None, None]
          op_id: 353
          schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
          calls: 
          returns: [empty_tensor_348]
          returns types: [Tensor]
        - fn_name: aten::clamp_min
          args: [tensor_ptr_4503111168_231, 0, empty_tensor_348]
          args types: [Tensor, Int, Tensor]
          op_id: 354
          schema: aten::clamp_min.out(Tensor self, Scalar min, *, Tensor(a!) out) -> (Tensor(a!))
          calls: 
          - fn_name: allocate
            addr: '4507175936_232'
            size: 512
            op_id: 355
          returns: [tensor_ptr_4507175936_232]
          returns types: [Tensor]
        returns: [tensor_ptr_4507175936_232]
        returns types: [Tensor]
      returns: [tensor_ptr_4507175936_232]
      returns types: [Tensor]
      returns names: [$input27_1]
    - fn_name: free
      addr: '4503111168_231'
      size: 512
      op_id: 356
    - fn_name: aten::_convolution
      args: [tensor_ptr_4507175936_232, tensor_ptr_4516498944_16, None, [2, 2], [1, 1], [1, 1], False, [0, 0], 1, False, False, True, True]
      args types: [Tensor, Tensor, None, GenericList, GenericList, GenericList, Bool, GenericList, Int, Bool, Bool, Bool, Bool]
      args names: [$input27_1, $25, $8, $3, $13, $13, $9, $1, $6, $9, $9, $10, $10]
      op_id: 357
      schema: aten::_convolution(Tensor input, Tensor weight, Tensor? bias, int[] stride, int[] padding, int[] dilation, bool transposed, int[] output_padding, int groups, bool benchmark, bool deterministic, bool cudnn_enabled, bool allow_tf32) -> (Tensor)
      calls: 
      - fn_name: aten::thnn_conv2d
        args: [tensor_ptr_4507175936_232, tensor_ptr_4516498944_16, [3, 3], null, [2, 2], [1, 1]]
        args types: [Tensor, Tensor, GenericList, Tensor, GenericList, GenericList]
        op_id: 358
        schema: aten::thnn_conv2d(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias=None, int[2] stride=[1, 1], int[2] padding=[0, 0]) -> (Tensor)
        calls: 
        - fn_name: aten::_slow_conv2d_forward
          args: [tensor_ptr_4507175936_232, tensor_ptr_4516498944_16, [3, 3], null, [2, 2], [1, 1]]
          args types: [Tensor, Tensor, GenericList, Tensor, GenericList, GenericList]
          op_id: 359
          schema: aten::_slow_conv2d_forward(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias, int[2] stride, int[2] padding) -> (Tensor output, Tensor finput)
          calls: 
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 360
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_349]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 361
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_350]
            returns types: [Tensor]
          - fn_name: aten::view
            args: [tensor_ptr_4516498944_16, [256, 1152]]
            args types: [Tensor, GenericList]
            op_id: 362
            schema: aten::view(Tensor(a) self, int[] size) -> (Tensor(a))
            calls: 
            returns: [tensor_ptr_4516498944_16]
            returns types: [Tensor]
          - fn_name: aten::resize_
            args: [empty_tensor_350, [1, 1152, 1], None]
            args types: [Tensor, GenericList, None]
            op_id: 363
            schema: aten::resize_(Tensor(a!) self, int[] size, *, int? memory_format=None) -> (Tensor(a!))
            calls: 
            - fn_name: allocate
              addr: '4590220288_233'
              size: 4608
              op_id: 364
            returns: [tensor_ptr_4590220288_233]
            returns types: [Tensor]
          - fn_name: aten::resize_
            args: [empty_tensor_349, [1, 256, 1, 1], None]
            args types: [Tensor, GenericList, None]
            op_id: 365
            schema: aten::resize_(Tensor(a!) self, int[] size, *, int? memory_format=None) -> (Tensor(a!))
            calls: 
            - fn_name: allocate
              addr: '4511935488_234'
              size: 1024
              op_id: 366
            returns: [tensor_ptr_4511935488_234]
            returns types: [Tensor]
          returns: [tensor_ptr_4511935488_234, tensor_ptr_4590220288_233]
          returns types: [Tensor, Tensor]
        - fn_name: free
          addr: '4590220288_233'
          size: 4608
          op_id: 367
        returns: [tensor_ptr_4511935488_234]
        returns types: [Tensor]
      returns: [tensor_ptr_4511935488_234]
      returns types: [Tensor]
      returns names: [$input28_1]
    - fn_name: aten::batch_norm
      args: [tensor_ptr_4511935488_234, tensor_ptr_4509185024_17, tensor_ptr_4509186048_18, tensor_ptr_4509186048_18, tensor_ptr_4509185024_17, False, 0.10000000000000001, 1.0000000000000001e-05, True]
      args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double, Bool]
      args names: [$input28_1, $26, $27, $27, $26, $9, $5, $4, $10]
      op_id: 368
      schema: aten::batch_norm(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps, bool cudnn_enabled) -> (Tensor)
      calls: 
      - fn_name: aten::_batch_norm_impl_index
        args: [tensor_ptr_4511935488_234, tensor_ptr_4509185024_17, tensor_ptr_4509186048_18, tensor_ptr_4509186048_18, tensor_ptr_4509185024_17, False, 0.10000000000000001, 1.0000000000000001e-05, True]
        args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double, Bool]
        op_id: 369
        schema: aten::_batch_norm_impl_index(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps, bool cudnn_enabled) -> (Tensor, Tensor, Tensor, Tensor, int)
        calls: 
        - fn_name: aten::empty
          args: [[0], 0, 0, cpu, None, None]
          args types: [GenericList, Int, Int, Device, None, None]
          op_id: 370
          schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
          calls: 
          returns: [empty_tensor_351]
          returns types: [Tensor]
        - fn_name: aten::native_batch_norm
          args: [tensor_ptr_4511935488_234, tensor_ptr_4509185024_17, tensor_ptr_4509186048_18, tensor_ptr_4509186048_18, tensor_ptr_4509185024_17, False, 0.10000000000000001, 1.0000000000000001e-05]
          args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double]
          op_id: 371
          schema: aten::native_batch_norm(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps) -> (Tensor, Tensor, Tensor)
          calls: 
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 372
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_352]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 373
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_353]
            returns types: [Tensor]
          - fn_name: aten::empty_like
            args: [tensor_ptr_4511935488_234, None, None, None, None, 0]
            args types: [Tensor, None, None, None, None, Int]
            op_id: 374
            schema: aten::empty_like(Tensor self, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: aten::empty
              args: [[1, 256, 1, 1], 6, 0, cpu, None, 0]
              args types: [GenericList, Int, Int, Device, None, Int]
              op_id: 375
              schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
              calls: 
              - fn_name: allocate
                addr: '4511934464_235'
                size: 1024
                op_id: 376
              returns: [tensor_ptr_4511934464_235]
              returns types: [Tensor]
            returns: [tensor_ptr_4511934464_235]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[256], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 377
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: allocate
              addr: '4533656576_236'
              size: 1024
              op_id: 378
            returns: [tensor_ptr_4533656576_236]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[256], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 379
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: allocate
              addr: '4571009024_237'
              size: 1024
              op_id: 380
            returns: [tensor_ptr_4571009024_237]
            returns types: [Tensor]
          - fn_name: free
            addr: '4571009024_237'
            size: 1024
            op_id: 381
          - fn_name: free
            addr: '4533656576_236'
            size: 1024
            op_id: 382
          returns: [tensor_ptr_4511934464_235, empty_tensor_352, empty_tensor_353]
          returns types: [Tensor, Tensor, Tensor]
        returns: [tensor_ptr_4511934464_235, empty_tensor_352, empty_tensor_353, empty_tensor_351, 0]
        returns types: [Tensor, Tensor, Tensor, Tensor, Int]
      returns: [tensor_ptr_4511934464_235]
      returns types: [Tensor]
      returns names: [$input29_1]
    - fn_name: free
      addr: '4511935488_234'
      size: 1024
      op_id: 383
    - fn_name: aten::relu
      args: [tensor_ptr_4511934464_235]
      args types: [Tensor]
      args names: [$input29_1]
      op_id: 384
      schema: aten::relu(Tensor self) -> (Tensor)
      calls: 
      - fn_name: aten::clamp_min
        args: [tensor_ptr_4511934464_235, 0]
        args types: [Tensor, Int]
        op_id: 385
        schema: aten::clamp_min(Tensor self, Scalar min) -> (Tensor)
        calls: 
        - fn_name: aten::empty
          args: [[0], 6, 0, cpu, None, None]
          args types: [GenericList, Int, Int, Device, None, None]
          op_id: 386
          schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
          calls: 
          returns: [empty_tensor_357]
          returns types: [Tensor]
        - fn_name: aten::clamp_min
          args: [tensor_ptr_4511934464_235, 0, empty_tensor_357]
          args types: [Tensor, Int, Tensor]
          op_id: 387
          schema: aten::clamp_min.out(Tensor self, Scalar min, *, Tensor(a!) out) -> (Tensor(a!))
          calls: 
          - fn_name: allocate
            addr: '4511935488_238'
            size: 1024
            op_id: 388
          returns: [tensor_ptr_4511935488_238]
          returns types: [Tensor]
        returns: [tensor_ptr_4511935488_238]
        returns types: [Tensor]
      returns: [tensor_ptr_4511935488_238]
      returns types: [Tensor]
      returns names: [$input30_1]
    - fn_name: free
      addr: '4511934464_235'
      size: 1024
      op_id: 389
    - fn_name: aten::_convolution
      args: [tensor_ptr_4511935488_238, tensor_ptr_4517840064_19, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1, False, False, True, True]
      args types: [Tensor, Tensor, None, GenericList, GenericList, GenericList, Bool, GenericList, Int, Bool, Bool, Bool, Bool]
      args names: [$input30_1, $28, $8, $13, $13, $13, $9, $1, $6, $9, $9, $10, $10]
      op_id: 390
      schema: aten::_convolution(Tensor input, Tensor weight, Tensor? bias, int[] stride, int[] padding, int[] dilation, bool transposed, int[] output_padding, int groups, bool benchmark, bool deterministic, bool cudnn_enabled, bool allow_tf32) -> (Tensor)
      calls: 
      - fn_name: aten::thnn_conv2d
        args: [tensor_ptr_4511935488_238, tensor_ptr_4517840064_19, [3, 3], null, [1, 1], [1, 1]]
        args types: [Tensor, Tensor, GenericList, Tensor, GenericList, GenericList]
        op_id: 391
        schema: aten::thnn_conv2d(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias=None, int[2] stride=[1, 1], int[2] padding=[0, 0]) -> (Tensor)
        calls: 
        - fn_name: aten::_slow_conv2d_forward
          args: [tensor_ptr_4511935488_238, tensor_ptr_4517840064_19, [3, 3], null, [1, 1], [1, 1]]
          args types: [Tensor, Tensor, GenericList, Tensor, GenericList, GenericList]
          op_id: 392
          schema: aten::_slow_conv2d_forward(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias, int[2] stride, int[2] padding) -> (Tensor output, Tensor finput)
          calls: 
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 393
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_358]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 394
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_359]
            returns types: [Tensor]
          - fn_name: aten::view
            args: [tensor_ptr_4517840064_19, [256, 2304]]
            args types: [Tensor, GenericList]
            op_id: 395
            schema: aten::view(Tensor(a) self, int[] size) -> (Tensor(a))
            calls: 
            returns: [tensor_ptr_4517840064_19]
            returns types: [Tensor]
          - fn_name: aten::resize_
            args: [empty_tensor_359, [1, 2304, 1], None]
            args types: [Tensor, GenericList, None]
            op_id: 396
            schema: aten::resize_(Tensor(a!) self, int[] size, *, int? memory_format=None) -> (Tensor(a!))
            calls: 
            - fn_name: allocate
              addr: '4589889536_239'
              size: 9216
              op_id: 397
            returns: [tensor_ptr_4589889536_239]
            returns types: [Tensor]
          - fn_name: aten::resize_
            args: [empty_tensor_358, [1, 256, 1, 1], None]
            args types: [Tensor, GenericList, None]
            op_id: 398
            schema: aten::resize_(Tensor(a!) self, int[] size, *, int? memory_format=None) -> (Tensor(a!))
            calls: 
            - fn_name: allocate
              addr: '4511934464_240'
              size: 1024
              op_id: 399
            returns: [tensor_ptr_4511934464_240]
            returns types: [Tensor]
          returns: [tensor_ptr_4511934464_240, tensor_ptr_4589889536_239]
          returns types: [Tensor, Tensor]
        - fn_name: free
          addr: '4589889536_239'
          size: 9216
          op_id: 400
        returns: [tensor_ptr_4511934464_240]
        returns types: [Tensor]
      returns: [tensor_ptr_4511934464_240]
      returns types: [Tensor]
      returns names: [$input31_1]
    - fn_name: free
      addr: '4511935488_238'
      size: 1024
      op_id: 401
    - fn_name: aten::batch_norm
      args: [tensor_ptr_4511934464_240, tensor_ptr_4509185024_17, tensor_ptr_4509186048_18, tensor_ptr_4509186048_18, tensor_ptr_4509185024_17, False, 0.10000000000000001, 1.0000000000000001e-05, True]
      args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double, Bool]
      args names: [$input31_1, $26, $27, $27, $26, $9, $5, $4, $10]
      op_id: 402
      schema: aten::batch_norm(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps, bool cudnn_enabled) -> (Tensor)
      calls: 
      - fn_name: aten::_batch_norm_impl_index
        args: [tensor_ptr_4511934464_240, tensor_ptr_4509185024_17, tensor_ptr_4509186048_18, tensor_ptr_4509186048_18, tensor_ptr_4509185024_17, False, 0.10000000000000001, 1.0000000000000001e-05, True]
        args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double, Bool]
        op_id: 403
        schema: aten::_batch_norm_impl_index(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps, bool cudnn_enabled) -> (Tensor, Tensor, Tensor, Tensor, int)
        calls: 
        - fn_name: aten::empty
          args: [[0], 0, 0, cpu, None, None]
          args types: [GenericList, Int, Int, Device, None, None]
          op_id: 404
          schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
          calls: 
          returns: [empty_tensor_360]
          returns types: [Tensor]
        - fn_name: aten::native_batch_norm
          args: [tensor_ptr_4511934464_240, tensor_ptr_4509185024_17, tensor_ptr_4509186048_18, tensor_ptr_4509186048_18, tensor_ptr_4509185024_17, False, 0.10000000000000001, 1.0000000000000001e-05]
          args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double]
          op_id: 405
          schema: aten::native_batch_norm(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps) -> (Tensor, Tensor, Tensor)
          calls: 
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 406
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_361]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 407
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_362]
            returns types: [Tensor]
          - fn_name: aten::empty_like
            args: [tensor_ptr_4511934464_240, None, None, None, None, 0]
            args types: [Tensor, None, None, None, None, Int]
            op_id: 408
            schema: aten::empty_like(Tensor self, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: aten::empty
              args: [[1, 256, 1, 1], 6, 0, cpu, None, 0]
              args types: [GenericList, Int, Int, Device, None, Int]
              op_id: 409
              schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
              calls: 
              - fn_name: allocate
                addr: '4511935488_241'
                size: 1024
                op_id: 410
              returns: [tensor_ptr_4511935488_241]
              returns types: [Tensor]
            returns: [tensor_ptr_4511935488_241]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[256], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 411
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: allocate
              addr: '4533656576_242'
              size: 1024
              op_id: 412
            returns: [tensor_ptr_4533656576_242]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[256], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 413
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: allocate
              addr: '4571009024_243'
              size: 1024
              op_id: 414
            returns: [tensor_ptr_4571009024_243]
            returns types: [Tensor]
          - fn_name: free
            addr: '4571009024_243'
            size: 1024
            op_id: 415
          - fn_name: free
            addr: '4533656576_242'
            size: 1024
            op_id: 416
          returns: [tensor_ptr_4511935488_241, empty_tensor_361, empty_tensor_362]
          returns types: [Tensor, Tensor, Tensor]
        returns: [tensor_ptr_4511935488_241, empty_tensor_361, empty_tensor_362, empty_tensor_360, 0]
        returns types: [Tensor, Tensor, Tensor, Tensor, Int]
      returns: [tensor_ptr_4511935488_241]
      returns types: [Tensor]
      returns names: [$out3_1]
    - fn_name: free
      addr: '4511934464_240'
      size: 1024
      op_id: 417
    - fn_name: aten::_convolution
      args: [tensor_ptr_4507175936_232, tensor_ptr_4520466816_20, None, [2, 2], [0, 0], [1, 1], False, [0, 0], 1, False, False, True, True]
      args types: [Tensor, Tensor, None, GenericList, GenericList, GenericList, Bool, GenericList, Int, Bool, Bool, Bool, Bool]
      args names: [$input27_1, $29, $8, $3, $1, $13, $9, $1, $6, $9, $9, $10, $10]
      op_id: 418
      schema: aten::_convolution(Tensor input, Tensor weight, Tensor? bias, int[] stride, int[] padding, int[] dilation, bool transposed, int[] output_padding, int groups, bool benchmark, bool deterministic, bool cudnn_enabled, bool allow_tf32) -> (Tensor)
      calls: 
      - fn_name: aten::thnn_conv2d
        args: [tensor_ptr_4507175936_232, tensor_ptr_4520466816_20, [1, 1], null, [2, 2], [0, 0]]
        args types: [Tensor, Tensor, GenericList, Tensor, GenericList, GenericList]
        op_id: 419
        schema: aten::thnn_conv2d(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias=None, int[2] stride=[1, 1], int[2] padding=[0, 0]) -> (Tensor)
        calls: 
        - fn_name: aten::_slow_conv2d_forward
          args: [tensor_ptr_4507175936_232, tensor_ptr_4520466816_20, [1, 1], null, [2, 2], [0, 0]]
          args types: [Tensor, Tensor, GenericList, Tensor, GenericList, GenericList]
          op_id: 420
          schema: aten::_slow_conv2d_forward(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias, int[2] stride, int[2] padding) -> (Tensor output, Tensor finput)
          calls: 
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 421
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_366]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 422
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_367]
            returns types: [Tensor]
          - fn_name: aten::view
            args: [tensor_ptr_4520466816_20, [256, 128]]
            args types: [Tensor, GenericList]
            op_id: 423
            schema: aten::view(Tensor(a) self, int[] size) -> (Tensor(a))
            calls: 
            returns: [tensor_ptr_4520466816_20]
            returns types: [Tensor]
          - fn_name: aten::resize_
            args: [empty_tensor_367, [1, 128, 1], None]
            args types: [Tensor, GenericList, None]
            op_id: 424
            schema: aten::resize_(Tensor(a!) self, int[] size, *, int? memory_format=None) -> (Tensor(a!))
            calls: 
            - fn_name: allocate
              addr: '4503111168_244'
              size: 512
              op_id: 425
            returns: [tensor_ptr_4503111168_244]
            returns types: [Tensor]
          - fn_name: aten::resize_
            args: [empty_tensor_366, [1, 256, 1, 1], None]
            args types: [Tensor, GenericList, None]
            op_id: 426
            schema: aten::resize_(Tensor(a!) self, int[] size, *, int? memory_format=None) -> (Tensor(a!))
            calls: 
            - fn_name: allocate
              addr: '4511934464_245'
              size: 1024
              op_id: 427
            returns: [tensor_ptr_4511934464_245]
            returns types: [Tensor]
          returns: [tensor_ptr_4511934464_245, tensor_ptr_4503111168_244]
          returns types: [Tensor, Tensor]
        - fn_name: free
          addr: '4503111168_244'
          size: 512
          op_id: 428
        returns: [tensor_ptr_4511934464_245]
        returns types: [Tensor]
      returns: [tensor_ptr_4511934464_245]
      returns types: [Tensor]
      returns names: [$input32_1]
    - fn_name: free
      addr: '4507175936_232'
      size: 512
      op_id: 429
    - fn_name: aten::batch_norm
      args: [tensor_ptr_4511934464_245, tensor_ptr_4509185024_17, tensor_ptr_4509186048_18, tensor_ptr_4509186048_18, tensor_ptr_4509185024_17, False, 0.10000000000000001, 1.0000000000000001e-05, True]
      args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double, Bool]
      args names: [$input32_1, $26, $27, $27, $26, $9, $5, $4, $10]
      op_id: 430
      schema: aten::batch_norm(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps, bool cudnn_enabled) -> (Tensor)
      calls: 
      - fn_name: aten::_batch_norm_impl_index
        args: [tensor_ptr_4511934464_245, tensor_ptr_4509185024_17, tensor_ptr_4509186048_18, tensor_ptr_4509186048_18, tensor_ptr_4509185024_17, False, 0.10000000000000001, 1.0000000000000001e-05, True]
        args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double, Bool]
        op_id: 431
        schema: aten::_batch_norm_impl_index(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps, bool cudnn_enabled) -> (Tensor, Tensor, Tensor, Tensor, int)
        calls: 
        - fn_name: aten::empty
          args: [[0], 0, 0, cpu, None, None]
          args types: [GenericList, Int, Int, Device, None, None]
          op_id: 432
          schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
          calls: 
          returns: [empty_tensor_368]
          returns types: [Tensor]
        - fn_name: aten::native_batch_norm
          args: [tensor_ptr_4511934464_245, tensor_ptr_4509185024_17, tensor_ptr_4509186048_18, tensor_ptr_4509186048_18, tensor_ptr_4509185024_17, False, 0.10000000000000001, 1.0000000000000001e-05]
          args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double]
          op_id: 433
          schema: aten::native_batch_norm(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps) -> (Tensor, Tensor, Tensor)
          calls: 
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 434
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_369]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 435
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_370]
            returns types: [Tensor]
          - fn_name: aten::empty_like
            args: [tensor_ptr_4511934464_245, None, None, None, None, 0]
            args types: [Tensor, None, None, None, None, Int]
            op_id: 436
            schema: aten::empty_like(Tensor self, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: aten::empty
              args: [[1, 256, 1, 1], 6, 0, cpu, None, 0]
              args types: [GenericList, Int, Int, Device, None, Int]
              op_id: 437
              schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
              calls: 
              - fn_name: allocate
                addr: '4533656576_246'
                size: 1024
                op_id: 438
              returns: [tensor_ptr_4533656576_246]
              returns types: [Tensor]
            returns: [tensor_ptr_4533656576_246]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[256], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 439
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: allocate
              addr: '4571009024_247'
              size: 1024
              op_id: 440
            returns: [tensor_ptr_4571009024_247]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[256], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 441
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: allocate
              addr: '4571010048_248'
              size: 1024
              op_id: 442
            returns: [tensor_ptr_4571010048_248]
            returns types: [Tensor]
          - fn_name: free
            addr: '4571010048_248'
            size: 1024
            op_id: 443
          - fn_name: free
            addr: '4571009024_247'
            size: 1024
            op_id: 444
          returns: [tensor_ptr_4533656576_246, empty_tensor_369, empty_tensor_370]
          returns types: [Tensor, Tensor, Tensor]
        returns: [tensor_ptr_4533656576_246, empty_tensor_369, empty_tensor_370, empty_tensor_368, 0]
        returns types: [Tensor, Tensor, Tensor, Tensor, Int]
      returns: [tensor_ptr_4533656576_246]
      returns types: [Tensor]
      returns names: [$identity0_1]
    - fn_name: free
      addr: '4511934464_245'
      size: 1024
      op_id: 445
    - fn_name: aten::add
      args: [tensor_ptr_4511935488_241, tensor_ptr_4533656576_246, 1]
      args types: [Tensor, Tensor, Int]
      args names: [$out3_1, $identity0_1, $6]
      op_id: 446
      schema: aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> (Tensor)
      calls: 
      - fn_name: allocate
        addr: '4511934464_249'
        size: 1024
        op_id: 447
      returns: [tensor_ptr_4511934464_249]
      returns types: [Tensor]
      returns names: [$input33_1]
    - fn_name: free
      addr: '4533656576_246'
      size: 1024
      op_id: 448
    - fn_name: free
      addr: '4511935488_241'
      size: 1024
      op_id: 449
    - fn_name: aten::relu
      args: [tensor_ptr_4511934464_249]
      args types: [Tensor]
      args names: [$input33_1]
      op_id: 450
      schema: aten::relu(Tensor self) -> (Tensor)
      calls: 
      - fn_name: aten::clamp_min
        args: [tensor_ptr_4511934464_249, 0]
        args types: [Tensor, Int]
        op_id: 451
        schema: aten::clamp_min(Tensor self, Scalar min) -> (Tensor)
        calls: 
        - fn_name: aten::empty
          args: [[0], 6, 0, cpu, None, None]
          args types: [GenericList, Int, Int, Device, None, None]
          op_id: 452
          schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
          calls: 
          returns: [empty_tensor_375]
          returns types: [Tensor]
        - fn_name: aten::clamp_min
          args: [tensor_ptr_4511934464_249, 0, empty_tensor_375]
          args types: [Tensor, Int, Tensor]
          op_id: 453
          schema: aten::clamp_min.out(Tensor self, Scalar min, *, Tensor(a!) out) -> (Tensor(a!))
          calls: 
          - fn_name: allocate
            addr: '4511935488_250'
            size: 1024
            op_id: 454
          returns: [tensor_ptr_4511935488_250]
          returns types: [Tensor]
        returns: [tensor_ptr_4511935488_250]
        returns types: [Tensor]
      returns: [tensor_ptr_4511935488_250]
      returns types: [Tensor]
      returns names: [$input34_1]
    - fn_name: free
      addr: '4511934464_249'
      size: 1024
      op_id: 455
    - fn_name: aten::_convolution
      args: [tensor_ptr_4511935488_250, tensor_ptr_4520600064_21, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1, False, False, True, True]
      args types: [Tensor, Tensor, None, GenericList, GenericList, GenericList, Bool, GenericList, Int, Bool, Bool, Bool, Bool]
      args names: [$input34_1, $30, $8, $13, $13, $13, $9, $1, $6, $9, $9, $10, $10]
      op_id: 456
      schema: aten::_convolution(Tensor input, Tensor weight, Tensor? bias, int[] stride, int[] padding, int[] dilation, bool transposed, int[] output_padding, int groups, bool benchmark, bool deterministic, bool cudnn_enabled, bool allow_tf32) -> (Tensor)
      calls: 
      - fn_name: aten::thnn_conv2d
        args: [tensor_ptr_4511935488_250, tensor_ptr_4520600064_21, [3, 3], null, [1, 1], [1, 1]]
        args types: [Tensor, Tensor, GenericList, Tensor, GenericList, GenericList]
        op_id: 457
        schema: aten::thnn_conv2d(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias=None, int[2] stride=[1, 1], int[2] padding=[0, 0]) -> (Tensor)
        calls: 
        - fn_name: aten::_slow_conv2d_forward
          args: [tensor_ptr_4511935488_250, tensor_ptr_4520600064_21, [3, 3], null, [1, 1], [1, 1]]
          args types: [Tensor, Tensor, GenericList, Tensor, GenericList, GenericList]
          op_id: 458
          schema: aten::_slow_conv2d_forward(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias, int[2] stride, int[2] padding) -> (Tensor output, Tensor finput)
          calls: 
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 459
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_376]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 460
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_377]
            returns types: [Tensor]
          - fn_name: aten::view
            args: [tensor_ptr_4520600064_21, [256, 2304]]
            args types: [Tensor, GenericList]
            op_id: 461
            schema: aten::view(Tensor(a) self, int[] size) -> (Tensor(a))
            calls: 
            returns: [tensor_ptr_4520600064_21]
            returns types: [Tensor]
          - fn_name: aten::resize_
            args: [empty_tensor_377, [1, 2304, 1], None]
            args types: [Tensor, GenericList, None]
            op_id: 462
            schema: aten::resize_(Tensor(a!) self, int[] size, *, int? memory_format=None) -> (Tensor(a!))
            calls: 
            - fn_name: allocate
              addr: '4589889536_251'
              size: 9216
              op_id: 463
            returns: [tensor_ptr_4589889536_251]
            returns types: [Tensor]
          - fn_name: aten::resize_
            args: [empty_tensor_376, [1, 256, 1, 1], None]
            args types: [Tensor, GenericList, None]
            op_id: 464
            schema: aten::resize_(Tensor(a!) self, int[] size, *, int? memory_format=None) -> (Tensor(a!))
            calls: 
            - fn_name: allocate
              addr: '4511934464_252'
              size: 1024
              op_id: 465
            returns: [tensor_ptr_4511934464_252]
            returns types: [Tensor]
          returns: [tensor_ptr_4511934464_252, tensor_ptr_4589889536_251]
          returns types: [Tensor, Tensor]
        - fn_name: free
          addr: '4589889536_251'
          size: 9216
          op_id: 466
        returns: [tensor_ptr_4511934464_252]
        returns types: [Tensor]
      returns: [tensor_ptr_4511934464_252]
      returns types: [Tensor]
      returns names: [$input35_1]
    - fn_name: aten::batch_norm
      args: [tensor_ptr_4511934464_252, tensor_ptr_4509185024_17, tensor_ptr_4509186048_18, tensor_ptr_4509186048_18, tensor_ptr_4509185024_17, False, 0.10000000000000001, 1.0000000000000001e-05, True]
      args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double, Bool]
      args names: [$input35_1, $26, $27, $27, $26, $9, $5, $4, $10]
      op_id: 467
      schema: aten::batch_norm(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps, bool cudnn_enabled) -> (Tensor)
      calls: 
      - fn_name: aten::_batch_norm_impl_index
        args: [tensor_ptr_4511934464_252, tensor_ptr_4509185024_17, tensor_ptr_4509186048_18, tensor_ptr_4509186048_18, tensor_ptr_4509185024_17, False, 0.10000000000000001, 1.0000000000000001e-05, True]
        args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double, Bool]
        op_id: 468
        schema: aten::_batch_norm_impl_index(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps, bool cudnn_enabled) -> (Tensor, Tensor, Tensor, Tensor, int)
        calls: 
        - fn_name: aten::empty
          args: [[0], 0, 0, cpu, None, None]
          args types: [GenericList, Int, Int, Device, None, None]
          op_id: 469
          schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
          calls: 
          returns: [empty_tensor_378]
          returns types: [Tensor]
        - fn_name: aten::native_batch_norm
          args: [tensor_ptr_4511934464_252, tensor_ptr_4509185024_17, tensor_ptr_4509186048_18, tensor_ptr_4509186048_18, tensor_ptr_4509185024_17, False, 0.10000000000000001, 1.0000000000000001e-05]
          args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double]
          op_id: 470
          schema: aten::native_batch_norm(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps) -> (Tensor, Tensor, Tensor)
          calls: 
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 471
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_379]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 472
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_380]
            returns types: [Tensor]
          - fn_name: aten::empty_like
            args: [tensor_ptr_4511934464_252, None, None, None, None, 0]
            args types: [Tensor, None, None, None, None, Int]
            op_id: 473
            schema: aten::empty_like(Tensor self, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: aten::empty
              args: [[1, 256, 1, 1], 6, 0, cpu, None, 0]
              args types: [GenericList, Int, Int, Device, None, Int]
              op_id: 474
              schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
              calls: 
              - fn_name: allocate
                addr: '4533656576_253'
                size: 1024
                op_id: 475
              returns: [tensor_ptr_4533656576_253]
              returns types: [Tensor]
            returns: [tensor_ptr_4533656576_253]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[256], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 476
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: allocate
              addr: '4571009024_254'
              size: 1024
              op_id: 477
            returns: [tensor_ptr_4571009024_254]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[256], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 478
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: allocate
              addr: '4571010048_255'
              size: 1024
              op_id: 479
            returns: [tensor_ptr_4571010048_255]
            returns types: [Tensor]
          - fn_name: free
            addr: '4571010048_255'
            size: 1024
            op_id: 480
          - fn_name: free
            addr: '4571009024_254'
            size: 1024
            op_id: 481
          returns: [tensor_ptr_4533656576_253, empty_tensor_379, empty_tensor_380]
          returns types: [Tensor, Tensor, Tensor]
        returns: [tensor_ptr_4533656576_253, empty_tensor_379, empty_tensor_380, empty_tensor_378, 0]
        returns types: [Tensor, Tensor, Tensor, Tensor, Int]
      returns: [tensor_ptr_4533656576_253]
      returns types: [Tensor]
      returns names: [$input36_1]
    - fn_name: free
      addr: '4511934464_252'
      size: 1024
      op_id: 482
    - fn_name: aten::relu
      args: [tensor_ptr_4533656576_253]
      args types: [Tensor]
      args names: [$input36_1]
      op_id: 483
      schema: aten::relu(Tensor self) -> (Tensor)
      calls: 
      - fn_name: aten::clamp_min
        args: [tensor_ptr_4533656576_253, 0]
        args types: [Tensor, Int]
        op_id: 484
        schema: aten::clamp_min(Tensor self, Scalar min) -> (Tensor)
        calls: 
        - fn_name: aten::empty
          args: [[0], 6, 0, cpu, None, None]
          args types: [GenericList, Int, Int, Device, None, None]
          op_id: 485
          schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
          calls: 
          returns: [empty_tensor_384]
          returns types: [Tensor]
        - fn_name: aten::clamp_min
          args: [tensor_ptr_4533656576_253, 0, empty_tensor_384]
          args types: [Tensor, Int, Tensor]
          op_id: 486
          schema: aten::clamp_min.out(Tensor self, Scalar min, *, Tensor(a!) out) -> (Tensor(a!))
          calls: 
          - fn_name: allocate
            addr: '4511934464_256'
            size: 1024
            op_id: 487
          returns: [tensor_ptr_4511934464_256]
          returns types: [Tensor]
        returns: [tensor_ptr_4511934464_256]
        returns types: [Tensor]
      returns: [tensor_ptr_4511934464_256]
      returns types: [Tensor]
      returns names: [$input37_1]
    - fn_name: free
      addr: '4533656576_253'
      size: 1024
      op_id: 488
    - fn_name: aten::_convolution
      args: [tensor_ptr_4511934464_256, tensor_ptr_4525122816_22, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1, False, False, True, True]
      args types: [Tensor, Tensor, None, GenericList, GenericList, GenericList, Bool, GenericList, Int, Bool, Bool, Bool, Bool]
      args names: [$input37_1, $31, $8, $13, $13, $13, $9, $1, $6, $9, $9, $10, $10]
      op_id: 489
      schema: aten::_convolution(Tensor input, Tensor weight, Tensor? bias, int[] stride, int[] padding, int[] dilation, bool transposed, int[] output_padding, int groups, bool benchmark, bool deterministic, bool cudnn_enabled, bool allow_tf32) -> (Tensor)
      calls: 
      - fn_name: aten::thnn_conv2d
        args: [tensor_ptr_4511934464_256, tensor_ptr_4525122816_22, [3, 3], null, [1, 1], [1, 1]]
        args types: [Tensor, Tensor, GenericList, Tensor, GenericList, GenericList]
        op_id: 490
        schema: aten::thnn_conv2d(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias=None, int[2] stride=[1, 1], int[2] padding=[0, 0]) -> (Tensor)
        calls: 
        - fn_name: aten::_slow_conv2d_forward
          args: [tensor_ptr_4511934464_256, tensor_ptr_4525122816_22, [3, 3], null, [1, 1], [1, 1]]
          args types: [Tensor, Tensor, GenericList, Tensor, GenericList, GenericList]
          op_id: 491
          schema: aten::_slow_conv2d_forward(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias, int[2] stride, int[2] padding) -> (Tensor output, Tensor finput)
          calls: 
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 492
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_385]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 493
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_386]
            returns types: [Tensor]
          - fn_name: aten::view
            args: [tensor_ptr_4525122816_22, [256, 2304]]
            args types: [Tensor, GenericList]
            op_id: 494
            schema: aten::view(Tensor(a) self, int[] size) -> (Tensor(a))
            calls: 
            returns: [tensor_ptr_4525122816_22]
            returns types: [Tensor]
          - fn_name: aten::resize_
            args: [empty_tensor_386, [1, 2304, 1], None]
            args types: [Tensor, GenericList, None]
            op_id: 495
            schema: aten::resize_(Tensor(a!) self, int[] size, *, int? memory_format=None) -> (Tensor(a!))
            calls: 
            - fn_name: allocate
              addr: '4589889536_257'
              size: 9216
              op_id: 496
            returns: [tensor_ptr_4589889536_257]
            returns types: [Tensor]
          - fn_name: aten::resize_
            args: [empty_tensor_385, [1, 256, 1, 1], None]
            args types: [Tensor, GenericList, None]
            op_id: 497
            schema: aten::resize_(Tensor(a!) self, int[] size, *, int? memory_format=None) -> (Tensor(a!))
            calls: 
            - fn_name: allocate
              addr: '4533656576_258'
              size: 1024
              op_id: 498
            returns: [tensor_ptr_4533656576_258]
            returns types: [Tensor]
          returns: [tensor_ptr_4533656576_258, tensor_ptr_4589889536_257]
          returns types: [Tensor, Tensor]
        - fn_name: free
          addr: '4589889536_257'
          size: 9216
          op_id: 499
        returns: [tensor_ptr_4533656576_258]
        returns types: [Tensor]
      returns: [tensor_ptr_4533656576_258]
      returns types: [Tensor]
      returns names: [$input38_1]
    - fn_name: free
      addr: '4511934464_256'
      size: 1024
      op_id: 500
    - fn_name: aten::batch_norm
      args: [tensor_ptr_4533656576_258, tensor_ptr_4509185024_17, tensor_ptr_4509186048_18, tensor_ptr_4509186048_18, tensor_ptr_4509185024_17, False, 0.10000000000000001, 1.0000000000000001e-05, True]
      args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double, Bool]
      args names: [$input38_1, $26, $27, $27, $26, $9, $5, $4, $10]
      op_id: 501
      schema: aten::batch_norm(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps, bool cudnn_enabled) -> (Tensor)
      calls: 
      - fn_name: aten::_batch_norm_impl_index
        args: [tensor_ptr_4533656576_258, tensor_ptr_4509185024_17, tensor_ptr_4509186048_18, tensor_ptr_4509186048_18, tensor_ptr_4509185024_17, False, 0.10000000000000001, 1.0000000000000001e-05, True]
        args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double, Bool]
        op_id: 502
        schema: aten::_batch_norm_impl_index(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps, bool cudnn_enabled) -> (Tensor, Tensor, Tensor, Tensor, int)
        calls: 
        - fn_name: aten::empty
          args: [[0], 0, 0, cpu, None, None]
          args types: [GenericList, Int, Int, Device, None, None]
          op_id: 503
          schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
          calls: 
          returns: [empty_tensor_387]
          returns types: [Tensor]
        - fn_name: aten::native_batch_norm
          args: [tensor_ptr_4533656576_258, tensor_ptr_4509185024_17, tensor_ptr_4509186048_18, tensor_ptr_4509186048_18, tensor_ptr_4509185024_17, False, 0.10000000000000001, 1.0000000000000001e-05]
          args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double]
          op_id: 504
          schema: aten::native_batch_norm(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps) -> (Tensor, Tensor, Tensor)
          calls: 
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 505
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_388]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 506
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_389]
            returns types: [Tensor]
          - fn_name: aten::empty_like
            args: [tensor_ptr_4533656576_258, None, None, None, None, 0]
            args types: [Tensor, None, None, None, None, Int]
            op_id: 507
            schema: aten::empty_like(Tensor self, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: aten::empty
              args: [[1, 256, 1, 1], 6, 0, cpu, None, 0]
              args types: [GenericList, Int, Int, Device, None, Int]
              op_id: 508
              schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
              calls: 
              - fn_name: allocate
                addr: '4511934464_259'
                size: 1024
                op_id: 509
              returns: [tensor_ptr_4511934464_259]
              returns types: [Tensor]
            returns: [tensor_ptr_4511934464_259]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[256], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 510
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: allocate
              addr: '4571009024_260'
              size: 1024
              op_id: 511
            returns: [tensor_ptr_4571009024_260]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[256], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 512
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: allocate
              addr: '4571010048_261'
              size: 1024
              op_id: 513
            returns: [tensor_ptr_4571010048_261]
            returns types: [Tensor]
          - fn_name: free
            addr: '4571010048_261'
            size: 1024
            op_id: 514
          - fn_name: free
            addr: '4571009024_260'
            size: 1024
            op_id: 515
          returns: [tensor_ptr_4511934464_259, empty_tensor_388, empty_tensor_389]
          returns types: [Tensor, Tensor, Tensor]
        returns: [tensor_ptr_4511934464_259, empty_tensor_388, empty_tensor_389, empty_tensor_387, 0]
        returns types: [Tensor, Tensor, Tensor, Tensor, Int]
      returns: [tensor_ptr_4511934464_259]
      returns types: [Tensor]
      returns names: [$out4_1]
    - fn_name: free
      addr: '4533656576_258'
      size: 1024
      op_id: 516
    - fn_name: aten::add
      args: [tensor_ptr_4511934464_259, tensor_ptr_4511935488_250, 1]
      args types: [Tensor, Tensor, Int]
      args names: [$out4_1, $input34_1, $6]
      op_id: 517
      schema: aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> (Tensor)
      calls: 
      - fn_name: allocate
        addr: '4533656576_262'
        size: 1024
        op_id: 518
      returns: [tensor_ptr_4533656576_262]
      returns types: [Tensor]
      returns names: [$input39_1]
    - fn_name: free
      addr: '4511935488_250'
      size: 1024
      op_id: 519
    - fn_name: free
      addr: '4511934464_259'
      size: 1024
      op_id: 520
    - fn_name: aten::relu
      args: [tensor_ptr_4533656576_262]
      args types: [Tensor]
      args names: [$input39_1]
      op_id: 521
      schema: aten::relu(Tensor self) -> (Tensor)
      calls: 
      - fn_name: aten::clamp_min
        args: [tensor_ptr_4533656576_262, 0]
        args types: [Tensor, Int]
        op_id: 522
        schema: aten::clamp_min(Tensor self, Scalar min) -> (Tensor)
        calls: 
        - fn_name: aten::empty
          args: [[0], 6, 0, cpu, None, None]
          args types: [GenericList, Int, Int, Device, None, None]
          op_id: 523
          schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
          calls: 
          returns: [empty_tensor_394]
          returns types: [Tensor]
        - fn_name: aten::clamp_min
          args: [tensor_ptr_4533656576_262, 0, empty_tensor_394]
          args types: [Tensor, Int, Tensor]
          op_id: 524
          schema: aten::clamp_min.out(Tensor self, Scalar min, *, Tensor(a!) out) -> (Tensor(a!))
          calls: 
          - fn_name: allocate
            addr: '4511934464_263'
            size: 1024
            op_id: 525
          returns: [tensor_ptr_4511934464_263]
          returns types: [Tensor]
        returns: [tensor_ptr_4511934464_263]
        returns types: [Tensor]
      returns: [tensor_ptr_4511934464_263]
      returns types: [Tensor]
      returns names: [$input40_1]
    - fn_name: free
      addr: '4533656576_262'
      size: 1024
      op_id: 526
    - fn_name: aten::_convolution
      args: [tensor_ptr_4511934464_263, tensor_ptr_4527748224_23, None, [2, 2], [1, 1], [1, 1], False, [0, 0], 1, False, False, True, True]
      args types: [Tensor, Tensor, None, GenericList, GenericList, GenericList, Bool, GenericList, Int, Bool, Bool, Bool, Bool]
      args names: [$input40_1, $32, $8, $3, $13, $13, $9, $1, $6, $9, $9, $10, $10]
      op_id: 527
      schema: aten::_convolution(Tensor input, Tensor weight, Tensor? bias, int[] stride, int[] padding, int[] dilation, bool transposed, int[] output_padding, int groups, bool benchmark, bool deterministic, bool cudnn_enabled, bool allow_tf32) -> (Tensor)
      calls: 
      - fn_name: aten::thnn_conv2d
        args: [tensor_ptr_4511934464_263, tensor_ptr_4527748224_23, [3, 3], null, [2, 2], [1, 1]]
        args types: [Tensor, Tensor, GenericList, Tensor, GenericList, GenericList]
        op_id: 528
        schema: aten::thnn_conv2d(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias=None, int[2] stride=[1, 1], int[2] padding=[0, 0]) -> (Tensor)
        calls: 
        - fn_name: aten::_slow_conv2d_forward
          args: [tensor_ptr_4511934464_263, tensor_ptr_4527748224_23, [3, 3], null, [2, 2], [1, 1]]
          args types: [Tensor, Tensor, GenericList, Tensor, GenericList, GenericList]
          op_id: 529
          schema: aten::_slow_conv2d_forward(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias, int[2] stride, int[2] padding) -> (Tensor output, Tensor finput)
          calls: 
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 530
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_395]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 531
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_396]
            returns types: [Tensor]
          - fn_name: aten::view
            args: [tensor_ptr_4527748224_23, [512, 2304]]
            args types: [Tensor, GenericList]
            op_id: 532
            schema: aten::view(Tensor(a) self, int[] size) -> (Tensor(a))
            calls: 
            returns: [tensor_ptr_4527748224_23]
            returns types: [Tensor]
          - fn_name: aten::resize_
            args: [empty_tensor_396, [1, 2304, 1], None]
            args types: [Tensor, GenericList, None]
            op_id: 533
            schema: aten::resize_(Tensor(a!) self, int[] size, *, int? memory_format=None) -> (Tensor(a!))
            calls: 
            - fn_name: allocate
              addr: '4589889536_264'
              size: 9216
              op_id: 534
            returns: [tensor_ptr_4589889536_264]
            returns types: [Tensor]
          - fn_name: aten::resize_
            args: [empty_tensor_395, [1, 512, 1, 1], None]
            args types: [Tensor, GenericList, None]
            op_id: 535
            schema: aten::resize_(Tensor(a!) self, int[] size, *, int? memory_format=None) -> (Tensor(a!))
            calls: 
            - fn_name: allocate
              addr: '4524111872_265'
              size: 2048
              op_id: 536
            returns: [tensor_ptr_4524111872_265]
            returns types: [Tensor]
          returns: [tensor_ptr_4524111872_265, tensor_ptr_4589889536_264]
          returns types: [Tensor, Tensor]
        - fn_name: free
          addr: '4589889536_264'
          size: 9216
          op_id: 537
        returns: [tensor_ptr_4524111872_265]
        returns types: [Tensor]
      returns: [tensor_ptr_4524111872_265]
      returns types: [Tensor]
      returns names: [$input41_1]
    - fn_name: aten::batch_norm
      args: [tensor_ptr_4524111872_265, tensor_ptr_4513214464_24, tensor_ptr_4513216512_25, tensor_ptr_4513216512_25, tensor_ptr_4513214464_24, False, 0.10000000000000001, 1.0000000000000001e-05, True]
      args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double, Bool]
      args names: [$input41_1, $33, $34, $34, $33, $9, $5, $4, $10]
      op_id: 538
      schema: aten::batch_norm(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps, bool cudnn_enabled) -> (Tensor)
      calls: 
      - fn_name: aten::_batch_norm_impl_index
        args: [tensor_ptr_4524111872_265, tensor_ptr_4513214464_24, tensor_ptr_4513216512_25, tensor_ptr_4513216512_25, tensor_ptr_4513214464_24, False, 0.10000000000000001, 1.0000000000000001e-05, True]
        args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double, Bool]
        op_id: 539
        schema: aten::_batch_norm_impl_index(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps, bool cudnn_enabled) -> (Tensor, Tensor, Tensor, Tensor, int)
        calls: 
        - fn_name: aten::empty
          args: [[0], 0, 0, cpu, None, None]
          args types: [GenericList, Int, Int, Device, None, None]
          op_id: 540
          schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
          calls: 
          returns: [empty_tensor_397]
          returns types: [Tensor]
        - fn_name: aten::native_batch_norm
          args: [tensor_ptr_4524111872_265, tensor_ptr_4513214464_24, tensor_ptr_4513216512_25, tensor_ptr_4513216512_25, tensor_ptr_4513214464_24, False, 0.10000000000000001, 1.0000000000000001e-05]
          args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double]
          op_id: 541
          schema: aten::native_batch_norm(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps) -> (Tensor, Tensor, Tensor)
          calls: 
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 542
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_398]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 543
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_399]
            returns types: [Tensor]
          - fn_name: aten::empty_like
            args: [tensor_ptr_4524111872_265, None, None, None, None, 0]
            args types: [Tensor, None, None, None, None, Int]
            op_id: 544
            schema: aten::empty_like(Tensor self, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: aten::empty
              args: [[1, 512, 1, 1], 6, 0, cpu, None, 0]
              args types: [GenericList, Int, Int, Device, None, Int]
              op_id: 545
              schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
              calls: 
              - fn_name: allocate
                addr: '4534005760_266'
                size: 2048
                op_id: 546
              returns: [tensor_ptr_4534005760_266]
              returns types: [Tensor]
            returns: [tensor_ptr_4534005760_266]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[512], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 547
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: allocate
              addr: '4591046656_267'
              size: 2048
              op_id: 548
            returns: [tensor_ptr_4591046656_267]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[512], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 549
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: allocate
              addr: '4591048704_268'
              size: 2048
              op_id: 550
            returns: [tensor_ptr_4591048704_268]
            returns types: [Tensor]
          - fn_name: free
            addr: '4591048704_268'
            size: 2048
            op_id: 551
          - fn_name: free
            addr: '4591046656_267'
            size: 2048
            op_id: 552
          returns: [tensor_ptr_4534005760_266, empty_tensor_398, empty_tensor_399]
          returns types: [Tensor, Tensor, Tensor]
        returns: [tensor_ptr_4534005760_266, empty_tensor_398, empty_tensor_399, empty_tensor_397, 0]
        returns types: [Tensor, Tensor, Tensor, Tensor, Int]
      returns: [tensor_ptr_4534005760_266]
      returns types: [Tensor]
      returns names: [$input42_1]
    - fn_name: free
      addr: '4524111872_265'
      size: 2048
      op_id: 553
    - fn_name: aten::relu
      args: [tensor_ptr_4534005760_266]
      args types: [Tensor]
      args names: [$input42_1]
      op_id: 554
      schema: aten::relu(Tensor self) -> (Tensor)
      calls: 
      - fn_name: aten::clamp_min
        args: [tensor_ptr_4534005760_266, 0]
        args types: [Tensor, Int]
        op_id: 555
        schema: aten::clamp_min(Tensor self, Scalar min) -> (Tensor)
        calls: 
        - fn_name: aten::empty
          args: [[0], 6, 0, cpu, None, None]
          args types: [GenericList, Int, Int, Device, None, None]
          op_id: 556
          schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
          calls: 
          returns: [empty_tensor_403]
          returns types: [Tensor]
        - fn_name: aten::clamp_min
          args: [tensor_ptr_4534005760_266, 0, empty_tensor_403]
          args types: [Tensor, Int, Tensor]
          op_id: 557
          schema: aten::clamp_min.out(Tensor self, Scalar min, *, Tensor(a!) out) -> (Tensor(a!))
          calls: 
          - fn_name: allocate
            addr: '4524111872_269'
            size: 2048
            op_id: 558
          returns: [tensor_ptr_4524111872_269]
          returns types: [Tensor]
        returns: [tensor_ptr_4524111872_269]
        returns types: [Tensor]
      returns: [tensor_ptr_4524111872_269]
      returns types: [Tensor]
      returns names: [$input43_1]
    - fn_name: free
      addr: '4534005760_266'
      size: 2048
      op_id: 559
    - fn_name: aten::_convolution
      args: [tensor_ptr_4524111872_269, tensor_ptr_4536140864_26, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1, False, False, True, True]
      args types: [Tensor, Tensor, None, GenericList, GenericList, GenericList, Bool, GenericList, Int, Bool, Bool, Bool, Bool]
      args names: [$input43_1, $35, $8, $13, $13, $13, $9, $1, $6, $9, $9, $10, $10]
      op_id: 560
      schema: aten::_convolution(Tensor input, Tensor weight, Tensor? bias, int[] stride, int[] padding, int[] dilation, bool transposed, int[] output_padding, int groups, bool benchmark, bool deterministic, bool cudnn_enabled, bool allow_tf32) -> (Tensor)
      calls: 
      - fn_name: aten::thnn_conv2d
        args: [tensor_ptr_4524111872_269, tensor_ptr_4536140864_26, [3, 3], null, [1, 1], [1, 1]]
        args types: [Tensor, Tensor, GenericList, Tensor, GenericList, GenericList]
        op_id: 561
        schema: aten::thnn_conv2d(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias=None, int[2] stride=[1, 1], int[2] padding=[0, 0]) -> (Tensor)
        calls: 
        - fn_name: aten::_slow_conv2d_forward
          args: [tensor_ptr_4524111872_269, tensor_ptr_4536140864_26, [3, 3], null, [1, 1], [1, 1]]
          args types: [Tensor, Tensor, GenericList, Tensor, GenericList, GenericList]
          op_id: 562
          schema: aten::_slow_conv2d_forward(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias, int[2] stride, int[2] padding) -> (Tensor output, Tensor finput)
          calls: 
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 563
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_404]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 564
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_405]
            returns types: [Tensor]
          - fn_name: aten::view
            args: [tensor_ptr_4536140864_26, [512, 4608]]
            args types: [Tensor, GenericList]
            op_id: 565
            schema: aten::view(Tensor(a) self, int[] size) -> (Tensor(a))
            calls: 
            returns: [tensor_ptr_4536140864_26]
            returns types: [Tensor]
          - fn_name: aten::resize_
            args: [empty_tensor_405, [1, 4608, 1], None]
            args types: [Tensor, GenericList, None]
            op_id: 566
            schema: aten::resize_(Tensor(a!) self, int[] size, *, int? memory_format=None) -> (Tensor(a!))
            calls: 
            - fn_name: allocate
              addr: '4590817728_270'
              size: 18432
              op_id: 567
            returns: [tensor_ptr_4590817728_270]
            returns types: [Tensor]
          - fn_name: aten::resize_
            args: [empty_tensor_404, [1, 512, 1, 1], None]
            args types: [Tensor, GenericList, None]
            op_id: 568
            schema: aten::resize_(Tensor(a!) self, int[] size, *, int? memory_format=None) -> (Tensor(a!))
            calls: 
            - fn_name: allocate
              addr: '4534005760_271'
              size: 2048
              op_id: 569
            returns: [tensor_ptr_4534005760_271]
            returns types: [Tensor]
          returns: [tensor_ptr_4534005760_271, tensor_ptr_4590817728_270]
          returns types: [Tensor, Tensor]
        - fn_name: free
          addr: '4590817728_270'
          size: 18432
          op_id: 570
        returns: [tensor_ptr_4534005760_271]
        returns types: [Tensor]
      returns: [tensor_ptr_4534005760_271]
      returns types: [Tensor]
      returns names: [$input44_1]
    - fn_name: free
      addr: '4524111872_269'
      size: 2048
      op_id: 571
    - fn_name: aten::batch_norm
      args: [tensor_ptr_4534005760_271, tensor_ptr_4513214464_24, tensor_ptr_4513216512_25, tensor_ptr_4513216512_25, tensor_ptr_4513214464_24, False, 0.10000000000000001, 1.0000000000000001e-05, True]
      args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double, Bool]
      args names: [$input44_1, $33, $34, $34, $33, $9, $5, $4, $10]
      op_id: 572
      schema: aten::batch_norm(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps, bool cudnn_enabled) -> (Tensor)
      calls: 
      - fn_name: aten::_batch_norm_impl_index
        args: [tensor_ptr_4534005760_271, tensor_ptr_4513214464_24, tensor_ptr_4513216512_25, tensor_ptr_4513216512_25, tensor_ptr_4513214464_24, False, 0.10000000000000001, 1.0000000000000001e-05, True]
        args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double, Bool]
        op_id: 573
        schema: aten::_batch_norm_impl_index(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps, bool cudnn_enabled) -> (Tensor, Tensor, Tensor, Tensor, int)
        calls: 
        - fn_name: aten::empty
          args: [[0], 0, 0, cpu, None, None]
          args types: [GenericList, Int, Int, Device, None, None]
          op_id: 574
          schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
          calls: 
          returns: [empty_tensor_406]
          returns types: [Tensor]
        - fn_name: aten::native_batch_norm
          args: [tensor_ptr_4534005760_271, tensor_ptr_4513214464_24, tensor_ptr_4513216512_25, tensor_ptr_4513216512_25, tensor_ptr_4513214464_24, False, 0.10000000000000001, 1.0000000000000001e-05]
          args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double]
          op_id: 575
          schema: aten::native_batch_norm(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps) -> (Tensor, Tensor, Tensor)
          calls: 
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 576
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_407]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 577
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_408]
            returns types: [Tensor]
          - fn_name: aten::empty_like
            args: [tensor_ptr_4534005760_271, None, None, None, None, 0]
            args types: [Tensor, None, None, None, None, Int]
            op_id: 578
            schema: aten::empty_like(Tensor self, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: aten::empty
              args: [[1, 512, 1, 1], 6, 0, cpu, None, 0]
              args types: [GenericList, Int, Int, Device, None, Int]
              op_id: 579
              schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
              calls: 
              - fn_name: allocate
                addr: '4524111872_272'
                size: 2048
                op_id: 580
              returns: [tensor_ptr_4524111872_272]
              returns types: [Tensor]
            returns: [tensor_ptr_4524111872_272]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[512], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 581
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: allocate
              addr: '4591046656_273'
              size: 2048
              op_id: 582
            returns: [tensor_ptr_4591046656_273]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[512], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 583
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: allocate
              addr: '4591048704_274'
              size: 2048
              op_id: 584
            returns: [tensor_ptr_4591048704_274]
            returns types: [Tensor]
          - fn_name: free
            addr: '4591048704_274'
            size: 2048
            op_id: 585
          - fn_name: free
            addr: '4591046656_273'
            size: 2048
            op_id: 586
          returns: [tensor_ptr_4524111872_272, empty_tensor_407, empty_tensor_408]
          returns types: [Tensor, Tensor, Tensor]
        returns: [tensor_ptr_4524111872_272, empty_tensor_407, empty_tensor_408, empty_tensor_406, 0]
        returns types: [Tensor, Tensor, Tensor, Tensor, Int]
      returns: [tensor_ptr_4524111872_272]
      returns types: [Tensor]
      returns names: [$out5_1]
    - fn_name: free
      addr: '4534005760_271'
      size: 2048
      op_id: 587
    - fn_name: aten::_convolution
      args: [tensor_ptr_4511934464_263, tensor_ptr_4523226944_27, None, [2, 2], [0, 0], [1, 1], False, [0, 0], 1, False, False, True, True]
      args types: [Tensor, Tensor, None, GenericList, GenericList, GenericList, Bool, GenericList, Int, Bool, Bool, Bool, Bool]
      args names: [$input40_1, $36, $8, $3, $1, $13, $9, $1, $6, $9, $9, $10, $10]
      op_id: 588
      schema: aten::_convolution(Tensor input, Tensor weight, Tensor? bias, int[] stride, int[] padding, int[] dilation, bool transposed, int[] output_padding, int groups, bool benchmark, bool deterministic, bool cudnn_enabled, bool allow_tf32) -> (Tensor)
      calls: 
      - fn_name: aten::thnn_conv2d
        args: [tensor_ptr_4511934464_263, tensor_ptr_4523226944_27, [1, 1], null, [2, 2], [0, 0]]
        args types: [Tensor, Tensor, GenericList, Tensor, GenericList, GenericList]
        op_id: 589
        schema: aten::thnn_conv2d(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias=None, int[2] stride=[1, 1], int[2] padding=[0, 0]) -> (Tensor)
        calls: 
        - fn_name: aten::_slow_conv2d_forward
          args: [tensor_ptr_4511934464_263, tensor_ptr_4523226944_27, [1, 1], null, [2, 2], [0, 0]]
          args types: [Tensor, Tensor, GenericList, Tensor, GenericList, GenericList]
          op_id: 590
          schema: aten::_slow_conv2d_forward(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias, int[2] stride, int[2] padding) -> (Tensor output, Tensor finput)
          calls: 
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 591
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_412]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 592
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_413]
            returns types: [Tensor]
          - fn_name: aten::view
            args: [tensor_ptr_4523226944_27, [512, 256]]
            args types: [Tensor, GenericList]
            op_id: 593
            schema: aten::view(Tensor(a) self, int[] size) -> (Tensor(a))
            calls: 
            returns: [tensor_ptr_4523226944_27]
            returns types: [Tensor]
          - fn_name: aten::resize_
            args: [empty_tensor_413, [1, 256, 1], None]
            args types: [Tensor, GenericList, None]
            op_id: 594
            schema: aten::resize_(Tensor(a!) self, int[] size, *, int? memory_format=None) -> (Tensor(a!))
            calls: 
            - fn_name: allocate
              addr: '4533656576_275'
              size: 1024
              op_id: 595
            returns: [tensor_ptr_4533656576_275]
            returns types: [Tensor]
          - fn_name: aten::resize_
            args: [empty_tensor_412, [1, 512, 1, 1], None]
            args types: [Tensor, GenericList, None]
            op_id: 596
            schema: aten::resize_(Tensor(a!) self, int[] size, *, int? memory_format=None) -> (Tensor(a!))
            calls: 
            - fn_name: allocate
              addr: '4534005760_276'
              size: 2048
              op_id: 597
            returns: [tensor_ptr_4534005760_276]
            returns types: [Tensor]
          returns: [tensor_ptr_4534005760_276, tensor_ptr_4533656576_275]
          returns types: [Tensor, Tensor]
        - fn_name: free
          addr: '4533656576_275'
          size: 1024
          op_id: 598
        returns: [tensor_ptr_4534005760_276]
        returns types: [Tensor]
      returns: [tensor_ptr_4534005760_276]
      returns types: [Tensor]
      returns names: [$input45_1]
    - fn_name: free
      addr: '4511934464_263'
      size: 1024
      op_id: 599
    - fn_name: aten::batch_norm
      args: [tensor_ptr_4534005760_276, tensor_ptr_4513214464_24, tensor_ptr_4513216512_25, tensor_ptr_4513216512_25, tensor_ptr_4513214464_24, False, 0.10000000000000001, 1.0000000000000001e-05, True]
      args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double, Bool]
      args names: [$input45_1, $33, $34, $34, $33, $9, $5, $4, $10]
      op_id: 600
      schema: aten::batch_norm(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps, bool cudnn_enabled) -> (Tensor)
      calls: 
      - fn_name: aten::_batch_norm_impl_index
        args: [tensor_ptr_4534005760_276, tensor_ptr_4513214464_24, tensor_ptr_4513216512_25, tensor_ptr_4513216512_25, tensor_ptr_4513214464_24, False, 0.10000000000000001, 1.0000000000000001e-05, True]
        args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double, Bool]
        op_id: 601
        schema: aten::_batch_norm_impl_index(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps, bool cudnn_enabled) -> (Tensor, Tensor, Tensor, Tensor, int)
        calls: 
        - fn_name: aten::empty
          args: [[0], 0, 0, cpu, None, None]
          args types: [GenericList, Int, Int, Device, None, None]
          op_id: 602
          schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
          calls: 
          returns: [empty_tensor_414]
          returns types: [Tensor]
        - fn_name: aten::native_batch_norm
          args: [tensor_ptr_4534005760_276, tensor_ptr_4513214464_24, tensor_ptr_4513216512_25, tensor_ptr_4513216512_25, tensor_ptr_4513214464_24, False, 0.10000000000000001, 1.0000000000000001e-05]
          args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double]
          op_id: 603
          schema: aten::native_batch_norm(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps) -> (Tensor, Tensor, Tensor)
          calls: 
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 604
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_415]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 605
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_416]
            returns types: [Tensor]
          - fn_name: aten::empty_like
            args: [tensor_ptr_4534005760_276, None, None, None, None, 0]
            args types: [Tensor, None, None, None, None, Int]
            op_id: 606
            schema: aten::empty_like(Tensor self, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: aten::empty
              args: [[1, 512, 1, 1], 6, 0, cpu, None, 0]
              args types: [GenericList, Int, Int, Device, None, Int]
              op_id: 607
              schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
              calls: 
              - fn_name: allocate
                addr: '4591046656_277'
                size: 2048
                op_id: 608
              returns: [tensor_ptr_4591046656_277]
              returns types: [Tensor]
            returns: [tensor_ptr_4591046656_277]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[512], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 609
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: allocate
              addr: '4591048704_278'
              size: 2048
              op_id: 610
            returns: [tensor_ptr_4591048704_278]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[512], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 611
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: allocate
              addr: '4591050752_279'
              size: 2048
              op_id: 612
            returns: [tensor_ptr_4591050752_279]
            returns types: [Tensor]
          - fn_name: free
            addr: '4591050752_279'
            size: 2048
            op_id: 613
          - fn_name: free
            addr: '4591048704_278'
            size: 2048
            op_id: 614
          returns: [tensor_ptr_4591046656_277, empty_tensor_415, empty_tensor_416]
          returns types: [Tensor, Tensor, Tensor]
        returns: [tensor_ptr_4591046656_277, empty_tensor_415, empty_tensor_416, empty_tensor_414, 0]
        returns types: [Tensor, Tensor, Tensor, Tensor, Int]
      returns: [tensor_ptr_4591046656_277]
      returns types: [Tensor]
      returns names: [$identity1_1]
    - fn_name: free
      addr: '4534005760_276'
      size: 2048
      op_id: 615
    - fn_name: aten::add
      args: [tensor_ptr_4524111872_272, tensor_ptr_4591046656_277, 1]
      args types: [Tensor, Tensor, Int]
      args names: [$out5_1, $identity1_1, $6]
      op_id: 616
      schema: aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> (Tensor)
      calls: 
      - fn_name: allocate
        addr: '4534005760_280'
        size: 2048
        op_id: 617
      returns: [tensor_ptr_4534005760_280]
      returns types: [Tensor]
      returns names: [$input46_1]
    - fn_name: free
      addr: '4591046656_277'
      size: 2048
      op_id: 618
    - fn_name: free
      addr: '4524111872_272'
      size: 2048
      op_id: 619
    - fn_name: aten::relu
      args: [tensor_ptr_4534005760_280]
      args types: [Tensor]
      args names: [$input46_1]
      op_id: 620
      schema: aten::relu(Tensor self) -> (Tensor)
      calls: 
      - fn_name: aten::clamp_min
        args: [tensor_ptr_4534005760_280, 0]
        args types: [Tensor, Int]
        op_id: 621
        schema: aten::clamp_min(Tensor self, Scalar min) -> (Tensor)
        calls: 
        - fn_name: aten::empty
          args: [[0], 6, 0, cpu, None, None]
          args types: [GenericList, Int, Int, Device, None, None]
          op_id: 622
          schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
          calls: 
          returns: [empty_tensor_421]
          returns types: [Tensor]
        - fn_name: aten::clamp_min
          args: [tensor_ptr_4534005760_280, 0, empty_tensor_421]
          args types: [Tensor, Int, Tensor]
          op_id: 623
          schema: aten::clamp_min.out(Tensor self, Scalar min, *, Tensor(a!) out) -> (Tensor(a!))
          calls: 
          - fn_name: allocate
            addr: '4524111872_281'
            size: 2048
            op_id: 624
          returns: [tensor_ptr_4524111872_281]
          returns types: [Tensor]
        returns: [tensor_ptr_4524111872_281]
        returns types: [Tensor]
      returns: [tensor_ptr_4524111872_281]
      returns types: [Tensor]
      returns names: [$input47_1]
    - fn_name: free
      addr: '4534005760_280'
      size: 2048
      op_id: 625
    - fn_name: aten::_convolution
      args: [tensor_ptr_4524111872_281, tensor_ptr_4546629696_28, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1, False, False, True, True]
      args types: [Tensor, Tensor, None, GenericList, GenericList, GenericList, Bool, GenericList, Int, Bool, Bool, Bool, Bool]
      args names: [$input47_1, $37, $8, $13, $13, $13, $9, $1, $6, $9, $9, $10, $10]
      op_id: 626
      schema: aten::_convolution(Tensor input, Tensor weight, Tensor? bias, int[] stride, int[] padding, int[] dilation, bool transposed, int[] output_padding, int groups, bool benchmark, bool deterministic, bool cudnn_enabled, bool allow_tf32) -> (Tensor)
      calls: 
      - fn_name: aten::thnn_conv2d
        args: [tensor_ptr_4524111872_281, tensor_ptr_4546629696_28, [3, 3], null, [1, 1], [1, 1]]
        args types: [Tensor, Tensor, GenericList, Tensor, GenericList, GenericList]
        op_id: 627
        schema: aten::thnn_conv2d(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias=None, int[2] stride=[1, 1], int[2] padding=[0, 0]) -> (Tensor)
        calls: 
        - fn_name: aten::_slow_conv2d_forward
          args: [tensor_ptr_4524111872_281, tensor_ptr_4546629696_28, [3, 3], null, [1, 1], [1, 1]]
          args types: [Tensor, Tensor, GenericList, Tensor, GenericList, GenericList]
          op_id: 628
          schema: aten::_slow_conv2d_forward(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias, int[2] stride, int[2] padding) -> (Tensor output, Tensor finput)
          calls: 
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 629
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_422]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 630
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_423]
            returns types: [Tensor]
          - fn_name: aten::view
            args: [tensor_ptr_4546629696_28, [512, 4608]]
            args types: [Tensor, GenericList]
            op_id: 631
            schema: aten::view(Tensor(a) self, int[] size) -> (Tensor(a))
            calls: 
            returns: [tensor_ptr_4546629696_28]
            returns types: [Tensor]
          - fn_name: aten::resize_
            args: [empty_tensor_423, [1, 4608, 1], None]
            args types: [Tensor, GenericList, None]
            op_id: 632
            schema: aten::resize_(Tensor(a!) self, int[] size, *, int? memory_format=None) -> (Tensor(a!))
            calls: 
            - fn_name: allocate
              addr: '4587954368_282'
              size: 18432
              op_id: 633
            returns: [tensor_ptr_4587954368_282]
            returns types: [Tensor]
          - fn_name: aten::resize_
            args: [empty_tensor_422, [1, 512, 1, 1], None]
            args types: [Tensor, GenericList, None]
            op_id: 634
            schema: aten::resize_(Tensor(a!) self, int[] size, *, int? memory_format=None) -> (Tensor(a!))
            calls: 
            - fn_name: allocate
              addr: '4534007808_283'
              size: 2048
              op_id: 635
            returns: [tensor_ptr_4534007808_283]
            returns types: [Tensor]
          returns: [tensor_ptr_4534007808_283, tensor_ptr_4587954368_282]
          returns types: [Tensor, Tensor]
        - fn_name: free
          addr: '4587954368_282'
          size: 18432
          op_id: 636
        returns: [tensor_ptr_4534007808_283]
        returns types: [Tensor]
      returns: [tensor_ptr_4534007808_283]
      returns types: [Tensor]
      returns names: [$input48_1]
    - fn_name: aten::batch_norm
      args: [tensor_ptr_4534007808_283, tensor_ptr_4513214464_24, tensor_ptr_4513216512_25, tensor_ptr_4513216512_25, tensor_ptr_4513214464_24, False, 0.10000000000000001, 1.0000000000000001e-05, True]
      args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double, Bool]
      args names: [$input48_1, $33, $34, $34, $33, $9, $5, $4, $10]
      op_id: 637
      schema: aten::batch_norm(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps, bool cudnn_enabled) -> (Tensor)
      calls: 
      - fn_name: aten::_batch_norm_impl_index
        args: [tensor_ptr_4534007808_283, tensor_ptr_4513214464_24, tensor_ptr_4513216512_25, tensor_ptr_4513216512_25, tensor_ptr_4513214464_24, False, 0.10000000000000001, 1.0000000000000001e-05, True]
        args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double, Bool]
        op_id: 638
        schema: aten::_batch_norm_impl_index(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps, bool cudnn_enabled) -> (Tensor, Tensor, Tensor, Tensor, int)
        calls: 
        - fn_name: aten::empty
          args: [[0], 0, 0, cpu, None, None]
          args types: [GenericList, Int, Int, Device, None, None]
          op_id: 639
          schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
          calls: 
          returns: [empty_tensor_424]
          returns types: [Tensor]
        - fn_name: aten::native_batch_norm
          args: [tensor_ptr_4534007808_283, tensor_ptr_4513214464_24, tensor_ptr_4513216512_25, tensor_ptr_4513216512_25, tensor_ptr_4513214464_24, False, 0.10000000000000001, 1.0000000000000001e-05]
          args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double]
          op_id: 640
          schema: aten::native_batch_norm(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps) -> (Tensor, Tensor, Tensor)
          calls: 
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 641
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_425]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 642
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_426]
            returns types: [Tensor]
          - fn_name: aten::empty_like
            args: [tensor_ptr_4534007808_283, None, None, None, None, 0]
            args types: [Tensor, None, None, None, None, Int]
            op_id: 643
            schema: aten::empty_like(Tensor self, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: aten::empty
              args: [[1, 512, 1, 1], 6, 0, cpu, None, 0]
              args types: [GenericList, Int, Int, Device, None, Int]
              op_id: 644
              schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
              calls: 
              - fn_name: allocate
                addr: '4524109824_284'
                size: 2048
                op_id: 645
              returns: [tensor_ptr_4524109824_284]
              returns types: [Tensor]
            returns: [tensor_ptr_4524109824_284]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[512], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 646
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: allocate
              addr: '4604758016_285'
              size: 2048
              op_id: 647
            returns: [tensor_ptr_4604758016_285]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[512], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 648
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: allocate
              addr: '4523913216_286'
              size: 2048
              op_id: 649
            returns: [tensor_ptr_4523913216_286]
            returns types: [Tensor]
          - fn_name: free
            addr: '4523913216_286'
            size: 2048
            op_id: 650
          - fn_name: free
            addr: '4604758016_285'
            size: 2048
            op_id: 651
          returns: [tensor_ptr_4524109824_284, empty_tensor_425, empty_tensor_426]
          returns types: [Tensor, Tensor, Tensor]
        returns: [tensor_ptr_4524109824_284, empty_tensor_425, empty_tensor_426, empty_tensor_424, 0]
        returns types: [Tensor, Tensor, Tensor, Tensor, Int]
      returns: [tensor_ptr_4524109824_284]
      returns types: [Tensor]
      returns names: [$input49_1]
    - fn_name: free
      addr: '4534007808_283'
      size: 2048
      op_id: 652
    - fn_name: aten::relu
      args: [tensor_ptr_4524109824_284]
      args types: [Tensor]
      args names: [$input49_1]
      op_id: 653
      schema: aten::relu(Tensor self) -> (Tensor)
      calls: 
      - fn_name: aten::clamp_min
        args: [tensor_ptr_4524109824_284, 0]
        args types: [Tensor, Int]
        op_id: 654
        schema: aten::clamp_min(Tensor self, Scalar min) -> (Tensor)
        calls: 
        - fn_name: aten::empty
          args: [[0], 6, 0, cpu, None, None]
          args types: [GenericList, Int, Int, Device, None, None]
          op_id: 655
          schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
          calls: 
          returns: [empty_tensor_430]
          returns types: [Tensor]
        - fn_name: aten::clamp_min
          args: [tensor_ptr_4524109824_284, 0, empty_tensor_430]
          args types: [Tensor, Int, Tensor]
          op_id: 656
          schema: aten::clamp_min.out(Tensor self, Scalar min, *, Tensor(a!) out) -> (Tensor(a!))
          calls: 
          - fn_name: allocate
            addr: '4534007808_287'
            size: 2048
            op_id: 657
          returns: [tensor_ptr_4534007808_287]
          returns types: [Tensor]
        returns: [tensor_ptr_4534007808_287]
        returns types: [Tensor]
      returns: [tensor_ptr_4534007808_287]
      returns types: [Tensor]
      returns names: [$input50_1]
    - fn_name: free
      addr: '4524109824_284'
      size: 2048
      op_id: 658
    - fn_name: aten::_convolution
      args: [tensor_ptr_4534007808_287, tensor_ptr_4557119488_29, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1, False, False, True, True]
      args types: [Tensor, Tensor, None, GenericList, GenericList, GenericList, Bool, GenericList, Int, Bool, Bool, Bool, Bool]
      args names: [$input50_1, $38, $8, $13, $13, $13, $9, $1, $6, $9, $9, $10, $10]
      op_id: 659
      schema: aten::_convolution(Tensor input, Tensor weight, Tensor? bias, int[] stride, int[] padding, int[] dilation, bool transposed, int[] output_padding, int groups, bool benchmark, bool deterministic, bool cudnn_enabled, bool allow_tf32) -> (Tensor)
      calls: 
      - fn_name: aten::thnn_conv2d
        args: [tensor_ptr_4534007808_287, tensor_ptr_4557119488_29, [3, 3], null, [1, 1], [1, 1]]
        args types: [Tensor, Tensor, GenericList, Tensor, GenericList, GenericList]
        op_id: 660
        schema: aten::thnn_conv2d(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias=None, int[2] stride=[1, 1], int[2] padding=[0, 0]) -> (Tensor)
        calls: 
        - fn_name: aten::_slow_conv2d_forward
          args: [tensor_ptr_4534007808_287, tensor_ptr_4557119488_29, [3, 3], null, [1, 1], [1, 1]]
          args types: [Tensor, Tensor, GenericList, Tensor, GenericList, GenericList]
          op_id: 661
          schema: aten::_slow_conv2d_forward(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias, int[2] stride, int[2] padding) -> (Tensor output, Tensor finput)
          calls: 
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 662
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_431]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 663
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_432]
            returns types: [Tensor]
          - fn_name: aten::view
            args: [tensor_ptr_4557119488_29, [512, 4608]]
            args types: [Tensor, GenericList]
            op_id: 664
            schema: aten::view(Tensor(a) self, int[] size) -> (Tensor(a))
            calls: 
            returns: [tensor_ptr_4557119488_29]
            returns types: [Tensor]
          - fn_name: aten::resize_
            args: [empty_tensor_432, [1, 4608, 1], None]
            args types: [Tensor, GenericList, None]
            op_id: 665
            schema: aten::resize_(Tensor(a!) self, int[] size, *, int? memory_format=None) -> (Tensor(a!))
            calls: 
            - fn_name: allocate
              addr: '4588368512_288'
              size: 18432
              op_id: 666
            returns: [tensor_ptr_4588368512_288]
            returns types: [Tensor]
          - fn_name: aten::resize_
            args: [empty_tensor_431, [1, 512, 1, 1], None]
            args types: [Tensor, GenericList, None]
            op_id: 667
            schema: aten::resize_(Tensor(a!) self, int[] size, *, int? memory_format=None) -> (Tensor(a!))
            calls: 
            - fn_name: allocate
              addr: '4524109824_289'
              size: 2048
              op_id: 668
            returns: [tensor_ptr_4524109824_289]
            returns types: [Tensor]
          returns: [tensor_ptr_4524109824_289, tensor_ptr_4588368512_288]
          returns types: [Tensor, Tensor]
        - fn_name: free
          addr: '4588368512_288'
          size: 18432
          op_id: 669
        returns: [tensor_ptr_4524109824_289]
        returns types: [Tensor]
      returns: [tensor_ptr_4524109824_289]
      returns types: [Tensor]
      returns names: [$input51_1]
    - fn_name: free
      addr: '4534007808_287'
      size: 2048
      op_id: 670
    - fn_name: aten::batch_norm
      args: [tensor_ptr_4524109824_289, tensor_ptr_4513214464_24, tensor_ptr_4513216512_25, tensor_ptr_4513216512_25, tensor_ptr_4513214464_24, False, 0.10000000000000001, 1.0000000000000001e-05, True]
      args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double, Bool]
      args names: [$input51_1, $33, $34, $34, $33, $9, $5, $4, $10]
      op_id: 671
      schema: aten::batch_norm(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps, bool cudnn_enabled) -> (Tensor)
      calls: 
      - fn_name: aten::_batch_norm_impl_index
        args: [tensor_ptr_4524109824_289, tensor_ptr_4513214464_24, tensor_ptr_4513216512_25, tensor_ptr_4513216512_25, tensor_ptr_4513214464_24, False, 0.10000000000000001, 1.0000000000000001e-05, True]
        args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double, Bool]
        op_id: 672
        schema: aten::_batch_norm_impl_index(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps, bool cudnn_enabled) -> (Tensor, Tensor, Tensor, Tensor, int)
        calls: 
        - fn_name: aten::empty
          args: [[0], 0, 0, cpu, None, None]
          args types: [GenericList, Int, Int, Device, None, None]
          op_id: 673
          schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
          calls: 
          returns: [empty_tensor_433]
          returns types: [Tensor]
        - fn_name: aten::native_batch_norm
          args: [tensor_ptr_4524109824_289, tensor_ptr_4513214464_24, tensor_ptr_4513216512_25, tensor_ptr_4513216512_25, tensor_ptr_4513214464_24, False, 0.10000000000000001, 1.0000000000000001e-05]
          args types: [Tensor, Tensor, Tensor, Tensor, Tensor, Bool, Double, Double]
          op_id: 674
          schema: aten::native_batch_norm(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps) -> (Tensor, Tensor, Tensor)
          calls: 
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 675
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_434]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[0], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 676
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            returns: [empty_tensor_435]
            returns types: [Tensor]
          - fn_name: aten::empty_like
            args: [tensor_ptr_4524109824_289, None, None, None, None, 0]
            args types: [Tensor, None, None, None, None, Int]
            op_id: 677
            schema: aten::empty_like(Tensor self, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: aten::empty
              args: [[1, 512, 1, 1], 6, 0, cpu, None, 0]
              args types: [GenericList, Int, Int, Device, None, Int]
              op_id: 678
              schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
              calls: 
              - fn_name: allocate
                addr: '4534007808_290'
                size: 2048
                op_id: 679
              returns: [tensor_ptr_4534007808_290]
              returns types: [Tensor]
            returns: [tensor_ptr_4534007808_290]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[512], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 680
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: allocate
              addr: '4604758016_291'
              size: 2048
              op_id: 681
            returns: [tensor_ptr_4604758016_291]
            returns types: [Tensor]
          - fn_name: aten::empty
            args: [[512], 6, 0, cpu, None, None]
            args types: [GenericList, Int, Int, Device, None, None]
            op_id: 682
            schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
            calls: 
            - fn_name: allocate
              addr: '4523913216_292'
              size: 2048
              op_id: 683
            returns: [tensor_ptr_4523913216_292]
            returns types: [Tensor]
          - fn_name: free
            addr: '4523913216_292'
            size: 2048
            op_id: 684
          - fn_name: free
            addr: '4604758016_291'
            size: 2048
            op_id: 685
          returns: [tensor_ptr_4534007808_290, empty_tensor_434, empty_tensor_435]
          returns types: [Tensor, Tensor, Tensor]
        returns: [tensor_ptr_4534007808_290, empty_tensor_434, empty_tensor_435, empty_tensor_433, 0]
        returns types: [Tensor, Tensor, Tensor, Tensor, Int]
      returns: [tensor_ptr_4534007808_290]
      returns types: [Tensor]
      returns names: [$out6_1]
    - fn_name: free
      addr: '4524109824_289'
      size: 2048
      op_id: 686
    - fn_name: aten::add
      args: [tensor_ptr_4534007808_290, tensor_ptr_4524111872_281, 1]
      args types: [Tensor, Tensor, Int]
      args names: [$out6_1, $input47_1, $6]
      op_id: 687
      schema: aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> (Tensor)
      calls: 
      - fn_name: allocate
        addr: '4524109824_293'
        size: 2048
        op_id: 688
      returns: [tensor_ptr_4524109824_293]
      returns types: [Tensor]
      returns names: [$input52_1]
    - fn_name: free
      addr: '4524111872_281'
      size: 2048
      op_id: 689
    - fn_name: free
      addr: '4534007808_290'
      size: 2048
      op_id: 690
    - fn_name: aten::relu
      args: [tensor_ptr_4524109824_293]
      args types: [Tensor]
      args names: [$input52_1]
      op_id: 691
      schema: aten::relu(Tensor self) -> (Tensor)
      calls: 
      - fn_name: aten::clamp_min
        args: [tensor_ptr_4524109824_293, 0]
        args types: [Tensor, Int]
        op_id: 692
        schema: aten::clamp_min(Tensor self, Scalar min) -> (Tensor)
        calls: 
        - fn_name: aten::empty
          args: [[0], 6, 0, cpu, None, None]
          args types: [GenericList, Int, Int, Device, None, None]
          op_id: 693
          schema: aten::empty.memory_format(int[] size, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, int? memory_format=None) -> (Tensor)
          calls: 
          returns: [empty_tensor_440]
          returns types: [Tensor]
        - fn_name: aten::clamp_min
          args: [tensor_ptr_4524109824_293, 0, empty_tensor_440]
          args types: [Tensor, Int, Tensor]
          op_id: 694
          schema: aten::clamp_min.out(Tensor self, Scalar min, *, Tensor(a!) out) -> (Tensor(a!))
          calls: 
          - fn_name: allocate
            addr: '4534007808_294'
            size: 2048
            op_id: 695
          returns: [tensor_ptr_4534007808_294]
          returns types: [Tensor]
        returns: [tensor_ptr_4534007808_294]
        returns types: [Tensor]
      returns: [tensor_ptr_4534007808_294]
      returns types: [Tensor]
      returns names: [$input53_1]
    - fn_name: free
      addr: '4524109824_293'
      size: 2048
      op_id: 696
    - fn_name: aten::adaptive_avg_pool2d
      args: [tensor_ptr_4534007808_294, [1, 1]]
      args types: [Tensor, GenericList]
      args names: [$input53_1, $13]
      op_id: 697
      schema: aten::adaptive_avg_pool2d(Tensor self, int[2] output_size) -> (Tensor)
      calls: 
      - fn_name: aten::mean
        args: [tensor_ptr_4534007808_294, [-1, -2], True, None]
        args types: [Tensor, GenericList, Bool, None]
        op_id: 698
        schema: aten::mean.dim(Tensor self, int[1] dim, bool keepdim=False, *, int? dtype=None) -> (Tensor)
        calls: 
        - fn_name: allocate
          addr: '4524109824_295'
          size: 2048
          op_id: 699
        - fn_name: aten::sum
          args: [tensor_ptr_4534007808_294, [-1, -2], True, 6, tensor_ptr_4524109824_295]
          args types: [Tensor, GenericList, Bool, Int, Tensor]
          op_id: 700
          schema: aten::sum.IntList_out(Tensor self, int[1] dim, bool keepdim=False, *, int? dtype=None, Tensor(a!) out) -> (Tensor(a!))
          calls: 
          - fn_name: aten::fill_
            args: [tensor_ptr_4524109824_295, 0.]
            args types: [Tensor, Double]
            op_id: 701
            schema: aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> (Tensor(a!))
            calls: 
            returns: [tensor_ptr_4524109824_295]
            returns types: [Tensor]
          returns: [tensor_ptr_4524109824_295]
          returns types: [Tensor]
        - fn_name: aten::div_
          args: [tensor_ptr_4524109824_295, 1]
          args types: [Tensor, Int]
          op_id: 702
          schema: aten::div_.Scalar(Tensor(a!) self, Scalar other) -> (Tensor(a!))
          calls: 
          - fn_name: allocate
            addr: '4571030528_296'
            size: 8
            op_id: 703
          - fn_name: aten::div_
            args: [tensor_ptr_4524109824_295, tensor_ptr_4571030528_296]
            args types: [Tensor, Tensor]
            op_id: 704
            schema: aten::div_.Tensor(Tensor(a!) self, Tensor other) -> (Tensor(a!))
            calls: 
            - fn_name: aten::to
              args: [tensor_ptr_4571030528_296, 6, False, False, None]
              args types: [Tensor, Int, Bool, Bool, None]
              op_id: 705
              schema: aten::to.dtype(Tensor(a) self, int dtype, bool non_blocking=False, bool copy=False, int? memory_format=None) -> (Tensor(a))
              calls: 
              - fn_name: aten::_to_copy
                args: [tensor_ptr_4571030528_296, 6, None, None, None, False, None]
                args types: [Tensor, Int, None, None, None, Bool, None]
                op_id: 706
                schema: aten::_to_copy(Tensor self, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, int? memory_format=None) -> (Tensor)
                calls: 
                - fn_name: aten::empty_strided
                  args: [[], [], 6, 0, cpu, False]
                  args types: [GenericList, GenericList, Int, Int, Device, Bool]
                  op_id: 707
                  schema: aten::empty_strided(int[] size, int[] stride, *, int? dtype=None, int? layout=None, Device? device=None, bool? pin_memory=None) -> (Tensor)
                  calls: 
                  - fn_name: allocate
                    addr: '4512054976_297'
                    size: 4
                    op_id: 708
                  returns: [tensor_ptr_4512054976_297]
                  returns types: [Tensor]
                - fn_name: aten::copy_
                  args: [tensor_ptr_4512054976_297, tensor_ptr_4571030528_296, False]
                  args types: [Tensor, Tensor, Bool]
                  op_id: 709
                  schema: aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> (Tensor(a!))
                  calls: 
                  returns: [tensor_ptr_4512054976_297]
                  returns types: [Tensor]
                returns: [tensor_ptr_4512054976_297]
                returns types: [Tensor]
              returns: [tensor_ptr_4512054976_297]
              returns types: [Tensor]
            - fn_name: free
              addr: '4512054976_297'
              size: 4
              op_id: 710
            returns: [tensor_ptr_4524109824_295]
            returns types: [Tensor]
          - fn_name: free
            addr: '4571030528_296'
            size: 8
            op_id: 711
          returns: [tensor_ptr_4524109824_295]
          returns types: [Tensor]
        returns: [tensor_ptr_4524109824_295]
        returns types: [Tensor]
      returns: [tensor_ptr_4524109824_295]
      returns types: [Tensor]
      returns names: [$x0_1]
    - fn_name: free
      addr: '4534007808_294'
      size: 2048
      op_id: 712
    - fn_name: aten::flatten
      args: [tensor_ptr_4524109824_295, 1, -1]
      args types: [Tensor, Int, Int]
      args names: [$x0_1, $6, $39]
      op_id: 713
      schema: aten::flatten.using_ints(Tensor(a) self, int start_dim=0, int end_dim=-1) -> (Tensor(a))
      calls: 
      - fn_name: aten::_reshape_alias
        args: [tensor_ptr_4524109824_295, [1, 512], [512, 1]]
        args types: [Tensor, GenericList, GenericList]
        op_id: 714
        schema: aten::_reshape_alias(Tensor(a) self, int[] size, int[] stride) -> (Tensor(a))
        calls: 
        returns: [tensor_ptr_4524109824_295]
        returns types: [Tensor]
      returns: [tensor_ptr_4524109824_295]
      returns types: [Tensor]
      returns names: [$input54_1]
    - fn_name: aten::linear
      args: [tensor_ptr_4524109824_295, tensor_ptr_4567609856_30, tensor_ptr_4511916032_31]
      args types: [Tensor, Tensor, Tensor]
      args names: [$input54_1, $40, $41]
      op_id: 715
      schema: aten::linear(Tensor input, Tensor weight, Tensor? bias=None) -> (Tensor)
      calls: 
      - fn_name: aten::t
        args: [tensor_ptr_4567609856_30]
        args types: [Tensor]
        op_id: 716
        schema: aten::t(Tensor(a) self) -> (Tensor(a))
        calls: 
        - fn_name: aten::transpose
          args: [tensor_ptr_4567609856_30, 0, 1]
          args types: [Tensor, Int, Int]
          op_id: 717
          schema: aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> (Tensor(a))
          calls: 
          - fn_name: aten::as_strided
            args: [tensor_ptr_4567609856_30, [512, 1000], [1, 512], None]
            args types: [Tensor, GenericList, GenericList, None]
            op_id: 718
            schema: aten::as_strided(Tensor(a) self, int[] size, int[] stride, int? storage_offset=None) -> (Tensor(a))
            calls: 
            returns: [tensor_ptr_4567609856_30]
            returns types: [Tensor]
          returns: [tensor_ptr_4567609856_30]
          returns types: [Tensor]
        returns: [tensor_ptr_4567609856_30]
        returns types: [Tensor]
      - fn_name: aten::addmm
        args: [tensor_ptr_4511916032_31, tensor_ptr_4524109824_295, tensor_ptr_4567609856_30, 1, 1]
        args types: [Tensor, Tensor, Tensor, Int, Int]
        op_id: 719
        schema: aten::addmm(Tensor self, Tensor mat1, Tensor mat2, *, Scalar beta=1, Scalar alpha=1) -> (Tensor)
        calls: 
        - fn_name: allocate
          addr: '4588072960_298'
          size: 4000
          op_id: 720
        - fn_name: aten::expand
          args: [tensor_ptr_4511916032_31, [1, 1000], False]
          args types: [Tensor, GenericList, Bool]
          op_id: 721
          schema: aten::expand(Tensor(a) self, int[] size, *, bool implicit=False) -> (Tensor(a))
          calls: 
          - fn_name: aten::as_strided
            args: [tensor_ptr_4511916032_31, [1, 1000], [1000, 1], None]
            args types: [Tensor, GenericList, GenericList, None]
            op_id: 722
            schema: aten::as_strided(Tensor(a) self, int[] size, int[] stride, int? storage_offset=None) -> (Tensor(a))
            calls: 
            returns: [tensor_ptr_4511916032_31]
            returns types: [Tensor]
          returns: [tensor_ptr_4511916032_31]
          returns types: [Tensor]
        - fn_name: aten::copy_
          args: [tensor_ptr_4588072960_298, tensor_ptr_4511916032_31, False]
          args types: [Tensor, Tensor, Bool]
          op_id: 723
          schema: aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> (Tensor(a!))
          calls: 
          returns: [tensor_ptr_4588072960_298]
          returns types: [Tensor]
        - fn_name: aten::resolve_conj
          args: [tensor_ptr_4588072960_298]
          args types: [Tensor]
          op_id: 724
          schema: aten::resolve_conj(Tensor(a) self) -> (Tensor(a))
          calls: 
          returns: [tensor_ptr_4588072960_298]
          returns types: [Tensor]
        - fn_name: aten::resolve_conj
          args: [tensor_ptr_4524109824_295]
          args types: [Tensor]
          op_id: 725
          schema: aten::resolve_conj(Tensor(a) self) -> (Tensor(a))
          calls: 
          returns: [tensor_ptr_4524109824_295]
          returns types: [Tensor]
        returns: [tensor_ptr_4588072960_298]
        returns types: [Tensor]
      returns: [tensor_ptr_4588072960_298]
      returns types: [Tensor]
      returns names: [$110]
    - fn_name: free
      addr: '4524109824_295'
      size: 2048
      op_id: 726
    returns: []
    returns types: []
  - fn_name: free
    addr: '4571030976_167'
    size: 12
    op_id: 727
  - fn_name: free
    addr: '4588072960_298'
    size: 4000
    op_id: 728
allocations_list:
- fn_name: allocate
  addr: '4571030976_167'
  size: 12
  op_id: 3
- fn_name: allocate
  addr: '4511493376_168'
  size: 588
  op_id: 13
- fn_name: allocate
  addr: '4587130112_169'
  size: 256
  op_id: 15
- fn_name: free
  addr: '4511493376_168'
  size: 588
  op_id: 16
- fn_name: allocate
  addr: '4587129856_170'
  size: 256
  op_id: 25
- fn_name: allocate
  addr: '4587139072_171'
  size: 256
  op_id: 27
- fn_name: allocate
  addr: '4587139328_172'
  size: 256
  op_id: 29
- fn_name: free
  addr: '4587139328_172'
  size: 256
  op_id: 30
- fn_name: free
  addr: '4587139072_171'
  size: 256
  op_id: 31
- fn_name: free
  addr: '4587130112_169'
  size: 256
  op_id: 32
- fn_name: allocate
  addr: '4587130112_173'
  size: 256
  op_id: 37
- fn_name: free
  addr: '4587129856_170'
  size: 256
  op_id: 38
- fn_name: allocate
  addr: '4587129856_174'
  size: 256
  op_id: 41
- fn_name: allocate
  addr: '4502885888_175'
  size: 512
  op_id: 42
- fn_name: free
  addr: '4502885888_175'
  size: 512
  op_id: 43
- fn_name: free
  addr: '4587130112_173'
  size: 256
  op_id: 44
- fn_name: allocate
  addr: '4588744704_176'
  size: 2304
  op_id: 52
- fn_name: allocate
  addr: '4587130112_177'
  size: 256
  op_id: 54
- fn_name: free
  addr: '4588744704_176'
  size: 2304
  op_id: 55
- fn_name: allocate
  addr: '4587139072_178'
  size: 256
  op_id: 64
- fn_name: allocate
  addr: '4587139328_179'
  size: 256
  op_id: 66
- fn_name: allocate
  addr: '4587139584_180'
  size: 256
  op_id: 68
- fn_name: free
  addr: '4587139584_180'
  size: 256
  op_id: 69
- fn_name: free
  addr: '4587139328_179'
  size: 256
  op_id: 70
- fn_name: free
  addr: '4587130112_177'
  size: 256
  op_id: 71
- fn_name: allocate
  addr: '4587130112_181'
  size: 256
  op_id: 76
- fn_name: free
  addr: '4587139072_178'
  size: 256
  op_id: 77
- fn_name: allocate
  addr: '4589154816_182'
  size: 2304
  op_id: 85
- fn_name: allocate
  addr: '4587139072_183'
  size: 256
  op_id: 87
- fn_name: free
  addr: '4589154816_182'
  size: 2304
  op_id: 88
- fn_name: free
  addr: '4587130112_181'
  size: 256
  op_id: 89
- fn_name: allocate
  addr: '4587130112_184'
  size: 256
  op_id: 98
- fn_name: allocate
  addr: '4587139328_185'
  size: 256
  op_id: 100
- fn_name: allocate
  addr: '4587139584_186'
  size: 256
  op_id: 102
- fn_name: free
  addr: '4587139584_186'
  size: 256
  op_id: 103
- fn_name: free
  addr: '4587139328_185'
  size: 256
  op_id: 104
- fn_name: free
  addr: '4587139072_183'
  size: 256
  op_id: 105
- fn_name: allocate
  addr: '4587139072_187'
  size: 256
  op_id: 107
- fn_name: free
  addr: '4587129856_174'
  size: 256
  op_id: 108
- fn_name: free
  addr: '4587130112_184'
  size: 256
  op_id: 109
- fn_name: allocate
  addr: '4587130112_188'
  size: 256
  op_id: 114
- fn_name: free
  addr: '4587139072_187'
  size: 256
  op_id: 115
- fn_name: allocate
  addr: '4589157376_189'
  size: 2304
  op_id: 123
- fn_name: allocate
  addr: '4587139072_190'
  size: 256
  op_id: 125
- fn_name: free
  addr: '4589157376_189'
  size: 2304
  op_id: 126
- fn_name: allocate
  addr: '4587129856_191'
  size: 256
  op_id: 135
- fn_name: allocate
  addr: '4587139328_192'
  size: 256
  op_id: 137
- fn_name: allocate
  addr: '4587139584_193'
  size: 256
  op_id: 139
- fn_name: free
  addr: '4587139584_193'
  size: 256
  op_id: 140
- fn_name: free
  addr: '4587139328_192'
  size: 256
  op_id: 141
- fn_name: free
  addr: '4587139072_190'
  size: 256
  op_id: 142
- fn_name: allocate
  addr: '4587139072_194'
  size: 256
  op_id: 147
- fn_name: free
  addr: '4587129856_191'
  size: 256
  op_id: 148
- fn_name: allocate
  addr: '4589154816_195'
  size: 2304
  op_id: 156
- fn_name: allocate
  addr: '4587129856_196'
  size: 256
  op_id: 158
- fn_name: free
  addr: '4589154816_195'
  size: 2304
  op_id: 159
- fn_name: free
  addr: '4587139072_194'
  size: 256
  op_id: 160
- fn_name: allocate
  addr: '4587139072_197'
  size: 256
  op_id: 169
- fn_name: allocate
  addr: '4587139328_198'
  size: 256
  op_id: 171
- fn_name: allocate
  addr: '4587139584_199'
  size: 256
  op_id: 173
- fn_name: free
  addr: '4587139584_199'
  size: 256
  op_id: 174
- fn_name: free
  addr: '4587139328_198'
  size: 256
  op_id: 175
- fn_name: free
  addr: '4587129856_196'
  size: 256
  op_id: 176
- fn_name: allocate
  addr: '4587129856_200'
  size: 256
  op_id: 178
- fn_name: free
  addr: '4587130112_188'
  size: 256
  op_id: 179
- fn_name: free
  addr: '4587139072_197'
  size: 256
  op_id: 180
- fn_name: allocate
  addr: '4587139072_201'
  size: 256
  op_id: 185
- fn_name: free
  addr: '4587129856_200'
  size: 256
  op_id: 186
- fn_name: allocate
  addr: '4589157376_202'
  size: 2304
  op_id: 194
- fn_name: allocate
  addr: '4503111168_203'
  size: 512
  op_id: 196
- fn_name: free
  addr: '4589157376_202'
  size: 2304
  op_id: 197
- fn_name: allocate
  addr: '4502904832_204'
  size: 512
  op_id: 206
- fn_name: allocate
  addr: '4502705152_205'
  size: 512
  op_id: 208
- fn_name: allocate
  addr: '4502602240_206'
  size: 512
  op_id: 210
- fn_name: free
  addr: '4502602240_206'
  size: 512
  op_id: 211
- fn_name: free
  addr: '4502705152_205'
  size: 512
  op_id: 212
- fn_name: free
  addr: '4503111168_203'
  size: 512
  op_id: 213
- fn_name: allocate
  addr: '4503111168_207'
  size: 512
  op_id: 218
- fn_name: free
  addr: '4502904832_204'
  size: 512
  op_id: 219
- fn_name: allocate
  addr: '4590220288_208'
  size: 4608
  op_id: 227
- fn_name: allocate
  addr: '4502904832_209'
  size: 512
  op_id: 229
- fn_name: free
  addr: '4590220288_208'
  size: 4608
  op_id: 230
- fn_name: free
  addr: '4503111168_207'
  size: 512
  op_id: 231
- fn_name: allocate
  addr: '4503014400_210'
  size: 512
  op_id: 240
- fn_name: allocate
  addr: '4502610944_211'
  size: 512
  op_id: 242
- fn_name: allocate
  addr: '4502704640_212'
  size: 512
  op_id: 244
- fn_name: free
  addr: '4502704640_212'
  size: 512
  op_id: 245
- fn_name: free
  addr: '4502610944_211'
  size: 512
  op_id: 246
- fn_name: free
  addr: '4502904832_209'
  size: 512
  op_id: 247
- fn_name: allocate
  addr: '4587129856_213'
  size: 256
  op_id: 255
- fn_name: allocate
  addr: '4502904832_214'
  size: 512
  op_id: 257
- fn_name: free
  addr: '4587129856_213'
  size: 256
  op_id: 258
- fn_name: free
  addr: '4587139072_201'
  size: 256
  op_id: 259
- fn_name: allocate
  addr: '4502610944_215'
  size: 512
  op_id: 268
- fn_name: allocate
  addr: '4507297792_216'
  size: 512
  op_id: 270
- fn_name: allocate
  addr: '4507299840_217'
  size: 512
  op_id: 272
- fn_name: free
  addr: '4507299840_217'
  size: 512
  op_id: 273
- fn_name: free
  addr: '4507297792_216'
  size: 512
  op_id: 274
- fn_name: free
  addr: '4502904832_214'
  size: 512
  op_id: 275
- fn_name: allocate
  addr: '4502904832_218'
  size: 512
  op_id: 277
- fn_name: free
  addr: '4502610944_215'
  size: 512
  op_id: 278
- fn_name: free
  addr: '4503014400_210'
  size: 512
  op_id: 279
- fn_name: allocate
  addr: '4503014400_219'
  size: 512
  op_id: 284
- fn_name: free
  addr: '4502904832_218'
  size: 512
  op_id: 285
- fn_name: allocate
  addr: '4590220288_220'
  size: 4608
  op_id: 293
- fn_name: allocate
  addr: '4502904832_221'
  size: 512
  op_id: 295
- fn_name: free
  addr: '4590220288_220'
  size: 4608
  op_id: 296
- fn_name: allocate
  addr: '4503111168_222'
  size: 512
  op_id: 305
- fn_name: allocate
  addr: '4507365376_223'
  size: 512
  op_id: 307
- fn_name: allocate
  addr: '4507365888_224'
  size: 512
  op_id: 309
- fn_name: free
  addr: '4507365888_224'
  size: 512
  op_id: 310
- fn_name: free
  addr: '4507365376_223'
  size: 512
  op_id: 311
- fn_name: free
  addr: '4502904832_221'
  size: 512
  op_id: 312
- fn_name: allocate
  addr: '4507254784_225'
  size: 512
  op_id: 317
- fn_name: free
  addr: '4503111168_222'
  size: 512
  op_id: 318
- fn_name: allocate
  addr: '4590220288_226'
  size: 4608
  op_id: 326
- fn_name: allocate
  addr: '4503111168_227'
  size: 512
  op_id: 328
- fn_name: free
  addr: '4590220288_226'
  size: 4608
  op_id: 329
- fn_name: free
  addr: '4507254784_225'
  size: 512
  op_id: 330
- fn_name: allocate
  addr: '4507175936_228'
  size: 512
  op_id: 339
- fn_name: allocate
  addr: '4503844352_229'
  size: 512
  op_id: 341
- fn_name: allocate
  addr: '4503843840_230'
  size: 512
  op_id: 343
- fn_name: free
  addr: '4503843840_230'
  size: 512
  op_id: 344
- fn_name: free
  addr: '4503844352_229'
  size: 512
  op_id: 345
- fn_name: free
  addr: '4503111168_227'
  size: 512
  op_id: 346
- fn_name: allocate
  addr: '4503111168_231'
  size: 512
  op_id: 348
- fn_name: free
  addr: '4503014400_219'
  size: 512
  op_id: 349
- fn_name: free
  addr: '4507175936_228'
  size: 512
  op_id: 350
- fn_name: allocate
  addr: '4507175936_232'
  size: 512
  op_id: 355
- fn_name: free
  addr: '4503111168_231'
  size: 512
  op_id: 356
- fn_name: allocate
  addr: '4590220288_233'
  size: 4608
  op_id: 364
- fn_name: allocate
  addr: '4511935488_234'
  size: 1024
  op_id: 366
- fn_name: free
  addr: '4590220288_233'
  size: 4608
  op_id: 367
- fn_name: allocate
  addr: '4511934464_235'
  size: 1024
  op_id: 376
- fn_name: allocate
  addr: '4533656576_236'
  size: 1024
  op_id: 378
- fn_name: allocate
  addr: '4571009024_237'
  size: 1024
  op_id: 380
- fn_name: free
  addr: '4571009024_237'
  size: 1024
  op_id: 381
- fn_name: free
  addr: '4533656576_236'
  size: 1024
  op_id: 382
- fn_name: free
  addr: '4511935488_234'
  size: 1024
  op_id: 383
- fn_name: allocate
  addr: '4511935488_238'
  size: 1024
  op_id: 388
- fn_name: free
  addr: '4511934464_235'
  size: 1024
  op_id: 389
- fn_name: allocate
  addr: '4589889536_239'
  size: 9216
  op_id: 397
- fn_name: allocate
  addr: '4511934464_240'
  size: 1024
  op_id: 399
- fn_name: free
  addr: '4589889536_239'
  size: 9216
  op_id: 400
- fn_name: free
  addr: '4511935488_238'
  size: 1024
  op_id: 401
- fn_name: allocate
  addr: '4511935488_241'
  size: 1024
  op_id: 410
- fn_name: allocate
  addr: '4533656576_242'
  size: 1024
  op_id: 412
- fn_name: allocate
  addr: '4571009024_243'
  size: 1024
  op_id: 414
- fn_name: free
  addr: '4571009024_243'
  size: 1024
  op_id: 415
- fn_name: free
  addr: '4533656576_242'
  size: 1024
  op_id: 416
- fn_name: free
  addr: '4511934464_240'
  size: 1024
  op_id: 417
- fn_name: allocate
  addr: '4503111168_244'
  size: 512
  op_id: 425
- fn_name: allocate
  addr: '4511934464_245'
  size: 1024
  op_id: 427
- fn_name: free
  addr: '4503111168_244'
  size: 512
  op_id: 428
- fn_name: free
  addr: '4507175936_232'
  size: 512
  op_id: 429
- fn_name: allocate
  addr: '4533656576_246'
  size: 1024
  op_id: 438
- fn_name: allocate
  addr: '4571009024_247'
  size: 1024
  op_id: 440
- fn_name: allocate
  addr: '4571010048_248'
  size: 1024
  op_id: 442
- fn_name: free
  addr: '4571010048_248'
  size: 1024
  op_id: 443
- fn_name: free
  addr: '4571009024_247'
  size: 1024
  op_id: 444
- fn_name: free
  addr: '4511934464_245'
  size: 1024
  op_id: 445
- fn_name: allocate
  addr: '4511934464_249'
  size: 1024
  op_id: 447
- fn_name: free
  addr: '4533656576_246'
  size: 1024
  op_id: 448
- fn_name: free
  addr: '4511935488_241'
  size: 1024
  op_id: 449
- fn_name: allocate
  addr: '4511935488_250'
  size: 1024
  op_id: 454
- fn_name: free
  addr: '4511934464_249'
  size: 1024
  op_id: 455
- fn_name: allocate
  addr: '4589889536_251'
  size: 9216
  op_id: 463
- fn_name: allocate
  addr: '4511934464_252'
  size: 1024
  op_id: 465
- fn_name: free
  addr: '4589889536_251'
  size: 9216
  op_id: 466
- fn_name: allocate
  addr: '4533656576_253'
  size: 1024
  op_id: 475
- fn_name: allocate
  addr: '4571009024_254'
  size: 1024
  op_id: 477
- fn_name: allocate
  addr: '4571010048_255'
  size: 1024
  op_id: 479
- fn_name: free
  addr: '4571010048_255'
  size: 1024
  op_id: 480
- fn_name: free
  addr: '4571009024_254'
  size: 1024
  op_id: 481
- fn_name: free
  addr: '4511934464_252'
  size: 1024
  op_id: 482
- fn_name: allocate
  addr: '4511934464_256'
  size: 1024
  op_id: 487
- fn_name: free
  addr: '4533656576_253'
  size: 1024
  op_id: 488
- fn_name: allocate
  addr: '4589889536_257'
  size: 9216
  op_id: 496
- fn_name: allocate
  addr: '4533656576_258'
  size: 1024
  op_id: 498
- fn_name: free
  addr: '4589889536_257'
  size: 9216
  op_id: 499
- fn_name: free
  addr: '4511934464_256'
  size: 1024
  op_id: 500
- fn_name: allocate
  addr: '4511934464_259'
  size: 1024
  op_id: 509
- fn_name: allocate
  addr: '4571009024_260'
  size: 1024
  op_id: 511
- fn_name: allocate
  addr: '4571010048_261'
  size: 1024
  op_id: 513
- fn_name: free
  addr: '4571010048_261'
  size: 1024
  op_id: 514
- fn_name: free
  addr: '4571009024_260'
  size: 1024
  op_id: 515
- fn_name: free
  addr: '4533656576_258'
  size: 1024
  op_id: 516
- fn_name: allocate
  addr: '4533656576_262'
  size: 1024
  op_id: 518
- fn_name: free
  addr: '4511935488_250'
  size: 1024
  op_id: 519
- fn_name: free
  addr: '4511934464_259'
  size: 1024
  op_id: 520
- fn_name: allocate
  addr: '4511934464_263'
  size: 1024
  op_id: 525
- fn_name: free
  addr: '4533656576_262'
  size: 1024
  op_id: 526
- fn_name: allocate
  addr: '4589889536_264'
  size: 9216
  op_id: 534
- fn_name: allocate
  addr: '4524111872_265'
  size: 2048
  op_id: 536
- fn_name: free
  addr: '4589889536_264'
  size: 9216
  op_id: 537
- fn_name: allocate
  addr: '4534005760_266'
  size: 2048
  op_id: 546
- fn_name: allocate
  addr: '4591046656_267'
  size: 2048
  op_id: 548
- fn_name: allocate
  addr: '4591048704_268'
  size: 2048
  op_id: 550
- fn_name: free
  addr: '4591048704_268'
  size: 2048
  op_id: 551
- fn_name: free
  addr: '4591046656_267'
  size: 2048
  op_id: 552
- fn_name: free
  addr: '4524111872_265'
  size: 2048
  op_id: 553
- fn_name: allocate
  addr: '4524111872_269'
  size: 2048
  op_id: 558
- fn_name: free
  addr: '4534005760_266'
  size: 2048
  op_id: 559
- fn_name: allocate
  addr: '4590817728_270'
  size: 18432
  op_id: 567
- fn_name: allocate
  addr: '4534005760_271'
  size: 2048
  op_id: 569
- fn_name: free
  addr: '4590817728_270'
  size: 18432
  op_id: 570
- fn_name: free
  addr: '4524111872_269'
  size: 2048
  op_id: 571
- fn_name: allocate
  addr: '4524111872_272'
  size: 2048
  op_id: 580
- fn_name: allocate
  addr: '4591046656_273'
  size: 2048
  op_id: 582
- fn_name: allocate
  addr: '4591048704_274'
  size: 2048
  op_id: 584
- fn_name: free
  addr: '4591048704_274'
  size: 2048
  op_id: 585
- fn_name: free
  addr: '4591046656_273'
  size: 2048
  op_id: 586
- fn_name: free
  addr: '4534005760_271'
  size: 2048
  op_id: 587
- fn_name: allocate
  addr: '4533656576_275'
  size: 1024
  op_id: 595
- fn_name: allocate
  addr: '4534005760_276'
  size: 2048
  op_id: 597
- fn_name: free
  addr: '4533656576_275'
  size: 1024
  op_id: 598
- fn_name: free
  addr: '4511934464_263'
  size: 1024
  op_id: 599
- fn_name: allocate
  addr: '4591046656_277'
  size: 2048
  op_id: 608
- fn_name: allocate
  addr: '4591048704_278'
  size: 2048
  op_id: 610
- fn_name: allocate
  addr: '4591050752_279'
  size: 2048
  op_id: 612
- fn_name: free
  addr: '4591050752_279'
  size: 2048
  op_id: 613
- fn_name: free
  addr: '4591048704_278'
  size: 2048
  op_id: 614
- fn_name: free
  addr: '4534005760_276'
  size: 2048
  op_id: 615
- fn_name: allocate
  addr: '4534005760_280'
  size: 2048
  op_id: 617
- fn_name: free
  addr: '4591046656_277'
  size: 2048
  op_id: 618
- fn_name: free
  addr: '4524111872_272'
  size: 2048
  op_id: 619
- fn_name: allocate
  addr: '4524111872_281'
  size: 2048
  op_id: 624
- fn_name: free
  addr: '4534005760_280'
  size: 2048
  op_id: 625
- fn_name: allocate
  addr: '4587954368_282'
  size: 18432
  op_id: 633
- fn_name: allocate
  addr: '4534007808_283'
  size: 2048
  op_id: 635
- fn_name: free
  addr: '4587954368_282'
  size: 18432
  op_id: 636
- fn_name: allocate
  addr: '4524109824_284'
  size: 2048
  op_id: 645
- fn_name: allocate
  addr: '4604758016_285'
  size: 2048
  op_id: 647
- fn_name: allocate
  addr: '4523913216_286'
  size: 2048
  op_id: 649
- fn_name: free
  addr: '4523913216_286'
  size: 2048
  op_id: 650
- fn_name: free
  addr: '4604758016_285'
  size: 2048
  op_id: 651
- fn_name: free
  addr: '4534007808_283'
  size: 2048
  op_id: 652
- fn_name: allocate
  addr: '4534007808_287'
  size: 2048
  op_id: 657
- fn_name: free
  addr: '4524109824_284'
  size: 2048
  op_id: 658
- fn_name: allocate
  addr: '4588368512_288'
  size: 18432
  op_id: 666
- fn_name: allocate
  addr: '4524109824_289'
  size: 2048
  op_id: 668
- fn_name: free
  addr: '4588368512_288'
  size: 18432
  op_id: 669
- fn_name: free
  addr: '4534007808_287'
  size: 2048
  op_id: 670
- fn_name: allocate
  addr: '4534007808_290'
  size: 2048
  op_id: 679
- fn_name: allocate
  addr: '4604758016_291'
  size: 2048
  op_id: 681
- fn_name: allocate
  addr: '4523913216_292'
  size: 2048
  op_id: 683
- fn_name: free
  addr: '4523913216_292'
  size: 2048
  op_id: 684
- fn_name: free
  addr: '4604758016_291'
  size: 2048
  op_id: 685
- fn_name: free
  addr: '4524109824_289'
  size: 2048
  op_id: 686
- fn_name: allocate
  addr: '4524109824_293'
  size: 2048
  op_id: 688
- fn_name: free
  addr: '4524111872_281'
  size: 2048
  op_id: 689
- fn_name: free
  addr: '4534007808_290'
  size: 2048
  op_id: 690
- fn_name: allocate
  addr: '4534007808_294'
  size: 2048
  op_id: 695
- fn_name: free
  addr: '4524109824_293'
  size: 2048
  op_id: 696
- fn_name: allocate
  addr: '4524109824_295'
  size: 2048
  op_id: 699
- fn_name: allocate
  addr: '4571030528_296'
  size: 8
  op_id: 703
- fn_name: allocate
  addr: '4512054976_297'
  size: 4
  op_id: 708
- fn_name: free
  addr: '4512054976_297'
  size: 4
  op_id: 710
- fn_name: free
  addr: '4571030528_296'
  size: 8
  op_id: 711
- fn_name: free
  addr: '4534007808_294'
  size: 2048
  op_id: 712
- fn_name: allocate
  addr: '4588072960_298'
  size: 4000
  op_id: 720
- fn_name: free
  addr: '4524109824_295'
  size: 2048
  op_id: 726
- fn_name: free
  addr: '4571030976_167'
  size: 12
  op_id: 727
- fn_name: free
  addr: '4588072960_298'
  size: 4000
  op_id: 728
